{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test xgboost with Bayesian Optimsation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x1085af128>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/suzukiry/lab/March/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/core.py\", line 368, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    }
   ],
   "source": [
    "### Thanks to Shinji Suzuki\n",
    "\n",
    "# OS\n",
    "import glob, re\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# data science tool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# machine learning\n",
    "from sklearn import *\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# データの読み込み\n",
    "# 事前にcalendar_dateをvisit_dataに変更しています。airとhpgで同じことですが、別名で使用されているようです。\n",
    "data = {\n",
    "    'tra': pd.read_csv('../../../mltestdata/05_recruit/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('../../../mltestdata/05_recruit/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('../../../mltestdata/05_recruit/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('../../../mltestdata/05_recruit/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('../../../mltestdata/05_recruit/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('../../../mltestdata/05_recruit/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('../../../mltestdata/05_recruit/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('../../../mltestdata/05_recruit/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "}\n",
    "\n",
    "# それぞれのデータをマージするために、まずは、relation用のものをマージします\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how = 'inner', on = ['hpg_store_id'])\n",
    "\n",
    "for df in ['ar', 'hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r:(r['visit_datetime']- r['reserve_datetime']).days, axis = 1)\n",
    "    tmp1 = data[df].groupby(['air_store_id', 'visit_datetime'], as_index =False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns = {'visit_datetime':'visit_date', 'reserve_datetime_diff':'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id', 'visit_datetime'], as_index =False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns = {'visit_datetime':'visit_date', 'reserve_datetime_diff':'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how = 'inner', on = ['air_store_id', 'visit_date'])\n",
    "\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n",
    "\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id':unique_stores, 'dow':[i]*len(unique_stores)}) for i in range(7)], axis =0, ignore_index = True).reset_index(drop = True) \n",
    "\n",
    "#曜日だけでなく、月も追加\n",
    "stores_m = pd.concat([pd.DataFrame({'air_store_id':unique_stores, 'month':[i]*len(unique_stores)}) for i in range(1,13)], axis =0, ignore_index = True).reset_index(drop = True)\n",
    "stores = pd.merge(stores_m, stores,on=('air_store_id'), how='left')\n",
    "\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].min().rename(columns = {'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].median().rename(columns = {'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].max().rename(columns = {'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index = False)['visitors'].count().rename(columns = {'visitors':'count_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'dow'])\n",
    "\n",
    "#曜日だけでなく、ID×月も追加\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].min().rename(columns = {'visitors':'m_min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'m_mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].median().rename(columns = {'visitors':'m_median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].max().rename(columns = {'visitors':'m_max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'month'], as_index = False)['visitors'].count().rename(columns = {'visitors':'m_count_visitors'})\n",
    "stores = pd.merge(stores, tmp, how ='left', on = ['air_store_id', 'month'])\n",
    "\n",
    "stores = pd.merge(stores, data['as'], how= \"left\", on = ['air_store_id'])\n",
    "\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/', ' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-', ' ')))\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name' + str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ' '))\n",
    "    stores['air_area_name' + str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ' '))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "#土日フラグ(day_of_week_1)と、休日前(holi_2)フラグを追加\n",
    "data['hol']['day_of_week_1']= data['hol']['day_of_week'].replace(['Saturday', 'Sunday','Monday','Tuesday','Wednesday','Thursday','Friday'],['1', '1','0','0','0','0','0']).astype('int')\n",
    "data['hol']['holi_2'] = data['hol'][['holiday_flg', 'day_of_week_1']].sum(axis = 1)\n",
    "data['hol']['holi_2'] = data['hol']['holi_2'].apply( lambda x: 0 if x < 1 else 1 )\n",
    "data['hol']['holi_2'] = data['hol']['holi_2'].shift(-1)\n",
    "data['hol']['holi_2'] = data['hol']['holi_2'].fillna(1)\n",
    "data['hol']['holi_2'] = data['hol']['holi_2'].astype('int')\n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "train = pd.merge(data['tra'], data['hol'], how ='left', on = ['visit_date'])\n",
    "test = pd.merge(data['tes'], data['hol'], how ='left', on = ['visit_date'])\n",
    "\n",
    "#曜日と月でmerge\n",
    "train = pd.merge(train, stores, how ='left', on = ['air_store_id', 'dow','month'])\n",
    "test = pd.merge(test, stores, how ='left', on = ['air_store_id', 'dow','month'])\n",
    "\n",
    "#ID×休日前でのvisitorsの平均、中央値等を追加\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].min().rename(columns = {'visitors':'h_min_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'h_mean_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].median().rename(columns = {'visitors':'h_median_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].max().rename(columns = {'visitors':'h_max_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "tmp = train.groupby(['air_store_id','holi_2'], as_index = False)['visitors'].count().rename(columns = {'visitors':'h_count_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','holi_2'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1) \n",
    "\n",
    "train['total_reserve_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserve_mean'] = (train['rv2_x'] + train['rv2_y'])/2\n",
    "train['total_reserve_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y'])/2\n",
    "\n",
    "test['total_reserve_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserve_mean'] = (test['rv2_x'] + test['rv2_y'])/2\n",
    "test['total_reserve_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y'])/2\n",
    "\n",
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2']= lbl.fit_transform(test['air_store_id'])\n",
    "\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date', 'visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "all_data = pd.concat([train, test]) \n",
    "\n",
    "#指数移動平均の追加。これはなくても良いかも\n",
    "#https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/46179#266344\n",
    "#def calc_shifted_ewm(series, alpha, adjust=True):\n",
    "#    return series.shift().ewm(alpha=alpha, adjust=adjust).mean()\n",
    "\n",
    "#train['ewm'] = train.groupby(['air_store_id', 'dow']).apply(lambda g: calc_shifted_ewm(g['visitors'], 0.1)).sort_index(level=['air_store_id']).values\n",
    "\n",
    "#以下、気象データの追加\n",
    "df_air_store_weather_station = pd.read_csv('../../../mltestdata/05_recruit/air_store_info_with_nearest_active_station.csv')\n",
    "\n",
    "cols = ['air_store_id', 'station_id', 'station_latitude', 'station_longitude', 'station_vincenty', 'station_great_circle']\n",
    "all_data = pd.merge(all_data, df_air_store_weather_station[cols], on='air_store_id', how='left')\n",
    "\n",
    "combine = all_data\n",
    "filenames = []\n",
    "df_weather = None\n",
    "for station_id in combine['station_id'].unique():\n",
    "    fn = f\"../../../mltestdata/05_recruit/1-1-16_5-31-17_Weather/{station_id}.csv\"\n",
    "    if not fn in filenames:\n",
    "        df = pd.read_csv(fn)\n",
    "        df['station_id'] = station_id\n",
    "        if df_weather is None:\n",
    "            df_weather = df\n",
    "        else:\n",
    "            df_weather = pd.concat([df_weather, df])\n",
    "        del df\n",
    "\n",
    "        filenames.append(fn)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#欠損値を平均で穴埋め（median, ffillで試すも特に差は出なかった）\n",
    "df_weather = df_weather.fillna(df_weather.mean())\n",
    "\n",
    "df_weather = df_weather.rename(columns={'calendar_date': 'visit_date'})\n",
    "\n",
    "df_weather['visit_date'] = pd.to_datetime(df_weather['visit_date'])\n",
    "df_weather['visit_date'] = df_weather['visit_date'].dt.date\n",
    "\n",
    "#なんとなく対数化\n",
    "df_weather['precipitation'] = np.log1p(df_weather['precipitation'])\n",
    "\n",
    "#使いそうなデータだけ結合（その他の気象データは試していません。特に意味はなし）\n",
    "cols = ['station_id', \n",
    "    'visit_date', \n",
    "    'precipitation', \n",
    "    'hours_sunlight',\n",
    "    'avg_temperature',\n",
    "    'high_temperature',\n",
    "    'low_temperature']\n",
    "\n",
    "combine = pd.merge(combine, df_weather[cols], on=['station_id', 'visit_date'], how='left')\n",
    "\n",
    "#降水量をカテゴリ化\n",
    "def simplify_pre(df):\n",
    "    df.precipitation = df.precipitation.fillna(0)\n",
    "    bins = ( -1, 0.01, 2,  5)\n",
    "    group_names = ['1', '2', '3']\n",
    "    categories = pd.cut(df.precipitation, bins, labels=group_names)\n",
    "    df.precipitation = categories\n",
    "    return df\n",
    "\n",
    "combine = simplify_pre(combine) \n",
    "all_data = combine \n",
    "\n",
    "#不要そうなデータを削除\n",
    "drop_col =['station_id', 'station_latitude','station_longitude','station_vincenty', 'station_great_circle','hours_sunlight','high_temperature','low_temperature']\n",
    "all_data = all_data.drop(drop_col, axis = 1)\n",
    "\n",
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]\n",
    "\n",
    "#ID×降水量で平均、中央値等を追加\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].min().rename(columns = {'visitors':'p_min_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].mean().rename(columns = {'visitors':'p_mean_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].median().rename(columns = {'visitors':'p_median_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation',])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].max().rename(columns = {'visitors':'p_max_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "tmp = train.groupby(['air_store_id','precipitation'], as_index = False)['visitors'].count().rename(columns = {'visitors':'p_count_visitors'})\n",
    "train = pd.merge(train, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "test = pd.merge(test, tmp, how ='left', on = ['air_store_id','precipitation'])\n",
    "\n",
    "#countをLabel Encoder化。なんとなく試してみたら結果が良かった。\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['count_visitors'] = lbl.fit_transform(train['count_visitors']) \n",
    "test['count_visitors']= lbl.fit_transform(test['count_visitors'])\n",
    "train['m_count_visitors'] = lbl.fit_transform(train['m_count_visitors'])\n",
    "test['m_count_visitors']= lbl.fit_transform(test['m_count_visitors'])\n",
    "train['h_count_reserves'] = lbl.fit_transform(train['h_count_visitors'])\n",
    "test['h_count_reserves']= lbl.fit_transform(test['h_count_visitors'])\n",
    "train['p_count_visitors'] = lbl.fit_transform(train['p_count_visitors'])\n",
    "test['p_count_visitors']= lbl.fit_transform(test['p_count_visitors'])\n",
    "\n",
    "# GW flag\n",
    "combine = [train, test]\n",
    "gw_list = ['2016-04-29','2016-04-30','2016-05-01','2016-05-02','2016-05-03','2016-05-04','2016-05-05','2017-04-29','2017-04-30','2017-05-01','2017-05-02','2017-05-03','2017-05-04','2017-05-05']\n",
    "post_gw_list=['2016-05-06']\n",
    "train['gw_flg'] = 0\n",
    "train['post_gw_flg'] = 0\n",
    "test['gw_flg'] = 0\n",
    "test['post_gw_flg'] = 0\n",
    "update_gw_list = [[\"0\" for i in range(3)] for j in range(len(gw_list))]\n",
    "update_post_gw_list = [[\"0\" for i in range(3)] for j in range(len(post_gw_list))]\n",
    "\n",
    "from datetime import date\n",
    "for index, gw_date in enumerate(gw_list):\n",
    "    temp_list = gw_date.split(\"-\")\n",
    "    for col_i, temp_figure in enumerate(temp_list):\n",
    "        update_gw_list[index][col_i]=int(temp_figure)\n",
    "        \n",
    "    #print(\"{}  {}  {}\".format(update_list[index][0],update_list[index][1],update_list[index][2]))\n",
    "    \n",
    "for index, gw_date in enumerate(post_gw_list):\n",
    "    temp_list = gw_date.split(\"-\")\n",
    "    for col_i, temp_figure in enumerate(temp_list):\n",
    "        update_post_gw_list[index][col_i]=int(temp_figure)\n",
    "\n",
    "for dataset in combine:\n",
    "    for index in range(len(update_gw_list)):\n",
    "        dataset.loc[dataset.visit_date == date(update_gw_list[index][0],update_gw_list[index][1],update_gw_list[index][2]), 'gw_flg'] = 1\n",
    "        \n",
    "for dataset in combine:\n",
    "    for index in range(len(update_post_gw_list)):\n",
    "        dataset.loc[dataset.visit_date == date(update_post_gw_list[index][0],update_post_gw_list[index][1],update_post_gw_list[index][2]), 'post_gw_flg'] = 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols=['visitors','air_store_id','visit_date','id']\n",
    "y_train=train['visitors']\n",
    "x_train=train.drop(drop_cols, axis=1)\n",
    "\n",
    "x_test=test.copy()\n",
    "x_test=x_test.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.visitors\n",
    "train_input = train.copy()\n",
    "test_input = test.copy()\n",
    "\n",
    "drop_cols=['visitors','air_store_id','visit_date','id']\n",
    "train_input=train_input.drop(drop_cols, axis=1)\n",
    "test_input=test_input.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update precipitation columns (category is not allowed in xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['precipitation'] = train['precipitation'].values.astype(float)\n",
    "test['precipitation'] = test['precipitation'].values.astype(float)\n",
    "\n",
    "train_input['precipitation'] = train_input['precipitation'].values.astype(float)\n",
    "test_input['precipitation'] = test_input['precipitation'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    122377\n",
       "1.0     89720\n",
       "3.0     39986\n",
       "Name: precipitation, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.precipitation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.precipitation.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.precipitation.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a evaluation function\n",
    "\n",
    "def rmsle(preds, true):\n",
    "    rmsle = np.sqrt(mean_squared_error(np.log1p(true), np.log1p(preds)))\n",
    "    return float(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a evaluation matrix \n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "RMSLE = make_scorer(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for comparing predictions and true data.\n",
    "def compare_result(preds, true):\n",
    "    compare = pd.DataFrame({\"test_id\": true.index,\n",
    "                           \"real_cost\": true,\n",
    "                           \"pred_cost\": preds})\n",
    "    compare = compare[[\"test_id\", \"real_cost\", \"pred_cost\"]].reset_index(drop=True)\n",
    "    \n",
    "    compare[\"error_percent_(%)\"] = np.abs(compare.real_cost - compare.pred_cost) / compare.real_cost * 100\n",
    "    \n",
    "    return compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_xgb(params, x_train, y_train, x_test, kf,  verbose=True, verbose_eval=50, scoreonly=False):\n",
    "    start_time=time.time()\n",
    "    nround=[]\n",
    "    # the prediction matrix need to contains 3 columns, one for the probability of each class\n",
    "    #train_pred = np.zeros((x_train.shape[0],3))\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "    \n",
    "    # self-defined eval metric\n",
    "    # f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "    # binary error\n",
    "    def feval_rmsle(preds, train_data):\n",
    "        preds = np.expm1(preds)\n",
    "        true = np.expm1(train_data.get_label())\n",
    "        #return 'rmsle', rmsle(true, preds), False\n",
    "\n",
    "        return 'rmsle', rmsle(preds, true), False\n",
    "\n",
    "    # use the k-fold object to enumerate indexes for each training and validation fold\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[val_index, :]\n",
    "\n",
    "        #y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "        y_train_kf, y_val_kf = np.log1p(y_train[train_index]), np.log1p(y_train[val_index])\n",
    "        x_test_kf=x_test.copy()\n",
    "        \n",
    "        d_train = xgboost.DMatrix(x_train_kf, y_train_kf)\n",
    "        d_val=xgboost.DMatrix(x_val_kf, y_val_kf)\n",
    "        d_test = xgboost.DMatrix(x_test_kf)\n",
    "        \n",
    "        watchlist= [(d_train, \"train\"), (d_val, 'val')]\n",
    "        bst = xgboost.train(params=params, \n",
    "                            dtrain=d_train, \n",
    "                            num_boost_round=8000, \n",
    "                            early_stopping_rounds=100,\n",
    "                            evals=watchlist, \n",
    "                            verbose_eval=verbose_eval)        \n",
    "        \n",
    "#        y_val_kf_preds=bst.predict(d_val, ntree_limit=bst.best_ntree_limit)\n",
    "        y_val_kf_preds=np.expm1(bst.predict(d_val, ntree_limit=bst.best_ntree_limit))\n",
    "        nround.append(bst.best_ntree_limit)\n",
    "        \n",
    "        train_pred[val_index] += y_val_kf_preds\n",
    "#        test_pred += np.expm1((bst.predict(x_test, ntree_limit=bst.best_ntree_limit)))\n",
    "        test_pred += np.expm1(bst.predict(d_test))\n",
    "        \n",
    "        \n",
    "        #fold_cv = log_loss(y_val_kf.values, y_val_kf_preds)\n",
    "        #fold_rmsle = rmsle(np.expm1(train_pred[val_index]),np.expm1(y_val_kf.values))\n",
    "        fold_rmsle = rmsle(train_pred[val_index],np.expm1(y_val_kf.values))\n",
    "        fold_cv = fold_rmsle\n",
    "        \n",
    "        if verbose:\n",
    "            print('fold cv {} rmsle score is {:.6f}'.format(i, fold_cv))\n",
    "\n",
    "    test_pred = test_pred / kf.n_splits\n",
    "    #cv_score = log_loss(y_train, train_pred)\n",
    "    #cv_score = rmsle(np.expm1(train_pred), y_train)\n",
    "    cv_score = rmsle(train_pred, y_train)\n",
    "    \n",
    "    if verbose:\n",
    "        print('cv rmsle score is {:.6f}'.format(cv_score))    \n",
    "        end_time = time.time()\n",
    "        print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n",
    " \n",
    "    if scoreonly:\n",
    "        #return cv_score # for the purpose of bayesian optimisation, we only need to return the CV score\n",
    "        return cv_score\n",
    "    else:\n",
    "        return (cv_score,train_pred,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do 3 fold CV here so that we save some running time on Kaggle Kernel\n",
    "kf=StratifiedKFold(n_splits=10, shuffle=True, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[0]\ttrain-rmse:2.32271\tval-rmse:2.33618\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.525353\tval-rmse:0.535489\n",
      "[100]\ttrain-rmse:0.484562\tval-rmse:0.493073\n",
      "[150]\ttrain-rmse:0.479103\tval-rmse:0.488727\n",
      "[200]\ttrain-rmse:0.475524\tval-rmse:0.486418\n",
      "[250]\ttrain-rmse:0.472913\tval-rmse:0.484755\n",
      "[300]\ttrain-rmse:0.471413\tval-rmse:0.483984\n",
      "[350]\ttrain-rmse:0.469852\tval-rmse:0.483252\n",
      "[400]\ttrain-rmse:0.468346\tval-rmse:0.482637\n",
      "[450]\ttrain-rmse:0.467142\tval-rmse:0.482123\n",
      "[500]\ttrain-rmse:0.466005\tval-rmse:0.481546\n",
      "[550]\ttrain-rmse:0.464944\tval-rmse:0.48125\n",
      "[600]\ttrain-rmse:0.463937\tval-rmse:0.480784\n",
      "[650]\ttrain-rmse:0.462924\tval-rmse:0.480282\n",
      "[700]\ttrain-rmse:0.462074\tval-rmse:0.480044\n",
      "[750]\ttrain-rmse:0.461274\tval-rmse:0.479782\n",
      "[800]\ttrain-rmse:0.460379\tval-rmse:0.479573\n",
      "[850]\ttrain-rmse:0.459529\tval-rmse:0.479353\n",
      "[900]\ttrain-rmse:0.458719\tval-rmse:0.479073\n",
      "[950]\ttrain-rmse:0.458082\tval-rmse:0.478949\n",
      "[1000]\ttrain-rmse:0.45729\tval-rmse:0.478786\n",
      "[1050]\ttrain-rmse:0.45654\tval-rmse:0.478618\n",
      "[1100]\ttrain-rmse:0.455808\tval-rmse:0.478464\n",
      "[1150]\ttrain-rmse:0.455225\tval-rmse:0.478305\n",
      "[1200]\ttrain-rmse:0.454604\tval-rmse:0.478204\n",
      "[1250]\ttrain-rmse:0.454067\tval-rmse:0.478084\n",
      "[1300]\ttrain-rmse:0.453505\tval-rmse:0.477961\n",
      "[1350]\ttrain-rmse:0.452962\tval-rmse:0.477876\n",
      "[1400]\ttrain-rmse:0.452395\tval-rmse:0.477798\n",
      "[1450]\ttrain-rmse:0.45187\tval-rmse:0.477695\n",
      "[1500]\ttrain-rmse:0.451261\tval-rmse:0.477535\n",
      "[1550]\ttrain-rmse:0.450626\tval-rmse:0.477334\n",
      "[1600]\ttrain-rmse:0.450067\tval-rmse:0.477237\n",
      "[1650]\ttrain-rmse:0.449619\tval-rmse:0.477122\n",
      "[1700]\ttrain-rmse:0.449119\tval-rmse:0.477025\n",
      "[1750]\ttrain-rmse:0.448717\tval-rmse:0.476979\n",
      "[1800]\ttrain-rmse:0.448266\tval-rmse:0.476949\n",
      "[1850]\ttrain-rmse:0.447811\tval-rmse:0.476945\n",
      "[1900]\ttrain-rmse:0.447348\tval-rmse:0.476939\n",
      "[1950]\ttrain-rmse:0.446842\tval-rmse:0.476973\n",
      "[2000]\ttrain-rmse:0.446448\tval-rmse:0.476932\n",
      "Stopping. Best iteration:\n",
      "[1905]\ttrain-rmse:0.447261\tval-rmse:0.476916\n",
      "\n",
      "[0]\ttrain-rmse:2.32385\tval-rmse:2.32486\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.526298\tval-rmse:0.529533\n",
      "[100]\ttrain-rmse:0.485343\tval-rmse:0.492175\n",
      "[150]\ttrain-rmse:0.479663\tval-rmse:0.487756\n",
      "[200]\ttrain-rmse:0.475672\tval-rmse:0.484658\n",
      "[250]\ttrain-rmse:0.473024\tval-rmse:0.48303\n",
      "[300]\ttrain-rmse:0.470998\tval-rmse:0.48183\n",
      "[350]\ttrain-rmse:0.469315\tval-rmse:0.480975\n",
      "[400]\ttrain-rmse:0.467721\tval-rmse:0.480164\n",
      "[450]\ttrain-rmse:0.466202\tval-rmse:0.479491\n",
      "[500]\ttrain-rmse:0.464962\tval-rmse:0.478914\n",
      "[550]\ttrain-rmse:0.463798\tval-rmse:0.478341\n",
      "[600]\ttrain-rmse:0.462847\tval-rmse:0.477993\n",
      "[650]\ttrain-rmse:0.461818\tval-rmse:0.477473\n",
      "[700]\ttrain-rmse:0.460824\tval-rmse:0.477181\n",
      "[750]\ttrain-rmse:0.460064\tval-rmse:0.476909\n",
      "[800]\ttrain-rmse:0.4592\tval-rmse:0.476657\n",
      "[850]\ttrain-rmse:0.458408\tval-rmse:0.476321\n",
      "[900]\ttrain-rmse:0.457581\tval-rmse:0.476005\n",
      "[950]\ttrain-rmse:0.456883\tval-rmse:0.475838\n",
      "[1000]\ttrain-rmse:0.456132\tval-rmse:0.475661\n",
      "[1050]\ttrain-rmse:0.455289\tval-rmse:0.475399\n",
      "[1100]\ttrain-rmse:0.454477\tval-rmse:0.475289\n",
      "[1150]\ttrain-rmse:0.453725\tval-rmse:0.475079\n",
      "[1200]\ttrain-rmse:0.452918\tval-rmse:0.474891\n",
      "[1250]\ttrain-rmse:0.452133\tval-rmse:0.474688\n",
      "[1300]\ttrain-rmse:0.451388\tval-rmse:0.474571\n",
      "[1350]\ttrain-rmse:0.450776\tval-rmse:0.474465\n",
      "[1400]\ttrain-rmse:0.450124\tval-rmse:0.474385\n",
      "[1450]\ttrain-rmse:0.449384\tval-rmse:0.474274\n",
      "[1500]\ttrain-rmse:0.448764\tval-rmse:0.47416\n",
      "[1550]\ttrain-rmse:0.448132\tval-rmse:0.474003\n",
      "[1600]\ttrain-rmse:0.447497\tval-rmse:0.473896\n",
      "[1650]\ttrain-rmse:0.446813\tval-rmse:0.473844\n",
      "[1700]\ttrain-rmse:0.44611\tval-rmse:0.473775\n",
      "[1750]\ttrain-rmse:0.445473\tval-rmse:0.473669\n",
      "[1800]\ttrain-rmse:0.444781\tval-rmse:0.473624\n",
      "[1850]\ttrain-rmse:0.444111\tval-rmse:0.473499\n",
      "[1900]\ttrain-rmse:0.44344\tval-rmse:0.473415\n",
      "[1950]\ttrain-rmse:0.442851\tval-rmse:0.473371\n",
      "[2000]\ttrain-rmse:0.442274\tval-rmse:0.473312\n",
      "[2050]\ttrain-rmse:0.441657\tval-rmse:0.473237\n",
      "[2100]\ttrain-rmse:0.441107\tval-rmse:0.473104\n",
      "[2150]\ttrain-rmse:0.440579\tval-rmse:0.473069\n",
      "[2200]\ttrain-rmse:0.440059\tval-rmse:0.473094\n",
      "Stopping. Best iteration:\n",
      "[2130]\ttrain-rmse:0.440771\tval-rmse:0.473057\n",
      "\n",
      "[0]\ttrain-rmse:2.32406\tval-rmse:2.3233\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.526951\tval-rmse:0.527492\n",
      "[100]\ttrain-rmse:0.485578\tval-rmse:0.489542\n",
      "[150]\ttrain-rmse:0.479783\tval-rmse:0.485037\n",
      "[200]\ttrain-rmse:0.476043\tval-rmse:0.482252\n",
      "[250]\ttrain-rmse:0.473372\tval-rmse:0.48036\n",
      "[300]\ttrain-rmse:0.471512\tval-rmse:0.479278\n",
      "[350]\ttrain-rmse:0.469656\tval-rmse:0.478131\n",
      "[400]\ttrain-rmse:0.468043\tval-rmse:0.477319\n",
      "[450]\ttrain-rmse:0.466696\tval-rmse:0.476756\n",
      "[500]\ttrain-rmse:0.465478\tval-rmse:0.476258\n",
      "[550]\ttrain-rmse:0.464545\tval-rmse:0.475779\n",
      "[600]\ttrain-rmse:0.463806\tval-rmse:0.475443\n",
      "[650]\ttrain-rmse:0.463112\tval-rmse:0.475168\n",
      "[700]\ttrain-rmse:0.46255\tval-rmse:0.474958\n",
      "[750]\ttrain-rmse:0.461866\tval-rmse:0.474629\n",
      "[800]\ttrain-rmse:0.461319\tval-rmse:0.474533\n",
      "[850]\ttrain-rmse:0.460942\tval-rmse:0.474441\n",
      "[900]\ttrain-rmse:0.460397\tval-rmse:0.474327\n",
      "[950]\ttrain-rmse:0.459837\tval-rmse:0.474109\n",
      "[1000]\ttrain-rmse:0.459225\tval-rmse:0.473872\n",
      "[1050]\ttrain-rmse:0.458675\tval-rmse:0.473797\n",
      "[1100]\ttrain-rmse:0.458116\tval-rmse:0.473707\n",
      "[1150]\ttrain-rmse:0.457541\tval-rmse:0.473526\n",
      "[1200]\ttrain-rmse:0.456895\tval-rmse:0.47332\n",
      "[1250]\ttrain-rmse:0.456347\tval-rmse:0.473252\n",
      "[1300]\ttrain-rmse:0.456029\tval-rmse:0.473171\n",
      "[1350]\ttrain-rmse:0.455565\tval-rmse:0.473048\n",
      "[1400]\ttrain-rmse:0.45516\tval-rmse:0.472966\n",
      "[1450]\ttrain-rmse:0.454691\tval-rmse:0.472868\n",
      "[1500]\ttrain-rmse:0.454314\tval-rmse:0.472725\n",
      "[1550]\ttrain-rmse:0.453934\tval-rmse:0.47265\n",
      "[1600]\ttrain-rmse:0.45363\tval-rmse:0.47257\n",
      "[1650]\ttrain-rmse:0.453237\tval-rmse:0.472528\n",
      "[1700]\ttrain-rmse:0.45279\tval-rmse:0.472478\n",
      "[1750]\ttrain-rmse:0.452364\tval-rmse:0.472412\n",
      "[1800]\ttrain-rmse:0.452209\tval-rmse:0.472399\n",
      "[1850]\ttrain-rmse:0.451918\tval-rmse:0.472369\n",
      "[1900]\ttrain-rmse:0.45156\tval-rmse:0.472334\n",
      "[1950]\ttrain-rmse:0.451145\tval-rmse:0.472334\n",
      "[2000]\ttrain-rmse:0.450684\tval-rmse:0.472306\n",
      "[2050]\ttrain-rmse:0.450357\tval-rmse:0.472233\n",
      "[2100]\ttrain-rmse:0.450008\tval-rmse:0.472183\n",
      "[2150]\ttrain-rmse:0.449628\tval-rmse:0.472094\n",
      "[2200]\ttrain-rmse:0.449153\tval-rmse:0.472035\n",
      "[2250]\ttrain-rmse:0.448757\tval-rmse:0.472009\n",
      "[2300]\ttrain-rmse:0.448492\tval-rmse:0.471961\n",
      "[2350]\ttrain-rmse:0.448122\tval-rmse:0.471933\n",
      "[2400]\ttrain-rmse:0.447797\tval-rmse:0.47193\n",
      "[2450]\ttrain-rmse:0.447511\tval-rmse:0.471884\n",
      "[2500]\ttrain-rmse:0.447142\tval-rmse:0.471859\n",
      "[2550]\ttrain-rmse:0.446811\tval-rmse:0.471856\n",
      "[2600]\ttrain-rmse:0.446431\tval-rmse:0.471842\n",
      "[2650]\ttrain-rmse:0.446046\tval-rmse:0.471738\n",
      "[2700]\ttrain-rmse:0.445622\tval-rmse:0.471714\n",
      "[2750]\ttrain-rmse:0.445336\tval-rmse:0.471704\n",
      "[2800]\ttrain-rmse:0.444917\tval-rmse:0.471663\n",
      "[2850]\ttrain-rmse:0.44458\tval-rmse:0.471668\n",
      "[2900]\ttrain-rmse:0.444279\tval-rmse:0.471636\n",
      "[2950]\ttrain-rmse:0.443821\tval-rmse:0.471589\n",
      "[3000]\ttrain-rmse:0.443481\tval-rmse:0.47155\n",
      "[3050]\ttrain-rmse:0.443106\tval-rmse:0.471526\n",
      "[3100]\ttrain-rmse:0.442665\tval-rmse:0.471511\n",
      "Stopping. Best iteration:\n",
      "[3021]\ttrain-rmse:0.443301\tval-rmse:0.471497\n",
      "\n",
      "[0]\ttrain-rmse:2.32419\tval-rmse:2.32247\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.527571\tval-rmse:0.528817\n",
      "[100]\ttrain-rmse:0.486072\tval-rmse:0.489372\n",
      "[150]\ttrain-rmse:0.480064\tval-rmse:0.484565\n",
      "[200]\ttrain-rmse:0.476919\tval-rmse:0.482485\n",
      "[250]\ttrain-rmse:0.474681\tval-rmse:0.481074\n",
      "[300]\ttrain-rmse:0.472897\tval-rmse:0.480119\n",
      "[350]\ttrain-rmse:0.471412\tval-rmse:0.479387\n",
      "[400]\ttrain-rmse:0.470093\tval-rmse:0.47868\n",
      "[450]\ttrain-rmse:0.468736\tval-rmse:0.477999\n",
      "[500]\ttrain-rmse:0.467922\tval-rmse:0.47763\n",
      "[550]\ttrain-rmse:0.46722\tval-rmse:0.47729\n",
      "[600]\ttrain-rmse:0.466363\tval-rmse:0.476941\n",
      "[650]\ttrain-rmse:0.465732\tval-rmse:0.476738\n",
      "[700]\ttrain-rmse:0.465015\tval-rmse:0.476402\n",
      "[750]\ttrain-rmse:0.464353\tval-rmse:0.476216\n",
      "[800]\ttrain-rmse:0.463824\tval-rmse:0.475978\n",
      "[850]\ttrain-rmse:0.463293\tval-rmse:0.475758\n",
      "[900]\ttrain-rmse:0.462766\tval-rmse:0.475569\n",
      "[950]\ttrain-rmse:0.462028\tval-rmse:0.475391\n",
      "[1000]\ttrain-rmse:0.461462\tval-rmse:0.475188\n",
      "[1050]\ttrain-rmse:0.460918\tval-rmse:0.475031\n",
      "[1100]\ttrain-rmse:0.460307\tval-rmse:0.474875\n",
      "[1150]\ttrain-rmse:0.459696\tval-rmse:0.474656\n",
      "[1200]\ttrain-rmse:0.459129\tval-rmse:0.474439\n",
      "[1250]\ttrain-rmse:0.458569\tval-rmse:0.474261\n",
      "[1300]\ttrain-rmse:0.457931\tval-rmse:0.474082\n",
      "[1350]\ttrain-rmse:0.457281\tval-rmse:0.47393\n",
      "[1400]\ttrain-rmse:0.456475\tval-rmse:0.473654\n",
      "[1450]\ttrain-rmse:0.455691\tval-rmse:0.473505\n",
      "[1500]\ttrain-rmse:0.454878\tval-rmse:0.473297\n",
      "[1550]\ttrain-rmse:0.454108\tval-rmse:0.473118\n",
      "[1600]\ttrain-rmse:0.453522\tval-rmse:0.472984\n",
      "[1650]\ttrain-rmse:0.452965\tval-rmse:0.472899\n",
      "[1700]\ttrain-rmse:0.452369\tval-rmse:0.472785\n",
      "[1750]\ttrain-rmse:0.451655\tval-rmse:0.472626\n",
      "[1800]\ttrain-rmse:0.451186\tval-rmse:0.472504\n",
      "[1850]\ttrain-rmse:0.450672\tval-rmse:0.472425\n",
      "[1900]\ttrain-rmse:0.450198\tval-rmse:0.472345\n",
      "[1950]\ttrain-rmse:0.44967\tval-rmse:0.472304\n",
      "[2000]\ttrain-rmse:0.449153\tval-rmse:0.47228\n",
      "[2050]\ttrain-rmse:0.448686\tval-rmse:0.472201\n",
      "[2100]\ttrain-rmse:0.448108\tval-rmse:0.472215\n",
      "[2150]\ttrain-rmse:0.447662\tval-rmse:0.472127\n",
      "[2200]\ttrain-rmse:0.447177\tval-rmse:0.47205\n",
      "[2250]\ttrain-rmse:0.446718\tval-rmse:0.47197\n",
      "[2300]\ttrain-rmse:0.44626\tval-rmse:0.471957\n",
      "[2350]\ttrain-rmse:0.44589\tval-rmse:0.471938\n",
      "Stopping. Best iteration:\n",
      "[2266]\ttrain-rmse:0.446517\tval-rmse:0.471908\n",
      "\n",
      "[0]\ttrain-rmse:2.32424\tval-rmse:2.32176\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.526483\tval-rmse:0.52492\n",
      "[100]\ttrain-rmse:0.485358\tval-rmse:0.484568\n",
      "[150]\ttrain-rmse:0.479728\tval-rmse:0.48005\n",
      "[200]\ttrain-rmse:0.476123\tval-rmse:0.477612\n",
      "[250]\ttrain-rmse:0.473535\tval-rmse:0.47596\n",
      "[300]\ttrain-rmse:0.471569\tval-rmse:0.474975\n",
      "[350]\ttrain-rmse:0.469848\tval-rmse:0.473963\n",
      "[400]\ttrain-rmse:0.468242\tval-rmse:0.473068\n",
      "[450]\ttrain-rmse:0.466719\tval-rmse:0.472321\n",
      "[500]\ttrain-rmse:0.46569\tval-rmse:0.471925\n",
      "[550]\ttrain-rmse:0.464583\tval-rmse:0.471514\n",
      "[600]\ttrain-rmse:0.463732\tval-rmse:0.471157\n",
      "[650]\ttrain-rmse:0.462972\tval-rmse:0.470859\n",
      "[700]\ttrain-rmse:0.462442\tval-rmse:0.470733\n",
      "[750]\ttrain-rmse:0.461955\tval-rmse:0.470547\n",
      "[800]\ttrain-rmse:0.461412\tval-rmse:0.470383\n",
      "[850]\ttrain-rmse:0.460944\tval-rmse:0.470184\n",
      "[900]\ttrain-rmse:0.460317\tval-rmse:0.469988\n",
      "[950]\ttrain-rmse:0.45968\tval-rmse:0.469776\n",
      "[1000]\ttrain-rmse:0.459103\tval-rmse:0.469589\n",
      "[1050]\ttrain-rmse:0.458625\tval-rmse:0.469402\n",
      "[1100]\ttrain-rmse:0.458088\tval-rmse:0.469247\n",
      "[1150]\ttrain-rmse:0.457537\tval-rmse:0.469104\n",
      "[1200]\ttrain-rmse:0.457125\tval-rmse:0.469\n",
      "[1250]\ttrain-rmse:0.456738\tval-rmse:0.46888\n",
      "[1300]\ttrain-rmse:0.456366\tval-rmse:0.468804\n",
      "[1350]\ttrain-rmse:0.455862\tval-rmse:0.468596\n",
      "[1400]\ttrain-rmse:0.45546\tval-rmse:0.468489\n",
      "[1450]\ttrain-rmse:0.455033\tval-rmse:0.468294\n",
      "[1500]\ttrain-rmse:0.454643\tval-rmse:0.46824\n",
      "[1550]\ttrain-rmse:0.454257\tval-rmse:0.468139\n",
      "[1600]\ttrain-rmse:0.453902\tval-rmse:0.468077\n",
      "[1650]\ttrain-rmse:0.453241\tval-rmse:0.46783\n",
      "[1700]\ttrain-rmse:0.452903\tval-rmse:0.467827\n",
      "[1750]\ttrain-rmse:0.452469\tval-rmse:0.467726\n",
      "[1800]\ttrain-rmse:0.452177\tval-rmse:0.467662\n",
      "[1850]\ttrain-rmse:0.451695\tval-rmse:0.467556\n",
      "[1900]\ttrain-rmse:0.451226\tval-rmse:0.467446\n",
      "[1950]\ttrain-rmse:0.450874\tval-rmse:0.467379\n",
      "[2000]\ttrain-rmse:0.450462\tval-rmse:0.467262\n",
      "[2050]\ttrain-rmse:0.449949\tval-rmse:0.467157\n",
      "[2100]\ttrain-rmse:0.449492\tval-rmse:0.467024\n",
      "[2150]\ttrain-rmse:0.448994\tval-rmse:0.466901\n",
      "[2200]\ttrain-rmse:0.44851\tval-rmse:0.466878\n",
      "[2250]\ttrain-rmse:0.448091\tval-rmse:0.466772\n",
      "[2300]\ttrain-rmse:0.44764\tval-rmse:0.466736\n",
      "[2350]\ttrain-rmse:0.447123\tval-rmse:0.466587\n",
      "[2400]\ttrain-rmse:0.446715\tval-rmse:0.46653\n",
      "[2450]\ttrain-rmse:0.446361\tval-rmse:0.466432\n",
      "[2500]\ttrain-rmse:0.445875\tval-rmse:0.466402\n",
      "[2550]\ttrain-rmse:0.445505\tval-rmse:0.466347\n",
      "[2600]\ttrain-rmse:0.445053\tval-rmse:0.46631\n",
      "[2650]\ttrain-rmse:0.44469\tval-rmse:0.466265\n",
      "[2700]\ttrain-rmse:0.44429\tval-rmse:0.466231\n",
      "[2750]\ttrain-rmse:0.443816\tval-rmse:0.466181\n",
      "[2800]\ttrain-rmse:0.443349\tval-rmse:0.466094\n",
      "[2850]\ttrain-rmse:0.44303\tval-rmse:0.466022\n",
      "[2900]\ttrain-rmse:0.442717\tval-rmse:0.46603\n",
      "[2950]\ttrain-rmse:0.442394\tval-rmse:0.466013\n",
      "[3000]\ttrain-rmse:0.442041\tval-rmse:0.465917\n",
      "[3050]\ttrain-rmse:0.441569\tval-rmse:0.465881\n",
      "[3100]\ttrain-rmse:0.441109\tval-rmse:0.46588\n",
      "[3150]\ttrain-rmse:0.440678\tval-rmse:0.465752\n",
      "[3200]\ttrain-rmse:0.44023\tval-rmse:0.465703\n",
      "[3250]\ttrain-rmse:0.439878\tval-rmse:0.465657\n",
      "[3300]\ttrain-rmse:0.439515\tval-rmse:0.465627\n",
      "[3350]\ttrain-rmse:0.439106\tval-rmse:0.465674\n",
      "[3400]\ttrain-rmse:0.438736\tval-rmse:0.465664\n",
      "Stopping. Best iteration:\n",
      "[3307]\ttrain-rmse:0.439437\tval-rmse:0.465621\n",
      "\n",
      "[0]\ttrain-rmse:2.3242\tval-rmse:2.32248\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.527036\tval-rmse:0.52765\n",
      "[100]\ttrain-rmse:0.48597\tval-rmse:0.488974\n",
      "[150]\ttrain-rmse:0.480071\tval-rmse:0.484509\n",
      "[200]\ttrain-rmse:0.476088\tval-rmse:0.481726\n",
      "[250]\ttrain-rmse:0.473439\tval-rmse:0.480101\n",
      "[300]\ttrain-rmse:0.471534\tval-rmse:0.478997\n",
      "[350]\ttrain-rmse:0.469872\tval-rmse:0.478152\n",
      "[400]\ttrain-rmse:0.468385\tval-rmse:0.477481\n",
      "[450]\ttrain-rmse:0.466957\tval-rmse:0.476877\n",
      "[500]\ttrain-rmse:0.465658\tval-rmse:0.476349\n",
      "[550]\ttrain-rmse:0.464766\tval-rmse:0.476027\n",
      "[600]\ttrain-rmse:0.463788\tval-rmse:0.475672\n",
      "[650]\ttrain-rmse:0.463048\tval-rmse:0.475485\n",
      "[700]\ttrain-rmse:0.462463\tval-rmse:0.475338\n",
      "[750]\ttrain-rmse:0.461946\tval-rmse:0.475123\n",
      "[800]\ttrain-rmse:0.461489\tval-rmse:0.474973\n",
      "[850]\ttrain-rmse:0.460918\tval-rmse:0.474843\n",
      "[900]\ttrain-rmse:0.460294\tval-rmse:0.47465\n",
      "[950]\ttrain-rmse:0.459918\tval-rmse:0.474511\n",
      "[1000]\ttrain-rmse:0.459575\tval-rmse:0.474393\n",
      "[1050]\ttrain-rmse:0.459081\tval-rmse:0.474249\n",
      "[1100]\ttrain-rmse:0.45867\tval-rmse:0.474124\n",
      "[1150]\ttrain-rmse:0.458298\tval-rmse:0.474089\n",
      "[1200]\ttrain-rmse:0.45784\tval-rmse:0.473968\n",
      "[1250]\ttrain-rmse:0.457451\tval-rmse:0.473874\n",
      "[1300]\ttrain-rmse:0.457023\tval-rmse:0.473759\n",
      "[1350]\ttrain-rmse:0.456686\tval-rmse:0.473645\n",
      "[1400]\ttrain-rmse:0.456271\tval-rmse:0.473585\n",
      "[1450]\ttrain-rmse:0.455854\tval-rmse:0.473468\n",
      "[1500]\ttrain-rmse:0.455459\tval-rmse:0.473367\n",
      "[1550]\ttrain-rmse:0.455047\tval-rmse:0.473308\n",
      "[1600]\ttrain-rmse:0.454622\tval-rmse:0.473263\n",
      "[1650]\ttrain-rmse:0.454202\tval-rmse:0.473214\n",
      "[1700]\ttrain-rmse:0.453888\tval-rmse:0.473141\n",
      "[1750]\ttrain-rmse:0.453344\tval-rmse:0.47304\n",
      "[1800]\ttrain-rmse:0.452825\tval-rmse:0.472902\n",
      "[1850]\ttrain-rmse:0.452345\tval-rmse:0.472739\n",
      "[1900]\ttrain-rmse:0.451932\tval-rmse:0.472724\n",
      "[1950]\ttrain-rmse:0.451522\tval-rmse:0.472745\n",
      "[2000]\ttrain-rmse:0.451234\tval-rmse:0.472673\n",
      "[2050]\ttrain-rmse:0.450751\tval-rmse:0.472626\n",
      "[2100]\ttrain-rmse:0.450296\tval-rmse:0.472558\n",
      "[2150]\ttrain-rmse:0.45001\tval-rmse:0.472571\n",
      "[2200]\ttrain-rmse:0.449574\tval-rmse:0.472525\n",
      "[2250]\ttrain-rmse:0.449202\tval-rmse:0.472448\n",
      "[2300]\ttrain-rmse:0.448859\tval-rmse:0.472401\n",
      "[2350]\ttrain-rmse:0.44845\tval-rmse:0.472306\n",
      "[2400]\ttrain-rmse:0.448075\tval-rmse:0.472293\n",
      "[2450]\ttrain-rmse:0.44774\tval-rmse:0.472249\n",
      "[2500]\ttrain-rmse:0.447415\tval-rmse:0.472217\n",
      "[2550]\ttrain-rmse:0.446975\tval-rmse:0.472158\n",
      "[2600]\ttrain-rmse:0.446646\tval-rmse:0.472135\n",
      "[2650]\ttrain-rmse:0.446327\tval-rmse:0.472109\n",
      "[2700]\ttrain-rmse:0.446104\tval-rmse:0.472069\n",
      "[2750]\ttrain-rmse:0.445802\tval-rmse:0.472035\n",
      "[2800]\ttrain-rmse:0.445406\tval-rmse:0.472074\n",
      "[2850]\ttrain-rmse:0.445075\tval-rmse:0.472054\n",
      "[2900]\ttrain-rmse:0.444757\tval-rmse:0.472055\n",
      "[2950]\ttrain-rmse:0.444504\tval-rmse:0.472008\n",
      "[3000]\ttrain-rmse:0.444245\tval-rmse:0.471998\n",
      "[3050]\ttrain-rmse:0.443925\tval-rmse:0.471999\n",
      "Stopping. Best iteration:\n",
      "[2970]\ttrain-rmse:0.444403\tval-rmse:0.471981\n",
      "\n",
      "[0]\ttrain-rmse:2.32426\tval-rmse:2.32154\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.525928\tval-rmse:0.529004\n",
      "[100]\ttrain-rmse:0.485422\tval-rmse:0.489995\n",
      "[150]\ttrain-rmse:0.479673\tval-rmse:0.485168\n",
      "[200]\ttrain-rmse:0.475816\tval-rmse:0.482345\n",
      "[250]\ttrain-rmse:0.473127\tval-rmse:0.480453\n",
      "[300]\ttrain-rmse:0.471113\tval-rmse:0.479163\n",
      "[350]\ttrain-rmse:0.469472\tval-rmse:0.478252\n",
      "[400]\ttrain-rmse:0.467817\tval-rmse:0.477388\n",
      "[450]\ttrain-rmse:0.466181\tval-rmse:0.47649\n",
      "[500]\ttrain-rmse:0.464968\tval-rmse:0.475982\n",
      "[550]\ttrain-rmse:0.463851\tval-rmse:0.475665\n",
      "[600]\ttrain-rmse:0.462613\tval-rmse:0.475202\n",
      "[650]\ttrain-rmse:0.461525\tval-rmse:0.474815\n",
      "[700]\ttrain-rmse:0.460619\tval-rmse:0.474564\n",
      "[750]\ttrain-rmse:0.459817\tval-rmse:0.474267\n",
      "[800]\ttrain-rmse:0.458815\tval-rmse:0.473894\n",
      "[850]\ttrain-rmse:0.458033\tval-rmse:0.473612\n",
      "[900]\ttrain-rmse:0.457401\tval-rmse:0.473427\n",
      "[950]\ttrain-rmse:0.456783\tval-rmse:0.473282\n",
      "[1000]\ttrain-rmse:0.456119\tval-rmse:0.473109\n",
      "[1050]\ttrain-rmse:0.455441\tval-rmse:0.472859\n",
      "[1100]\ttrain-rmse:0.454761\tval-rmse:0.472572\n",
      "[1150]\ttrain-rmse:0.454138\tval-rmse:0.472482\n",
      "[1200]\ttrain-rmse:0.45364\tval-rmse:0.472351\n",
      "[1250]\ttrain-rmse:0.45285\tval-rmse:0.472124\n",
      "[1300]\ttrain-rmse:0.452277\tval-rmse:0.472021\n",
      "[1350]\ttrain-rmse:0.451665\tval-rmse:0.471804\n",
      "[1400]\ttrain-rmse:0.451085\tval-rmse:0.471695\n",
      "[1450]\ttrain-rmse:0.450501\tval-rmse:0.471571\n",
      "[1500]\ttrain-rmse:0.449866\tval-rmse:0.471466\n",
      "[1550]\ttrain-rmse:0.449237\tval-rmse:0.471345\n",
      "[1600]\ttrain-rmse:0.448739\tval-rmse:0.471211\n",
      "[1650]\ttrain-rmse:0.448222\tval-rmse:0.471108\n",
      "[1700]\ttrain-rmse:0.447639\tval-rmse:0.471046\n",
      "[1750]\ttrain-rmse:0.446999\tval-rmse:0.470986\n",
      "[1800]\ttrain-rmse:0.446412\tval-rmse:0.470948\n",
      "[1850]\ttrain-rmse:0.445834\tval-rmse:0.470845\n",
      "[1900]\ttrain-rmse:0.445279\tval-rmse:0.470792\n",
      "[1950]\ttrain-rmse:0.444749\tval-rmse:0.470733\n",
      "[2000]\ttrain-rmse:0.444233\tval-rmse:0.470619\n",
      "[2050]\ttrain-rmse:0.443616\tval-rmse:0.470523\n",
      "[2100]\ttrain-rmse:0.443022\tval-rmse:0.470398\n",
      "[2150]\ttrain-rmse:0.442471\tval-rmse:0.470368\n",
      "[2200]\ttrain-rmse:0.441921\tval-rmse:0.470316\n",
      "[2250]\ttrain-rmse:0.44139\tval-rmse:0.470331\n",
      "[2300]\ttrain-rmse:0.440849\tval-rmse:0.470252\n",
      "[2350]\ttrain-rmse:0.440372\tval-rmse:0.470169\n",
      "[2400]\ttrain-rmse:0.439852\tval-rmse:0.470165\n",
      "[2450]\ttrain-rmse:0.439303\tval-rmse:0.470103\n",
      "[2500]\ttrain-rmse:0.438884\tval-rmse:0.470093\n",
      "[2550]\ttrain-rmse:0.438399\tval-rmse:0.470077\n",
      "[2600]\ttrain-rmse:0.43794\tval-rmse:0.470074\n",
      "[2650]\ttrain-rmse:0.437394\tval-rmse:0.47\n",
      "[2700]\ttrain-rmse:0.436859\tval-rmse:0.469984\n",
      "[2750]\ttrain-rmse:0.436354\tval-rmse:0.469952\n",
      "[2800]\ttrain-rmse:0.43583\tval-rmse:0.469981\n",
      "[2850]\ttrain-rmse:0.435294\tval-rmse:0.469988\n",
      "Stopping. Best iteration:\n",
      "[2756]\ttrain-rmse:0.436279\tval-rmse:0.469933\n",
      "\n",
      "[0]\ttrain-rmse:2.32391\tval-rmse:2.32476\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.526894\tval-rmse:0.527938\n",
      "[100]\ttrain-rmse:0.485859\tval-rmse:0.487039\n",
      "[150]\ttrain-rmse:0.480207\tval-rmse:0.482011\n",
      "[200]\ttrain-rmse:0.476513\tval-rmse:0.479082\n",
      "[250]\ttrain-rmse:0.473897\tval-rmse:0.477209\n",
      "[300]\ttrain-rmse:0.472084\tval-rmse:0.476145\n",
      "[350]\ttrain-rmse:0.470329\tval-rmse:0.475126\n",
      "[400]\ttrain-rmse:0.469021\tval-rmse:0.474515\n",
      "[450]\ttrain-rmse:0.467754\tval-rmse:0.473917\n",
      "[500]\ttrain-rmse:0.466546\tval-rmse:0.473281\n",
      "[550]\ttrain-rmse:0.46552\tval-rmse:0.472827\n",
      "[600]\ttrain-rmse:0.46459\tval-rmse:0.47247\n",
      "[650]\ttrain-rmse:0.463569\tval-rmse:0.472004\n",
      "[700]\ttrain-rmse:0.462718\tval-rmse:0.471722\n",
      "[750]\ttrain-rmse:0.462022\tval-rmse:0.471513\n",
      "[800]\ttrain-rmse:0.461049\tval-rmse:0.471183\n",
      "[850]\ttrain-rmse:0.460391\tval-rmse:0.471048\n",
      "[900]\ttrain-rmse:0.459832\tval-rmse:0.470858\n",
      "[950]\ttrain-rmse:0.459281\tval-rmse:0.470717\n",
      "[1000]\ttrain-rmse:0.458714\tval-rmse:0.470508\n",
      "[1050]\ttrain-rmse:0.458173\tval-rmse:0.470335\n",
      "[1100]\ttrain-rmse:0.457501\tval-rmse:0.470116\n",
      "[1150]\ttrain-rmse:0.456951\tval-rmse:0.469986\n",
      "[1200]\ttrain-rmse:0.456475\tval-rmse:0.469889\n",
      "[1250]\ttrain-rmse:0.455893\tval-rmse:0.469711\n",
      "[1300]\ttrain-rmse:0.455402\tval-rmse:0.469612\n",
      "[1350]\ttrain-rmse:0.455011\tval-rmse:0.469503\n",
      "[1400]\ttrain-rmse:0.454458\tval-rmse:0.469354\n",
      "[1450]\ttrain-rmse:0.453822\tval-rmse:0.469229\n",
      "[1500]\ttrain-rmse:0.453436\tval-rmse:0.469186\n",
      "[1550]\ttrain-rmse:0.453005\tval-rmse:0.46911\n",
      "[1600]\ttrain-rmse:0.452554\tval-rmse:0.468987\n",
      "[1650]\ttrain-rmse:0.452085\tval-rmse:0.468894\n",
      "[1700]\ttrain-rmse:0.451601\tval-rmse:0.468867\n",
      "[1750]\ttrain-rmse:0.451047\tval-rmse:0.468794\n",
      "[1800]\ttrain-rmse:0.450612\tval-rmse:0.468729\n",
      "[1850]\ttrain-rmse:0.450094\tval-rmse:0.468588\n",
      "[1900]\ttrain-rmse:0.449554\tval-rmse:0.468506\n",
      "[1950]\ttrain-rmse:0.449122\tval-rmse:0.468441\n",
      "[2000]\ttrain-rmse:0.44857\tval-rmse:0.468369\n",
      "[2050]\ttrain-rmse:0.448078\tval-rmse:0.468208\n",
      "[2100]\ttrain-rmse:0.4476\tval-rmse:0.468107\n",
      "[2150]\ttrain-rmse:0.447083\tval-rmse:0.468094\n",
      "[2200]\ttrain-rmse:0.446664\tval-rmse:0.468063\n",
      "[2250]\ttrain-rmse:0.446203\tval-rmse:0.46797\n",
      "[2300]\ttrain-rmse:0.44567\tval-rmse:0.46781\n",
      "[2350]\ttrain-rmse:0.445264\tval-rmse:0.467789\n",
      "[2400]\ttrain-rmse:0.444833\tval-rmse:0.467748\n",
      "[2450]\ttrain-rmse:0.444393\tval-rmse:0.467743\n",
      "[2500]\ttrain-rmse:0.443964\tval-rmse:0.46777\n",
      "[2550]\ttrain-rmse:0.443455\tval-rmse:0.467765\n",
      "Stopping. Best iteration:\n",
      "[2458]\ttrain-rmse:0.444305\tval-rmse:0.46772\n",
      "\n",
      "[0]\ttrain-rmse:2.3242\tval-rmse:2.32234\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.52681\tval-rmse:0.526675\n",
      "[100]\ttrain-rmse:0.485358\tval-rmse:0.486755\n",
      "[150]\ttrain-rmse:0.479503\tval-rmse:0.482211\n",
      "[200]\ttrain-rmse:0.47582\tval-rmse:0.479801\n",
      "[250]\ttrain-rmse:0.473768\tval-rmse:0.478654\n",
      "[300]\ttrain-rmse:0.472366\tval-rmse:0.477867\n",
      "[350]\ttrain-rmse:0.471029\tval-rmse:0.477194\n",
      "[400]\ttrain-rmse:0.470286\tval-rmse:0.476838\n",
      "[450]\ttrain-rmse:0.469169\tval-rmse:0.476302\n",
      "[500]\ttrain-rmse:0.468179\tval-rmse:0.475986\n",
      "[550]\ttrain-rmse:0.467117\tval-rmse:0.4755\n",
      "[600]\ttrain-rmse:0.466337\tval-rmse:0.475203\n",
      "[650]\ttrain-rmse:0.465392\tval-rmse:0.474815\n",
      "[700]\ttrain-rmse:0.464608\tval-rmse:0.474532\n",
      "[750]\ttrain-rmse:0.463801\tval-rmse:0.474177\n",
      "[800]\ttrain-rmse:0.463168\tval-rmse:0.47397\n",
      "[850]\ttrain-rmse:0.462586\tval-rmse:0.473704\n",
      "[900]\ttrain-rmse:0.462027\tval-rmse:0.473489\n",
      "[950]\ttrain-rmse:0.461617\tval-rmse:0.473467\n",
      "[1000]\ttrain-rmse:0.461043\tval-rmse:0.473338\n",
      "[1050]\ttrain-rmse:0.460558\tval-rmse:0.473147\n",
      "[1100]\ttrain-rmse:0.459902\tval-rmse:0.47299\n",
      "[1150]\ttrain-rmse:0.459454\tval-rmse:0.472851\n",
      "[1200]\ttrain-rmse:0.459031\tval-rmse:0.47275\n",
      "[1250]\ttrain-rmse:0.458734\tval-rmse:0.472699\n",
      "[1300]\ttrain-rmse:0.458181\tval-rmse:0.47258\n",
      "[1350]\ttrain-rmse:0.457628\tval-rmse:0.472479\n",
      "[1400]\ttrain-rmse:0.457268\tval-rmse:0.472408\n",
      "[1450]\ttrain-rmse:0.456778\tval-rmse:0.472268\n",
      "[1500]\ttrain-rmse:0.456563\tval-rmse:0.472218\n",
      "[1550]\ttrain-rmse:0.456191\tval-rmse:0.472142\n",
      "[1600]\ttrain-rmse:0.455778\tval-rmse:0.472004\n",
      "[1650]\ttrain-rmse:0.455422\tval-rmse:0.471905\n",
      "[1700]\ttrain-rmse:0.454876\tval-rmse:0.471788\n",
      "[1750]\ttrain-rmse:0.454536\tval-rmse:0.471734\n",
      "[1800]\ttrain-rmse:0.454222\tval-rmse:0.471708\n",
      "[1850]\ttrain-rmse:0.453796\tval-rmse:0.471615\n",
      "[1900]\ttrain-rmse:0.453405\tval-rmse:0.471489\n",
      "[1950]\ttrain-rmse:0.452984\tval-rmse:0.471404\n",
      "[2000]\ttrain-rmse:0.452528\tval-rmse:0.471386\n",
      "[2050]\ttrain-rmse:0.452215\tval-rmse:0.471339\n",
      "[2100]\ttrain-rmse:0.451772\tval-rmse:0.471223\n",
      "[2150]\ttrain-rmse:0.451385\tval-rmse:0.471191\n",
      "[2200]\ttrain-rmse:0.451017\tval-rmse:0.471096\n",
      "[2250]\ttrain-rmse:0.450804\tval-rmse:0.471101\n",
      "[2300]\ttrain-rmse:0.45044\tval-rmse:0.471051\n",
      "[2350]\ttrain-rmse:0.450131\tval-rmse:0.470993\n",
      "[2400]\ttrain-rmse:0.449767\tval-rmse:0.470865\n",
      "[2450]\ttrain-rmse:0.449427\tval-rmse:0.470813\n",
      "[2500]\ttrain-rmse:0.449034\tval-rmse:0.47078\n",
      "[2550]\ttrain-rmse:0.448663\tval-rmse:0.470687\n",
      "[2600]\ttrain-rmse:0.448326\tval-rmse:0.470673\n",
      "[2650]\ttrain-rmse:0.447953\tval-rmse:0.470605\n",
      "[2700]\ttrain-rmse:0.44767\tval-rmse:0.470556\n",
      "[2750]\ttrain-rmse:0.447281\tval-rmse:0.470485\n",
      "[2800]\ttrain-rmse:0.44701\tval-rmse:0.470528\n",
      "[2850]\ttrain-rmse:0.446773\tval-rmse:0.470481\n",
      "Stopping. Best iteration:\n",
      "[2759]\ttrain-rmse:0.447214\tval-rmse:0.47047\n",
      "\n",
      "[0]\ttrain-rmse:2.32447\tval-rmse:2.32032\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.526951\tval-rmse:0.525888\n",
      "[100]\ttrain-rmse:0.485965\tval-rmse:0.484798\n",
      "[150]\ttrain-rmse:0.48038\tval-rmse:0.480006\n",
      "[200]\ttrain-rmse:0.476843\tval-rmse:0.477341\n",
      "[250]\ttrain-rmse:0.474295\tval-rmse:0.475539\n",
      "[300]\ttrain-rmse:0.472352\tval-rmse:0.474259\n",
      "[350]\ttrain-rmse:0.471009\tval-rmse:0.473496\n",
      "[400]\ttrain-rmse:0.46974\tval-rmse:0.472878\n",
      "[450]\ttrain-rmse:0.468842\tval-rmse:0.472471\n",
      "[500]\ttrain-rmse:0.467951\tval-rmse:0.472111\n",
      "[550]\ttrain-rmse:0.466785\tval-rmse:0.471569\n",
      "[600]\ttrain-rmse:0.465833\tval-rmse:0.471045\n",
      "[650]\ttrain-rmse:0.464849\tval-rmse:0.470496\n",
      "[700]\ttrain-rmse:0.464046\tval-rmse:0.470202\n",
      "[750]\ttrain-rmse:0.463089\tval-rmse:0.469765\n",
      "[800]\ttrain-rmse:0.462111\tval-rmse:0.469355\n",
      "[850]\ttrain-rmse:0.461334\tval-rmse:0.469045\n",
      "[900]\ttrain-rmse:0.460709\tval-rmse:0.46874\n",
      "[950]\ttrain-rmse:0.460029\tval-rmse:0.468515\n",
      "[1000]\ttrain-rmse:0.459402\tval-rmse:0.468311\n",
      "[1050]\ttrain-rmse:0.458815\tval-rmse:0.468156\n",
      "[1100]\ttrain-rmse:0.458244\tval-rmse:0.46795\n",
      "[1150]\ttrain-rmse:0.457815\tval-rmse:0.467855\n",
      "[1200]\ttrain-rmse:0.457099\tval-rmse:0.467704\n",
      "[1250]\ttrain-rmse:0.456539\tval-rmse:0.467599\n",
      "[1300]\ttrain-rmse:0.456062\tval-rmse:0.467455\n",
      "[1350]\ttrain-rmse:0.455634\tval-rmse:0.467317\n",
      "[1400]\ttrain-rmse:0.455099\tval-rmse:0.467211\n",
      "[1450]\ttrain-rmse:0.454676\tval-rmse:0.467111\n",
      "[1500]\ttrain-rmse:0.454178\tval-rmse:0.467017\n",
      "[1550]\ttrain-rmse:0.453572\tval-rmse:0.466935\n",
      "[1600]\ttrain-rmse:0.453246\tval-rmse:0.46687\n",
      "[1650]\ttrain-rmse:0.452843\tval-rmse:0.46683\n",
      "[1700]\ttrain-rmse:0.452314\tval-rmse:0.466657\n",
      "[1750]\ttrain-rmse:0.45192\tval-rmse:0.466605\n",
      "[1800]\ttrain-rmse:0.451518\tval-rmse:0.466433\n",
      "[1850]\ttrain-rmse:0.451088\tval-rmse:0.466371\n",
      "[1900]\ttrain-rmse:0.450638\tval-rmse:0.466291\n",
      "[1950]\ttrain-rmse:0.45022\tval-rmse:0.466253\n",
      "[2000]\ttrain-rmse:0.44984\tval-rmse:0.466212\n",
      "[2050]\ttrain-rmse:0.449398\tval-rmse:0.466054\n",
      "[2100]\ttrain-rmse:0.449012\tval-rmse:0.465996\n",
      "[2150]\ttrain-rmse:0.448666\tval-rmse:0.465908\n",
      "[2200]\ttrain-rmse:0.448213\tval-rmse:0.465827\n",
      "[2250]\ttrain-rmse:0.447888\tval-rmse:0.465782\n",
      "[2300]\ttrain-rmse:0.44755\tval-rmse:0.465751\n",
      "[2350]\ttrain-rmse:0.447283\tval-rmse:0.465724\n",
      "[2400]\ttrain-rmse:0.446802\tval-rmse:0.465626\n",
      "[2450]\ttrain-rmse:0.446422\tval-rmse:0.465596\n",
      "[2500]\ttrain-rmse:0.446054\tval-rmse:0.465591\n",
      "[2550]\ttrain-rmse:0.445652\tval-rmse:0.465507\n",
      "[2600]\ttrain-rmse:0.445187\tval-rmse:0.465457\n",
      "[2650]\ttrain-rmse:0.4448\tval-rmse:0.465402\n",
      "[2700]\ttrain-rmse:0.444404\tval-rmse:0.465402\n",
      "[2750]\ttrain-rmse:0.444115\tval-rmse:0.465398\n",
      "[2800]\ttrain-rmse:0.443808\tval-rmse:0.465392\n",
      "Stopping. Best iteration:\n",
      "[2726]\ttrain-rmse:0.444259\tval-rmse:0.465361\n",
      "\n",
      "cv score is 0.470464\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \"objective\" : \"reg:linear\",\n",
    "    #\"num_class\" : 3,\n",
    "    #\"tree_method\" : \"hist\",\n",
    "    \"eval_metric\" : \"rmse\",\n",
    "    \"nthread\": 4,\n",
    "    \"seed\" : 0,\n",
    "    'silent': 1,\n",
    "\n",
    "    \"eta\":0.05,  # default 0.3\n",
    "    \"max_depth\" : 5, # default 6\n",
    "    \"subsample\" : 0.8, # default 1\n",
    "    \"colsample_bytree\" : 0.6, # default 1\n",
    "    \"gamma\": 0.5\n",
    "}\n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "cv_score =cross_validate_xgb(xgb_params, train_input, y, test_input, kf, verbose=False, verbose_eval=50, scoreonly=True)\n",
    "\n",
    "print('cv score is {:.6f}'.format(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimsation - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'max_depth':(4,10),\n",
    "        'learning_rate':(0.05,0.3),\n",
    "        'subsample': (0.4, 1),\n",
    "        'colsample_bytree': (0.4, 1),\n",
    "        'gamma': (0.001, 10.0),\n",
    "        'min_child_weight': (0, 20),\n",
    "        'max_delta_step': (0, 10),\n",
    "        'n_estimators': (10, 25),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'max_features': (0.1, 0.999)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(xgb_wrapper)\n",
    "def xgbcv_func(max_depth, learning_rate, subsample, \n",
    "               colsample_bytree, gamma, min_child_weight, \n",
    "               max_delta_step, n_estimators, \n",
    "               min_samples_split, max_features,nthread=4, seed=0):\n",
    "    params = {\n",
    "        \"objective\" : \"reg:linear\",\n",
    "        #\"num_class\" : 3,\n",
    "        #\"tree_method\" : \"hist\",\n",
    "        \"eval_metric\" : \"rmse\",\n",
    "        \"nthread\": nthread,\n",
    "        \"seed\" : 0,\n",
    "        'silent': 1,\n",
    "\n",
    "        \"eta\":learning_rate,  # default 0.3\n",
    "        \"max_depth\" : int(max_depth), # default 6\n",
    "        \"subsample\" : subsample, # default 1\n",
    "        \"colsample_bytree\" : colsample_bytree, # default 1\n",
    "\n",
    "        'gamma': gamma,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'max_delta_step': max_delta_step,\n",
    "        'n_estimators': n_estimators,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'max_features': max_features    \n",
    "\n",
    "    }\n",
    "    \n",
    "    # for a more ideal out-of-fold model prediction for this dataset, we use 10-fold CV\n",
    "    kf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "    \n",
    "    # we will disable all the verbose setting in this functional call, so that we don't have too much information \n",
    "    # to read during the bayesian optimisation process.\n",
    "    return 1-cross_validate_xgb(params, train_input, y, test_input, kf, verbose=False, verbose_eval=False, scoreonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo=BayesianOptimization(xgbcv_func, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   learning_rate |   max_delta_step |   max_depth |   max_features |   min_child_weight |   min_samples_split |   n_estimators |   subsample | \n",
      "    1 | 07m15s | \u001b[35m   0.52631\u001b[0m | \u001b[32m            0.7334\u001b[0m | \u001b[32m   1.5532\u001b[0m | \u001b[32m         0.2386\u001b[0m | \u001b[32m          7.0350\u001b[0m | \u001b[32m     6.9391\u001b[0m | \u001b[32m        0.9559\u001b[0m | \u001b[32m            1.3978\u001b[0m | \u001b[32m             9.6175\u001b[0m | \u001b[32m       17.8681\u001b[0m | \u001b[32m     0.8622\u001b[0m | \n",
      "    2 | 14m23s |    0.51893 |             0.7855 |    9.1125 |          0.2584 |           6.3987 |      4.2793 |         0.7461 |            16.7874 |              5.2534 |        17.5612 |      0.6033 | \n",
      "    3 | 20m18s |    0.52433 |             0.7342 |    7.1192 |          0.1500 |           5.1049 |      7.0226 |         0.4314 |             9.2539 |             19.6877 |        21.5452 |      0.9660 | \n",
      "    4 | 17m22s | \u001b[35m   0.52664\u001b[0m | \u001b[32m            0.9476\u001b[0m | \u001b[32m   3.3280\u001b[0m | \u001b[32m         0.2521\u001b[0m | \u001b[32m          4.1114\u001b[0m | \u001b[32m     9.6761\u001b[0m | \u001b[32m        0.2418\u001b[0m | \u001b[32m           19.9124\u001b[0m | \u001b[32m            11.1118\u001b[0m | \u001b[32m       10.7187\u001b[0m | \u001b[32m     0.9635\u001b[0m | \n",
      "    5 | 07m33s | \u001b[35m   0.52702\u001b[0m | \u001b[32m            0.9130\u001b[0m | \u001b[32m   0.7970\u001b[0m | \u001b[32m         0.1275\u001b[0m | \u001b[32m          2.4270\u001b[0m | \u001b[32m     9.6075\u001b[0m | \u001b[32m        0.7418\u001b[0m | \u001b[32m           11.8469\u001b[0m | \u001b[32m            11.5286\u001b[0m | \u001b[32m       24.0641\u001b[0m | \u001b[32m     0.7075\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   learning_rate |   max_delta_step |   max_depth |   max_features |   min_child_weight |   min_samples_split |   n_estimators |   subsample | \n",
      "    6 | 39m45s |    0.52695 |             0.8678 |    0.4701 |          0.0727 |           0.0888 |      9.2454 |         0.3248 |             0.2123 |             18.0969 |        12.1975 |      0.8818 | \n",
      "    7 | 04m32s |    0.52504 |             0.5243 |    0.0445 |          0.2381 |           8.9600 |      5.1486 |         0.5312 |            18.8240 |             19.1259 |        11.8722 |      0.6620 | \n",
      "    8 | 03m55s |    0.52223 |             0.6476 |    0.0388 |          0.1857 |           9.7059 |      9.7764 |         0.8557 |             0.8428 |             19.6370 |        18.1436 |      0.5743 | \n",
      "    9 | 07m36s |    0.52636 |             0.5470 |    1.4269 |          0.1640 |           0.3329 |      9.2794 |         0.1424 |             1.1657 |              3.3142 |        24.7144 |      0.9571 | \n",
      "   10 | 11m46s |    0.52480 |             0.8254 |    0.0228 |          0.2770 |           0.6099 |      4.7133 |         0.8802 |            12.7073 |              2.8331 |        10.1131 |      0.9088 | \n",
      "   11 | 28m58s |    0.52391 |             0.4679 |    7.3337 |          0.1774 |           0.1568 |      9.3180 |         0.9321 |            18.7631 |             16.6359 |        10.1252 |      0.8186 | \n",
      "   12 | 07m04s |    0.51985 |             0.9864 |    0.9373 |          0.2271 |           0.1473 |      4.0447 |         0.4781 |             3.9093 |             19.3103 |        24.3043 |      0.9879 | \n",
      "   13 | 03m21s |    0.52434 |             0.4030 |    1.4550 |          0.2038 |           8.9104 |      9.6868 |         0.2715 |             0.0018 |              2.8208 |        10.7967 |      0.7198 | \n",
      "   14 | 12m32s |    0.52289 |             0.8052 |    9.6909 |          0.1794 |           0.7677 |      9.8095 |         0.8461 |             1.4945 |              3.9687 |        11.6889 |      0.9582 | \n",
      "   15 | 04m01s |    0.52367 |             0.8463 |    0.2014 |          0.2765 |           8.2794 |      9.3171 |         0.9497 |            19.7929 |              2.2135 |        23.7826 |      0.8322 | \n",
      "   16 | 02m49s |    0.52372 |             0.4101 |    1.3982 |          0.2942 |           4.3341 |      9.6771 |         0.1879 |            10.9878 |              9.5429 |        18.1670 |      0.8774 | \n",
      "   17 | 63m14s |    0.52370 |             0.9884 |    8.2143 |          0.1180 |           9.9703 |      9.6925 |         0.8147 |            13.2227 |             18.6343 |        11.1375 |      0.4061 | \n",
      "   18 | 14m09s |    0.52418 |             0.9635 |    6.9326 |          0.2325 |           9.3717 |      8.4918 |         0.1017 |            19.6292 |             19.7622 |        23.6949 |      0.9671 | \n",
      "   19 | 27m26s |    0.52373 |             0.9579 |    9.9814 |          0.1618 |           5.9147 |      9.6039 |         0.9984 |             0.3923 |              8.5326 |        24.8457 |      0.9432 | \n",
      "   20 | 22m55s |    0.51955 |             0.9211 |    8.9562 |          0.1369 |           6.4936 |      4.2613 |         0.1012 |             1.3429 |             18.5937 |        10.3834 |      0.7770 | \n"
     ]
    }
   ],
   "source": [
    "xgb_bo.maximize(init_points=5, n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Maximum value: 0.527018\n",
      "Best parameters:  {'max_depth': 9.6075334961758525, 'learning_rate': 0.12750069121004876, 'subsample': 0.70746966313901982, 'colsample_bytree': 0.91300804206695696, 'gamma': 0.79704305097433081, 'min_child_weight': 11.84689258578884, 'max_delta_step': 2.4269823914863409, 'n_estimators': 24.064145942538754, 'min_samples_split': 11.528636630859337, 'max_features': 0.74184703574431088}\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Maximum value: %f' % xgb_bo.res['max']['max_val'])\n",
    "print('Best parameters: ', xgb_bo.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Velification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting xgboost...\n",
      "fold cv 0 rmsle score is 0.478461\n",
      "fold cv 1 rmsle score is 0.474502\n",
      "fold cv 2 rmsle score is 0.473347\n",
      "fold cv 3 rmsle score is 0.472648\n",
      "fold cv 4 rmsle score is 0.467772\n",
      "fold cv 5 rmsle score is 0.472786\n",
      "fold cv 6 rmsle score is 0.471886\n",
      "fold cv 7 rmsle score is 0.470286\n",
      "fold cv 8 rmsle score is 0.471732\n",
      "fold cv 9 rmsle score is 0.467608\n",
      "cv rmsle score is 0.472117\n",
      "it takes 987.265 seconds to perform cross validation\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': int(9.6075334961758525), \n",
    "    'learning_rate': 0.12750069121004876, \n",
    "    'subsample': 0.70746966313901982, \n",
    "    'colsample_bytree': 0.91300804206695696, \n",
    "    'gamma': 0.79704305097433081, \n",
    "    'min_child_weight': 11.84689258578884, \n",
    "    'max_delta_step': 2.4269823914863409, \n",
    "    'n_estimators': 24.064145942538754, \n",
    "    'min_samples_split': 11.528636630859337, \n",
    "    'max_features': 0.74184703574431088\n",
    "}\n",
    "print(\"Starting xgboost...\")\n",
    "outcomes=cross_validate_xgb(xgb_params, train_input, y, test_input, kf, verbose_eval=False)\n",
    "\n",
    "xgb_cv=outcomes[0]\n",
    "xgb_train_pred=outcomes[1]\n",
    "xgb_test_pred=outcomes[2]\n",
    "\n",
    "xgb_train_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_train_pred)\n",
    "xgb_test_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_test_pred)\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv1_xgb_train_pred = xgb_train_pred_df.copy()\n",
    "lv1_xgb_train_pred.to_csv('lv1_xgb_train_pred.csv', index=False)\n",
    "\n",
    "lv1_xgb_test_pred = xgb_test_pred_df.copy()\n",
    "lv1_xgb_test_pred.to_csv('lv1_xgb_test_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good luck :)\n"
     ]
    }
   ],
   "source": [
    "test['visitors'] = xgb_test_pred_df.values\n",
    "sub = test[['id','visitors']].copy()\n",
    "sub.to_csv('submission_rs_recruit_v14_xgb_linear_feature_engineering_shinji_01.csv', index=False)\n",
    "print('Good luck :)')\n",
    "\n",
    "#fe\n",
    "#xgboost\n",
    "#Bopt\n",
    "#LB NOT SUBMITTED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last work with weight# Consider weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hklee\n",
    "# https://www.kaggle.com/zeemeen/weighted-mean-comparisons-lb-0-497-1st/code\n",
    "dfs = { re.search('/([^/\\.]*)\\.csv', fn).group(1):\n",
    "    pd.read_csv(fn)for fn in glob.glob('../../../mltestdata/05_recruit/*.csv')}\n",
    "\n",
    "for k, v in dfs.items(): locals()[k] = v\n",
    "\n",
    "wkend_holidays = date_info.apply(\n",
    "    (lambda x:(x.day_of_week=='Sunday' or x.day_of_week=='Saturday') and x.holiday_flg==1), axis=1)\n",
    "date_info.loc[wkend_holidays, 'holiday_flg'] = 0\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5  \n",
    "\n",
    "visit_data = air_visit_data.merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "visit_data.drop('calendar_date', axis=1, inplace=True)\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "wmean = lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )\n",
    "visitors = visit_data.groupby(['air_store_id', 'day_of_week', 'holiday_flg']).apply(wmean).reset_index()\n",
    "visitors.rename(columns={0:'visitors'}, inplace=True) # cumbersome, should be better ways.\n",
    "\n",
    "sample_submission['air_store_id'] = sample_submission.id.map(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(visitors, on=[\n",
    "    'air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), \n",
    "    how='left')['visitors_y'].values\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), \n",
    "    on='air_store_id', how='left')['visitors_y'].values\n",
    "\n",
    "sample_submission['visitors'] = sample_submission.visitors.map(pd.np.expm1)\n",
    "sub2 = sample_submission[['id', 'visitors']].copy()\n",
    "sub_merge = pd.merge(sub1, sub2, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_merge['visitors'] = (sub_merge['visitors_x'] + sub_merge['visitors_y']* 1.1)/2\n",
    "sub_merge[['id', 'visitors']].to_csv('submission_rs_recruit_v14_xgb_linear_feature_engineering_shinji_02.csv', index=False)\n",
    "\n",
    "# fe\n",
    "# xgb\n",
    "# Bopt\n",
    "# weight\n",
    "# LB 0.481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
