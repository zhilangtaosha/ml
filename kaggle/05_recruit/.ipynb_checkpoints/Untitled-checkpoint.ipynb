{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ...\n",
      "Loading Data Compelete.\n",
      "=========================================================================================\n",
      "Data Exploring ...\n",
      "=========================================================================================\n",
      "Unique store id in different dataset :\n",
      "-----------------------------------------------------------------------------------------\n",
      "Number of unique stores in 'df_ar' is:314\n",
      "Number of unique stores in 'df_as' is:829\n",
      "Number of unique stores in 'df_av' is:829\n",
      "-----------------------------------------------------------------------------------------\n",
      "Number of unique stores in 'df_hr' is:13325\n",
      "Number of unique stores in 'df_hs' is:4690\n",
      "-----------------------------------------------------------------------------------------\n",
      "Number of unique stores in 'df_test' is:821\n",
      "-----------------------------------------------------------------------------------------\n",
      "Number of unique stores in 'df_test' is:150\n",
      "=========================================================================================\n",
      "mapping and dropping useless information in df_hr ...\n",
      "mapping and dropping useless information in df_hr Done!\n",
      "-----------------------------------------------------------------------------------------\n",
      "mapping and dropping useless information in df_hr ...\n",
      "mapping and dropping useless information in df_hs Done!\n",
      "=========================================================================================\n",
      "seperating date time features ...\n",
      "seperating date time features done! ...\n",
      "=========================================================================================\n",
      "label encoding ...\n",
      "label encoding done !\n",
      "=========================================================================================\n",
      "merging dataframes ...\n",
      "merging dataframes done!\n",
      "=========================================================================================\n",
      "Training LGBM model...\n",
      "[10]\ttraining's rmse: 0.793419\tvalid_1's rmse: 0.796289\n",
      "[20]\ttraining's rmse: 0.788117\tvalid_1's rmse: 0.791048\n",
      "[30]\ttraining's rmse: 0.783505\tvalid_1's rmse: 0.786475\n",
      "[40]\ttraining's rmse: 0.779176\tvalid_1's rmse: 0.782086\n",
      "[50]\ttraining's rmse: 0.775461\tvalid_1's rmse: 0.778429\n",
      "[60]\ttraining's rmse: 0.771199\tvalid_1's rmse: 0.774136\n",
      "[70]\ttraining's rmse: 0.767795\tvalid_1's rmse: 0.770676\n",
      "[80]\ttraining's rmse: 0.763549\tvalid_1's rmse: 0.766399\n",
      "[90]\ttraining's rmse: 0.760123\tvalid_1's rmse: 0.762942\n",
      "[100]\ttraining's rmse: 0.75651\tvalid_1's rmse: 0.759314\n",
      "[110]\ttraining's rmse: 0.753526\tvalid_1's rmse: 0.756342\n",
      "[120]\ttraining's rmse: 0.75071\tvalid_1's rmse: 0.753537\n",
      "[130]\ttraining's rmse: 0.747438\tvalid_1's rmse: 0.750254\n",
      "[140]\ttraining's rmse: 0.74491\tvalid_1's rmse: 0.747721\n",
      "[150]\ttraining's rmse: 0.742381\tvalid_1's rmse: 0.745184\n",
      "[160]\ttraining's rmse: 0.740144\tvalid_1's rmse: 0.742903\n",
      "[170]\ttraining's rmse: 0.737914\tvalid_1's rmse: 0.740651\n",
      "[180]\ttraining's rmse: 0.735277\tvalid_1's rmse: 0.737956\n",
      "[190]\ttraining's rmse: 0.73271\tvalid_1's rmse: 0.735356\n",
      "[200]\ttraining's rmse: 0.729891\tvalid_1's rmse: 0.732579\n",
      "[210]\ttraining's rmse: 0.727944\tvalid_1's rmse: 0.73067\n",
      "[220]\ttraining's rmse: 0.725661\tvalid_1's rmse: 0.728369\n",
      "[230]\ttraining's rmse: 0.723586\tvalid_1's rmse: 0.726281\n",
      "[240]\ttraining's rmse: 0.721663\tvalid_1's rmse: 0.724363\n",
      "[250]\ttraining's rmse: 0.719406\tvalid_1's rmse: 0.72209\n",
      "[260]\ttraining's rmse: 0.71746\tvalid_1's rmse: 0.720143\n",
      "[270]\ttraining's rmse: 0.714731\tvalid_1's rmse: 0.7174\n",
      "[280]\ttraining's rmse: 0.712296\tvalid_1's rmse: 0.71493\n",
      "[290]\ttraining's rmse: 0.710206\tvalid_1's rmse: 0.712835\n",
      "[300]\ttraining's rmse: 0.7077\tvalid_1's rmse: 0.710257\n",
      "[310]\ttraining's rmse: 0.705713\tvalid_1's rmse: 0.70824\n",
      "[320]\ttraining's rmse: 0.703588\tvalid_1's rmse: 0.706094\n",
      "[330]\ttraining's rmse: 0.701376\tvalid_1's rmse: 0.703879\n",
      "[340]\ttraining's rmse: 0.699507\tvalid_1's rmse: 0.702022\n",
      "[350]\ttraining's rmse: 0.697465\tvalid_1's rmse: 0.699945\n",
      "[360]\ttraining's rmse: 0.695783\tvalid_1's rmse: 0.698256\n",
      "[370]\ttraining's rmse: 0.694022\tvalid_1's rmse: 0.696516\n",
      "[380]\ttraining's rmse: 0.692327\tvalid_1's rmse: 0.694777\n",
      "[390]\ttraining's rmse: 0.690651\tvalid_1's rmse: 0.693177\n",
      "[400]\ttraining's rmse: 0.689028\tvalid_1's rmse: 0.691545\n",
      "[410]\ttraining's rmse: 0.687309\tvalid_1's rmse: 0.689834\n",
      "[420]\ttraining's rmse: 0.685582\tvalid_1's rmse: 0.688116\n",
      "[430]\ttraining's rmse: 0.683871\tvalid_1's rmse: 0.686449\n",
      "[440]\ttraining's rmse: 0.68221\tvalid_1's rmse: 0.684767\n",
      "[450]\ttraining's rmse: 0.680892\tvalid_1's rmse: 0.683467\n",
      "[460]\ttraining's rmse: 0.679254\tvalid_1's rmse: 0.681852\n",
      "[470]\ttraining's rmse: 0.677583\tvalid_1's rmse: 0.680156\n",
      "[480]\ttraining's rmse: 0.676203\tvalid_1's rmse: 0.678792\n",
      "[490]\ttraining's rmse: 0.674627\tvalid_1's rmse: 0.677223\n",
      "[500]\ttraining's rmse: 0.67323\tvalid_1's rmse: 0.675845\n",
      "[510]\ttraining's rmse: 0.671947\tvalid_1's rmse: 0.674637\n",
      "[520]\ttraining's rmse: 0.67047\tvalid_1's rmse: 0.673188\n",
      "[530]\ttraining's rmse: 0.668931\tvalid_1's rmse: 0.671709\n",
      "[540]\ttraining's rmse: 0.667579\tvalid_1's rmse: 0.670412\n",
      "[550]\ttraining's rmse: 0.666226\tvalid_1's rmse: 0.669096\n",
      "[560]\ttraining's rmse: 0.66481\tvalid_1's rmse: 0.667753\n",
      "[570]\ttraining's rmse: 0.663398\tvalid_1's rmse: 0.66638\n",
      "[580]\ttraining's rmse: 0.662071\tvalid_1's rmse: 0.665086\n",
      "[590]\ttraining's rmse: 0.660469\tvalid_1's rmse: 0.66355\n",
      "[600]\ttraining's rmse: 0.659081\tvalid_1's rmse: 0.662188\n",
      "[610]\ttraining's rmse: 0.657787\tvalid_1's rmse: 0.660963\n",
      "[620]\ttraining's rmse: 0.656518\tvalid_1's rmse: 0.65975\n",
      "[630]\ttraining's rmse: 0.655305\tvalid_1's rmse: 0.658603\n",
      "[640]\ttraining's rmse: 0.653987\tvalid_1's rmse: 0.657264\n",
      "[650]\ttraining's rmse: 0.65267\tvalid_1's rmse: 0.656003\n",
      "[660]\ttraining's rmse: 0.651484\tvalid_1's rmse: 0.654842\n",
      "[670]\ttraining's rmse: 0.650141\tvalid_1's rmse: 0.653553\n",
      "[680]\ttraining's rmse: 0.648947\tvalid_1's rmse: 0.652373\n",
      "[690]\ttraining's rmse: 0.647861\tvalid_1's rmse: 0.651287\n",
      "[700]\ttraining's rmse: 0.647011\tvalid_1's rmse: 0.65047\n",
      "[710]\ttraining's rmse: 0.645849\tvalid_1's rmse: 0.649278\n",
      "[720]\ttraining's rmse: 0.644777\tvalid_1's rmse: 0.648237\n",
      "[730]\ttraining's rmse: 0.643782\tvalid_1's rmse: 0.647264\n",
      "[740]\ttraining's rmse: 0.642831\tvalid_1's rmse: 0.646346\n",
      "[750]\ttraining's rmse: 0.641889\tvalid_1's rmse: 0.645435\n",
      "[760]\ttraining's rmse: 0.641052\tvalid_1's rmse: 0.644647\n",
      "[770]\ttraining's rmse: 0.640145\tvalid_1's rmse: 0.643771\n",
      "[780]\ttraining's rmse: 0.639224\tvalid_1's rmse: 0.642856\n",
      "[790]\ttraining's rmse: 0.638415\tvalid_1's rmse: 0.642092\n",
      "[800]\ttraining's rmse: 0.637562\tvalid_1's rmse: 0.641299\n",
      "[810]\ttraining's rmse: 0.636629\tvalid_1's rmse: 0.640376\n",
      "[820]\ttraining's rmse: 0.635878\tvalid_1's rmse: 0.639631\n",
      "[830]\ttraining's rmse: 0.634812\tvalid_1's rmse: 0.638608\n",
      "[840]\ttraining's rmse: 0.633968\tvalid_1's rmse: 0.6378\n",
      "[850]\ttraining's rmse: 0.63311\tvalid_1's rmse: 0.637011\n",
      "[860]\ttraining's rmse: 0.632292\tvalid_1's rmse: 0.636186\n",
      "[870]\ttraining's rmse: 0.631335\tvalid_1's rmse: 0.635286\n",
      "[880]\ttraining's rmse: 0.630596\tvalid_1's rmse: 0.634573\n",
      "[890]\ttraining's rmse: 0.629964\tvalid_1's rmse: 0.633982\n",
      "[900]\ttraining's rmse: 0.629163\tvalid_1's rmse: 0.633252\n",
      "[910]\ttraining's rmse: 0.628363\tvalid_1's rmse: 0.632481\n",
      "[920]\ttraining's rmse: 0.627661\tvalid_1's rmse: 0.631811\n",
      "[930]\ttraining's rmse: 0.626705\tvalid_1's rmse: 0.630899\n",
      "[940]\ttraining's rmse: 0.62584\tvalid_1's rmse: 0.630061\n",
      "[950]\ttraining's rmse: 0.625035\tvalid_1's rmse: 0.629289\n",
      "[960]\ttraining's rmse: 0.624288\tvalid_1's rmse: 0.628574\n",
      "[970]\ttraining's rmse: 0.623569\tvalid_1's rmse: 0.627903\n",
      "[980]\ttraining's rmse: 0.622881\tvalid_1's rmse: 0.627221\n",
      "[990]\ttraining's rmse: 0.622229\tvalid_1's rmse: 0.626612\n",
      "[1000]\ttraining's rmse: 0.621597\tvalid_1's rmse: 0.625987\n",
      "[1010]\ttraining's rmse: 0.620955\tvalid_1's rmse: 0.62539\n",
      "[1020]\ttraining's rmse: 0.62031\tvalid_1's rmse: 0.62477\n",
      "[1030]\ttraining's rmse: 0.619682\tvalid_1's rmse: 0.62419\n",
      "[1040]\ttraining's rmse: 0.619104\tvalid_1's rmse: 0.62364\n",
      "[1050]\ttraining's rmse: 0.618346\tvalid_1's rmse: 0.622917\n",
      "[1060]\ttraining's rmse: 0.617758\tvalid_1's rmse: 0.622374\n",
      "[1070]\ttraining's rmse: 0.61706\tvalid_1's rmse: 0.621706\n",
      "[1080]\ttraining's rmse: 0.616447\tvalid_1's rmse: 0.621126\n",
      "[1090]\ttraining's rmse: 0.615869\tvalid_1's rmse: 0.62055\n",
      "[1100]\ttraining's rmse: 0.615256\tvalid_1's rmse: 0.619978\n",
      "[1110]\ttraining's rmse: 0.614582\tvalid_1's rmse: 0.619292\n",
      "[1120]\ttraining's rmse: 0.613877\tvalid_1's rmse: 0.618632\n",
      "[1130]\ttraining's rmse: 0.613247\tvalid_1's rmse: 0.618004\n",
      "[1140]\ttraining's rmse: 0.612701\tvalid_1's rmse: 0.617488\n",
      "[1150]\ttraining's rmse: 0.612061\tvalid_1's rmse: 0.61687\n",
      "[1160]\ttraining's rmse: 0.611501\tvalid_1's rmse: 0.616328\n",
      "[1170]\ttraining's rmse: 0.610851\tvalid_1's rmse: 0.615695\n",
      "[1180]\ttraining's rmse: 0.610279\tvalid_1's rmse: 0.615145\n",
      "[1190]\ttraining's rmse: 0.609792\tvalid_1's rmse: 0.614689\n",
      "[1200]\ttraining's rmse: 0.609303\tvalid_1's rmse: 0.614201\n",
      "[1210]\ttraining's rmse: 0.608874\tvalid_1's rmse: 0.613785\n",
      "[1220]\ttraining's rmse: 0.60837\tvalid_1's rmse: 0.613287\n",
      "[1230]\ttraining's rmse: 0.607891\tvalid_1's rmse: 0.612824\n",
      "[1240]\ttraining's rmse: 0.607228\tvalid_1's rmse: 0.61218\n",
      "[1250]\ttraining's rmse: 0.606654\tvalid_1's rmse: 0.611661\n",
      "[1260]\ttraining's rmse: 0.606056\tvalid_1's rmse: 0.611104\n",
      "[1270]\ttraining's rmse: 0.605637\tvalid_1's rmse: 0.610709\n",
      "[1280]\ttraining's rmse: 0.605154\tvalid_1's rmse: 0.610255\n",
      "[1290]\ttraining's rmse: 0.604667\tvalid_1's rmse: 0.609801\n",
      "[1300]\ttraining's rmse: 0.604237\tvalid_1's rmse: 0.609411\n",
      "[1310]\ttraining's rmse: 0.603577\tvalid_1's rmse: 0.608764\n",
      "[1320]\ttraining's rmse: 0.603058\tvalid_1's rmse: 0.608299\n",
      "[1330]\ttraining's rmse: 0.602645\tvalid_1's rmse: 0.607882\n",
      "[1340]\ttraining's rmse: 0.602202\tvalid_1's rmse: 0.607469\n",
      "[1350]\ttraining's rmse: 0.601748\tvalid_1's rmse: 0.60704\n",
      "[1360]\ttraining's rmse: 0.601205\tvalid_1's rmse: 0.606523\n",
      "[1370]\ttraining's rmse: 0.600825\tvalid_1's rmse: 0.606151\n",
      "[1380]\ttraining's rmse: 0.600151\tvalid_1's rmse: 0.605515\n",
      "[1390]\ttraining's rmse: 0.599641\tvalid_1's rmse: 0.605028\n",
      "[1400]\ttraining's rmse: 0.599173\tvalid_1's rmse: 0.604573\n",
      "[1410]\ttraining's rmse: 0.598683\tvalid_1's rmse: 0.60411\n",
      "[1420]\ttraining's rmse: 0.598207\tvalid_1's rmse: 0.603633\n",
      "[1430]\ttraining's rmse: 0.597591\tvalid_1's rmse: 0.603067\n",
      "[1440]\ttraining's rmse: 0.597107\tvalid_1's rmse: 0.602621\n",
      "[1450]\ttraining's rmse: 0.596734\tvalid_1's rmse: 0.602272\n",
      "[1460]\ttraining's rmse: 0.596274\tvalid_1's rmse: 0.601825\n",
      "[1470]\ttraining's rmse: 0.595833\tvalid_1's rmse: 0.60143\n",
      "[1480]\ttraining's rmse: 0.595492\tvalid_1's rmse: 0.601101\n",
      "[1490]\ttraining's rmse: 0.595059\tvalid_1's rmse: 0.600685\n",
      "[1500]\ttraining's rmse: 0.594732\tvalid_1's rmse: 0.600378\n",
      "[1510]\ttraining's rmse: 0.594411\tvalid_1's rmse: 0.600072\n",
      "[1520]\ttraining's rmse: 0.593965\tvalid_1's rmse: 0.599636\n",
      "[1530]\ttraining's rmse: 0.593615\tvalid_1's rmse: 0.59931\n",
      "[1540]\ttraining's rmse: 0.593232\tvalid_1's rmse: 0.598958\n",
      "[1550]\ttraining's rmse: 0.592785\tvalid_1's rmse: 0.598539\n",
      "[1560]\ttraining's rmse: 0.592387\tvalid_1's rmse: 0.598168\n",
      "[1570]\ttraining's rmse: 0.591966\tvalid_1's rmse: 0.597788\n",
      "[1580]\ttraining's rmse: 0.591655\tvalid_1's rmse: 0.597508\n",
      "[1590]\ttraining's rmse: 0.591176\tvalid_1's rmse: 0.597062\n",
      "[1600]\ttraining's rmse: 0.590816\tvalid_1's rmse: 0.59673\n",
      "[1610]\ttraining's rmse: 0.590492\tvalid_1's rmse: 0.596415\n",
      "[1620]\ttraining's rmse: 0.590127\tvalid_1's rmse: 0.596063\n",
      "[1630]\ttraining's rmse: 0.589825\tvalid_1's rmse: 0.595782\n",
      "[1640]\ttraining's rmse: 0.589536\tvalid_1's rmse: 0.595512\n",
      "[1650]\ttraining's rmse: 0.589264\tvalid_1's rmse: 0.595275\n",
      "[1660]\ttraining's rmse: 0.588925\tvalid_1's rmse: 0.594979\n",
      "[1670]\ttraining's rmse: 0.58849\tvalid_1's rmse: 0.594551\n",
      "[1680]\ttraining's rmse: 0.588163\tvalid_1's rmse: 0.59424\n",
      "[1690]\ttraining's rmse: 0.587915\tvalid_1's rmse: 0.594009\n",
      "[1700]\ttraining's rmse: 0.587539\tvalid_1's rmse: 0.593648\n",
      "[1710]\ttraining's rmse: 0.587098\tvalid_1's rmse: 0.593226\n",
      "[1720]\ttraining's rmse: 0.586764\tvalid_1's rmse: 0.592895\n",
      "[1730]\ttraining's rmse: 0.586484\tvalid_1's rmse: 0.592639\n",
      "[1740]\ttraining's rmse: 0.586236\tvalid_1's rmse: 0.592412\n",
      "[1750]\ttraining's rmse: 0.585967\tvalid_1's rmse: 0.592162\n",
      "[1760]\ttraining's rmse: 0.585668\tvalid_1's rmse: 0.591877\n",
      "[1770]\ttraining's rmse: 0.585403\tvalid_1's rmse: 0.591635\n",
      "[1780]\ttraining's rmse: 0.585167\tvalid_1's rmse: 0.591407\n",
      "[1790]\ttraining's rmse: 0.584934\tvalid_1's rmse: 0.591204\n",
      "[1800]\ttraining's rmse: 0.584749\tvalid_1's rmse: 0.591035\n",
      "[1810]\ttraining's rmse: 0.584487\tvalid_1's rmse: 0.590781\n",
      "[1820]\ttraining's rmse: 0.584147\tvalid_1's rmse: 0.590452\n",
      "[1830]\ttraining's rmse: 0.583895\tvalid_1's rmse: 0.59023\n",
      "[1840]\ttraining's rmse: 0.58367\tvalid_1's rmse: 0.590024\n",
      "[1850]\ttraining's rmse: 0.583488\tvalid_1's rmse: 0.58986\n",
      "[1860]\ttraining's rmse: 0.583213\tvalid_1's rmse: 0.589594\n",
      "[1870]\ttraining's rmse: 0.582931\tvalid_1's rmse: 0.589314\n",
      "[1880]\ttraining's rmse: 0.582623\tvalid_1's rmse: 0.589031\n",
      "[1890]\ttraining's rmse: 0.582227\tvalid_1's rmse: 0.588661\n",
      "[1900]\ttraining's rmse: 0.581864\tvalid_1's rmse: 0.588302\n",
      "[1910]\ttraining's rmse: 0.581399\tvalid_1's rmse: 0.587862\n",
      "[1920]\ttraining's rmse: 0.581085\tvalid_1's rmse: 0.587558\n",
      "[1930]\ttraining's rmse: 0.580695\tvalid_1's rmse: 0.58718\n",
      "[1940]\ttraining's rmse: 0.580368\tvalid_1's rmse: 0.586897\n",
      "[1950]\ttraining's rmse: 0.580082\tvalid_1's rmse: 0.586632\n",
      "[1960]\ttraining's rmse: 0.579771\tvalid_1's rmse: 0.586342\n",
      "[1970]\ttraining's rmse: 0.579528\tvalid_1's rmse: 0.586106\n",
      "[1980]\ttraining's rmse: 0.579282\tvalid_1's rmse: 0.585864\n",
      "[1990]\ttraining's rmse: 0.57903\tvalid_1's rmse: 0.585634\n",
      "[2000]\ttraining's rmse: 0.578783\tvalid_1's rmse: 0.585386\n",
      "[2010]\ttraining's rmse: 0.578464\tvalid_1's rmse: 0.585087\n",
      "[2020]\ttraining's rmse: 0.578134\tvalid_1's rmse: 0.584752\n",
      "[2030]\ttraining's rmse: 0.577787\tvalid_1's rmse: 0.58442\n",
      "[2040]\ttraining's rmse: 0.577441\tvalid_1's rmse: 0.584085\n",
      "[2050]\ttraining's rmse: 0.577123\tvalid_1's rmse: 0.583792\n",
      "[2060]\ttraining's rmse: 0.57672\tvalid_1's rmse: 0.58342\n",
      "[2070]\ttraining's rmse: 0.576423\tvalid_1's rmse: 0.583142\n",
      "[2080]\ttraining's rmse: 0.576046\tvalid_1's rmse: 0.582775\n",
      "[2090]\ttraining's rmse: 0.57573\tvalid_1's rmse: 0.582491\n",
      "[2100]\ttraining's rmse: 0.575512\tvalid_1's rmse: 0.582292\n",
      "[2110]\ttraining's rmse: 0.575221\tvalid_1's rmse: 0.582026\n",
      "[2120]\ttraining's rmse: 0.574905\tvalid_1's rmse: 0.581724\n",
      "[2130]\ttraining's rmse: 0.574565\tvalid_1's rmse: 0.581409\n",
      "[2140]\ttraining's rmse: 0.574305\tvalid_1's rmse: 0.581184\n",
      "[2150]\ttraining's rmse: 0.574018\tvalid_1's rmse: 0.580917\n",
      "[2160]\ttraining's rmse: 0.573742\tvalid_1's rmse: 0.580644\n",
      "[2170]\ttraining's rmse: 0.573471\tvalid_1's rmse: 0.580412\n",
      "[2180]\ttraining's rmse: 0.573115\tvalid_1's rmse: 0.580071\n",
      "[2190]\ttraining's rmse: 0.57286\tvalid_1's rmse: 0.579846\n",
      "[2200]\ttraining's rmse: 0.572555\tvalid_1's rmse: 0.579545\n",
      "[2210]\ttraining's rmse: 0.572301\tvalid_1's rmse: 0.579311\n",
      "[2220]\ttraining's rmse: 0.572059\tvalid_1's rmse: 0.579113\n",
      "[2230]\ttraining's rmse: 0.571789\tvalid_1's rmse: 0.578828\n",
      "[2240]\ttraining's rmse: 0.571505\tvalid_1's rmse: 0.578585\n",
      "[2250]\ttraining's rmse: 0.571217\tvalid_1's rmse: 0.578301\n",
      "[2260]\ttraining's rmse: 0.571018\tvalid_1's rmse: 0.578119\n",
      "[2270]\ttraining's rmse: 0.570805\tvalid_1's rmse: 0.577948\n",
      "[2280]\ttraining's rmse: 0.57054\tvalid_1's rmse: 0.577704\n",
      "[2290]\ttraining's rmse: 0.570308\tvalid_1's rmse: 0.577486\n",
      "[2300]\ttraining's rmse: 0.570049\tvalid_1's rmse: 0.577246\n",
      "[2310]\ttraining's rmse: 0.569762\tvalid_1's rmse: 0.576981\n",
      "[2320]\ttraining's rmse: 0.569524\tvalid_1's rmse: 0.576774\n",
      "[2330]\ttraining's rmse: 0.569293\tvalid_1's rmse: 0.576554\n",
      "[2340]\ttraining's rmse: 0.569007\tvalid_1's rmse: 0.576277\n",
      "[2350]\ttraining's rmse: 0.56878\tvalid_1's rmse: 0.576068\n",
      "[2360]\ttraining's rmse: 0.568555\tvalid_1's rmse: 0.57587\n",
      "[2370]\ttraining's rmse: 0.568308\tvalid_1's rmse: 0.575641\n",
      "[2380]\ttraining's rmse: 0.568076\tvalid_1's rmse: 0.57542\n",
      "[2390]\ttraining's rmse: 0.567828\tvalid_1's rmse: 0.575202\n",
      "[2400]\ttraining's rmse: 0.567586\tvalid_1's rmse: 0.574985\n",
      "[2410]\ttraining's rmse: 0.567327\tvalid_1's rmse: 0.574735\n",
      "[2420]\ttraining's rmse: 0.567135\tvalid_1's rmse: 0.574552\n",
      "[2430]\ttraining's rmse: 0.566905\tvalid_1's rmse: 0.574343\n",
      "[2440]\ttraining's rmse: 0.566605\tvalid_1's rmse: 0.574029\n",
      "[2450]\ttraining's rmse: 0.566273\tvalid_1's rmse: 0.573723\n",
      "[2460]\ttraining's rmse: 0.56611\tvalid_1's rmse: 0.573571\n",
      "[2470]\ttraining's rmse: 0.565891\tvalid_1's rmse: 0.57335\n",
      "[2480]\ttraining's rmse: 0.565633\tvalid_1's rmse: 0.573105\n",
      "[2490]\ttraining's rmse: 0.565452\tvalid_1's rmse: 0.572939\n",
      "[2500]\ttraining's rmse: 0.565313\tvalid_1's rmse: 0.572835\n",
      "[2510]\ttraining's rmse: 0.565064\tvalid_1's rmse: 0.5726\n",
      "[2520]\ttraining's rmse: 0.564902\tvalid_1's rmse: 0.572459\n",
      "[2530]\ttraining's rmse: 0.564694\tvalid_1's rmse: 0.572248\n",
      "[2540]\ttraining's rmse: 0.564514\tvalid_1's rmse: 0.572067\n",
      "[2550]\ttraining's rmse: 0.564342\tvalid_1's rmse: 0.571939\n",
      "[2560]\ttraining's rmse: 0.564162\tvalid_1's rmse: 0.571777\n",
      "[2570]\ttraining's rmse: 0.564001\tvalid_1's rmse: 0.571653\n",
      "[2580]\ttraining's rmse: 0.563828\tvalid_1's rmse: 0.571486\n",
      "[2590]\ttraining's rmse: 0.563615\tvalid_1's rmse: 0.57129\n",
      "[2600]\ttraining's rmse: 0.563463\tvalid_1's rmse: 0.571157\n",
      "[2610]\ttraining's rmse: 0.563339\tvalid_1's rmse: 0.571076\n",
      "[2620]\ttraining's rmse: 0.563104\tvalid_1's rmse: 0.570852\n",
      "[2630]\ttraining's rmse: 0.562975\tvalid_1's rmse: 0.570745\n",
      "[2640]\ttraining's rmse: 0.562776\tvalid_1's rmse: 0.570557\n",
      "[2650]\ttraining's rmse: 0.562618\tvalid_1's rmse: 0.570395\n",
      "[2660]\ttraining's rmse: 0.562428\tvalid_1's rmse: 0.570235\n",
      "[2670]\ttraining's rmse: 0.562227\tvalid_1's rmse: 0.570044\n",
      "[2680]\ttraining's rmse: 0.562064\tvalid_1's rmse: 0.569907\n",
      "[2690]\ttraining's rmse: 0.561883\tvalid_1's rmse: 0.569763\n",
      "[2700]\ttraining's rmse: 0.561735\tvalid_1's rmse: 0.569637\n",
      "[2710]\ttraining's rmse: 0.561514\tvalid_1's rmse: 0.56944\n",
      "[2720]\ttraining's rmse: 0.561338\tvalid_1's rmse: 0.569279\n",
      "[2730]\ttraining's rmse: 0.561103\tvalid_1's rmse: 0.569072\n",
      "[2740]\ttraining's rmse: 0.560869\tvalid_1's rmse: 0.568837\n",
      "[2750]\ttraining's rmse: 0.560665\tvalid_1's rmse: 0.568661\n",
      "[2760]\ttraining's rmse: 0.560416\tvalid_1's rmse: 0.568462\n",
      "[2770]\ttraining's rmse: 0.560245\tvalid_1's rmse: 0.568317\n",
      "[2780]\ttraining's rmse: 0.560117\tvalid_1's rmse: 0.568206\n",
      "[2790]\ttraining's rmse: 0.559857\tvalid_1's rmse: 0.567946\n",
      "[2800]\ttraining's rmse: 0.559614\tvalid_1's rmse: 0.567738\n",
      "[2810]\ttraining's rmse: 0.559433\tvalid_1's rmse: 0.567576\n",
      "[2820]\ttraining's rmse: 0.559236\tvalid_1's rmse: 0.567405\n",
      "[2830]\ttraining's rmse: 0.559056\tvalid_1's rmse: 0.567234\n",
      "[2840]\ttraining's rmse: 0.558926\tvalid_1's rmse: 0.567131\n",
      "[2850]\ttraining's rmse: 0.558791\tvalid_1's rmse: 0.567036\n",
      "[2860]\ttraining's rmse: 0.558602\tvalid_1's rmse: 0.566879\n",
      "[2870]\ttraining's rmse: 0.558486\tvalid_1's rmse: 0.566799\n",
      "[2880]\ttraining's rmse: 0.558336\tvalid_1's rmse: 0.566671\n",
      "[2890]\ttraining's rmse: 0.558165\tvalid_1's rmse: 0.566521\n",
      "[2900]\ttraining's rmse: 0.557992\tvalid_1's rmse: 0.566366\n",
      "[2910]\ttraining's rmse: 0.55788\tvalid_1's rmse: 0.566281\n",
      "[2920]\ttraining's rmse: 0.557696\tvalid_1's rmse: 0.566115\n",
      "[2930]\ttraining's rmse: 0.557524\tvalid_1's rmse: 0.565957\n",
      "[2940]\ttraining's rmse: 0.557407\tvalid_1's rmse: 0.565864\n",
      "[2950]\ttraining's rmse: 0.557286\tvalid_1's rmse: 0.565767\n",
      "[2960]\ttraining's rmse: 0.557153\tvalid_1's rmse: 0.565652\n",
      "[2970]\ttraining's rmse: 0.556982\tvalid_1's rmse: 0.56548\n",
      "[2980]\ttraining's rmse: 0.556804\tvalid_1's rmse: 0.56532\n",
      "[2990]\ttraining's rmse: 0.556682\tvalid_1's rmse: 0.565228\n",
      "[3000]\ttraining's rmse: 0.556483\tvalid_1's rmse: 0.565033\n",
      "[3010]\ttraining's rmse: 0.556299\tvalid_1's rmse: 0.564861\n",
      "[3020]\ttraining's rmse: 0.556173\tvalid_1's rmse: 0.56476\n",
      "[3030]\ttraining's rmse: 0.556034\tvalid_1's rmse: 0.564619\n",
      "[3040]\ttraining's rmse: 0.55585\tvalid_1's rmse: 0.56445\n",
      "[3050]\ttraining's rmse: 0.555641\tvalid_1's rmse: 0.564249\n",
      "[3060]\ttraining's rmse: 0.555433\tvalid_1's rmse: 0.564066\n",
      "[3070]\ttraining's rmse: 0.555267\tvalid_1's rmse: 0.563912\n",
      "[3080]\ttraining's rmse: 0.555028\tvalid_1's rmse: 0.563691\n",
      "[3090]\ttraining's rmse: 0.554896\tvalid_1's rmse: 0.563589\n",
      "[3100]\ttraining's rmse: 0.554726\tvalid_1's rmse: 0.563437\n",
      "[3110]\ttraining's rmse: 0.554558\tvalid_1's rmse: 0.563285\n",
      "[3120]\ttraining's rmse: 0.554399\tvalid_1's rmse: 0.563157\n",
      "[3130]\ttraining's rmse: 0.554252\tvalid_1's rmse: 0.563041\n",
      "[3140]\ttraining's rmse: 0.554172\tvalid_1's rmse: 0.562986\n",
      "[3150]\ttraining's rmse: 0.554027\tvalid_1's rmse: 0.562863\n",
      "[3160]\ttraining's rmse: 0.553909\tvalid_1's rmse: 0.56276\n",
      "[3170]\ttraining's rmse: 0.55375\tvalid_1's rmse: 0.562619\n",
      "[3180]\ttraining's rmse: 0.553628\tvalid_1's rmse: 0.562504\n",
      "[3190]\ttraining's rmse: 0.553505\tvalid_1's rmse: 0.562401\n",
      "[3200]\ttraining's rmse: 0.553344\tvalid_1's rmse: 0.562249\n",
      "[3210]\ttraining's rmse: 0.553181\tvalid_1's rmse: 0.562095\n",
      "[3220]\ttraining's rmse: 0.553059\tvalid_1's rmse: 0.561988\n",
      "[3230]\ttraining's rmse: 0.552866\tvalid_1's rmse: 0.561804\n",
      "[3240]\ttraining's rmse: 0.552683\tvalid_1's rmse: 0.561622\n",
      "[3250]\ttraining's rmse: 0.552544\tvalid_1's rmse: 0.561509\n",
      "[3260]\ttraining's rmse: 0.55238\tvalid_1's rmse: 0.56133\n",
      "[3270]\ttraining's rmse: 0.552186\tvalid_1's rmse: 0.561135\n",
      "[3280]\ttraining's rmse: 0.552007\tvalid_1's rmse: 0.560957\n",
      "[3290]\ttraining's rmse: 0.551842\tvalid_1's rmse: 0.560807\n",
      "[3300]\ttraining's rmse: 0.551652\tvalid_1's rmse: 0.560625\n",
      "[3310]\ttraining's rmse: 0.551472\tvalid_1's rmse: 0.56043\n",
      "[3320]\ttraining's rmse: 0.551304\tvalid_1's rmse: 0.560258\n",
      "[3330]\ttraining's rmse: 0.551131\tvalid_1's rmse: 0.560095\n",
      "[3340]\ttraining's rmse: 0.550992\tvalid_1's rmse: 0.559975\n",
      "[3350]\ttraining's rmse: 0.550787\tvalid_1's rmse: 0.559774\n",
      "[3360]\ttraining's rmse: 0.550627\tvalid_1's rmse: 0.559623\n",
      "[3370]\ttraining's rmse: 0.550426\tvalid_1's rmse: 0.559427\n",
      "[3380]\ttraining's rmse: 0.550259\tvalid_1's rmse: 0.559267\n",
      "[3390]\ttraining's rmse: 0.550094\tvalid_1's rmse: 0.559129\n",
      "[3400]\ttraining's rmse: 0.549932\tvalid_1's rmse: 0.558979\n",
      "[3410]\ttraining's rmse: 0.549817\tvalid_1's rmse: 0.558878\n",
      "[3420]\ttraining's rmse: 0.549634\tvalid_1's rmse: 0.558694\n",
      "[3430]\ttraining's rmse: 0.549433\tvalid_1's rmse: 0.558495\n",
      "[3440]\ttraining's rmse: 0.549257\tvalid_1's rmse: 0.558314\n",
      "[3450]\ttraining's rmse: 0.549081\tvalid_1's rmse: 0.558153\n",
      "[3460]\ttraining's rmse: 0.548959\tvalid_1's rmse: 0.558043\n",
      "[3470]\ttraining's rmse: 0.548814\tvalid_1's rmse: 0.557918\n",
      "[3480]\ttraining's rmse: 0.548694\tvalid_1's rmse: 0.557806\n",
      "[3490]\ttraining's rmse: 0.548544\tvalid_1's rmse: 0.55767\n",
      "[3500]\ttraining's rmse: 0.54838\tvalid_1's rmse: 0.557523\n",
      "[3510]\ttraining's rmse: 0.548217\tvalid_1's rmse: 0.557366\n",
      "[3520]\ttraining's rmse: 0.548052\tvalid_1's rmse: 0.557203\n",
      "[3530]\ttraining's rmse: 0.547901\tvalid_1's rmse: 0.557054\n",
      "[3540]\ttraining's rmse: 0.547789\tvalid_1's rmse: 0.556953\n",
      "[3550]\ttraining's rmse: 0.547619\tvalid_1's rmse: 0.556797\n",
      "[3560]\ttraining's rmse: 0.547407\tvalid_1's rmse: 0.556588\n",
      "[3570]\ttraining's rmse: 0.547269\tvalid_1's rmse: 0.556472\n",
      "[3580]\ttraining's rmse: 0.547154\tvalid_1's rmse: 0.55638\n",
      "[3590]\ttraining's rmse: 0.547011\tvalid_1's rmse: 0.556265\n",
      "[3600]\ttraining's rmse: 0.546861\tvalid_1's rmse: 0.556134\n",
      "[3610]\ttraining's rmse: 0.546751\tvalid_1's rmse: 0.556062\n",
      "[3620]\ttraining's rmse: 0.54663\tvalid_1's rmse: 0.555949\n",
      "[3630]\ttraining's rmse: 0.546528\tvalid_1's rmse: 0.55585\n",
      "[3640]\ttraining's rmse: 0.546422\tvalid_1's rmse: 0.555751\n",
      "[3650]\ttraining's rmse: 0.546302\tvalid_1's rmse: 0.555633\n",
      "[3660]\ttraining's rmse: 0.546222\tvalid_1's rmse: 0.555578\n",
      "[3670]\ttraining's rmse: 0.546122\tvalid_1's rmse: 0.555486\n",
      "[3680]\ttraining's rmse: 0.546023\tvalid_1's rmse: 0.555404\n",
      "[3690]\ttraining's rmse: 0.545899\tvalid_1's rmse: 0.555294\n",
      "[3700]\ttraining's rmse: 0.545797\tvalid_1's rmse: 0.555214\n",
      "[3710]\ttraining's rmse: 0.545693\tvalid_1's rmse: 0.555131\n",
      "[3720]\ttraining's rmse: 0.545606\tvalid_1's rmse: 0.55506\n",
      "[3730]\ttraining's rmse: 0.545506\tvalid_1's rmse: 0.554993\n",
      "[3740]\ttraining's rmse: 0.545395\tvalid_1's rmse: 0.5549\n",
      "[3750]\ttraining's rmse: 0.545276\tvalid_1's rmse: 0.554809\n",
      "[3760]\ttraining's rmse: 0.545204\tvalid_1's rmse: 0.554759\n",
      "[3770]\ttraining's rmse: 0.545101\tvalid_1's rmse: 0.554669\n",
      "[3780]\ttraining's rmse: 0.545003\tvalid_1's rmse: 0.5546\n",
      "[3790]\ttraining's rmse: 0.544888\tvalid_1's rmse: 0.554498\n",
      "[3800]\ttraining's rmse: 0.544761\tvalid_1's rmse: 0.554377\n",
      "[3810]\ttraining's rmse: 0.544674\tvalid_1's rmse: 0.554298\n",
      "[3820]\ttraining's rmse: 0.544563\tvalid_1's rmse: 0.554208\n",
      "[3830]\ttraining's rmse: 0.544447\tvalid_1's rmse: 0.554104\n",
      "[3840]\ttraining's rmse: 0.544331\tvalid_1's rmse: 0.554021\n",
      "[3850]\ttraining's rmse: 0.544221\tvalid_1's rmse: 0.553934\n",
      "[3860]\ttraining's rmse: 0.544078\tvalid_1's rmse: 0.553804\n",
      "[3870]\ttraining's rmse: 0.543966\tvalid_1's rmse: 0.553706\n",
      "[3880]\ttraining's rmse: 0.543862\tvalid_1's rmse: 0.553615\n",
      "[3890]\ttraining's rmse: 0.543767\tvalid_1's rmse: 0.553532\n",
      "[3900]\ttraining's rmse: 0.543646\tvalid_1's rmse: 0.553416\n",
      "[3910]\ttraining's rmse: 0.543569\tvalid_1's rmse: 0.553353\n",
      "[3920]\ttraining's rmse: 0.543452\tvalid_1's rmse: 0.553263\n",
      "[3930]\ttraining's rmse: 0.543345\tvalid_1's rmse: 0.553172\n",
      "[3940]\ttraining's rmse: 0.543252\tvalid_1's rmse: 0.553091\n",
      "[3950]\ttraining's rmse: 0.543149\tvalid_1's rmse: 0.553011\n",
      "[3960]\ttraining's rmse: 0.543026\tvalid_1's rmse: 0.552899\n",
      "[3970]\ttraining's rmse: 0.542926\tvalid_1's rmse: 0.552811\n",
      "[3980]\ttraining's rmse: 0.542806\tvalid_1's rmse: 0.552705\n",
      "[3990]\ttraining's rmse: 0.542696\tvalid_1's rmse: 0.552616\n",
      "[4000]\ttraining's rmse: 0.542609\tvalid_1's rmse: 0.552547\n",
      "[4010]\ttraining's rmse: 0.542506\tvalid_1's rmse: 0.552464\n",
      "[4020]\ttraining's rmse: 0.54238\tvalid_1's rmse: 0.552352\n",
      "[4030]\ttraining's rmse: 0.542305\tvalid_1's rmse: 0.552308\n",
      "[4040]\ttraining's rmse: 0.542216\tvalid_1's rmse: 0.55225\n",
      "[4050]\ttraining's rmse: 0.542129\tvalid_1's rmse: 0.552185\n",
      "[4060]\ttraining's rmse: 0.542013\tvalid_1's rmse: 0.552096\n",
      "[4070]\ttraining's rmse: 0.541906\tvalid_1's rmse: 0.552008\n",
      "[4080]\ttraining's rmse: 0.541794\tvalid_1's rmse: 0.551912\n",
      "[4090]\ttraining's rmse: 0.541713\tvalid_1's rmse: 0.551856\n",
      "[4100]\ttraining's rmse: 0.54162\tvalid_1's rmse: 0.551792\n",
      "[4110]\ttraining's rmse: 0.54154\tvalid_1's rmse: 0.55174\n",
      "[4120]\ttraining's rmse: 0.541461\tvalid_1's rmse: 0.551674\n",
      "[4130]\ttraining's rmse: 0.541405\tvalid_1's rmse: 0.551632\n",
      "[4140]\ttraining's rmse: 0.541335\tvalid_1's rmse: 0.551602\n",
      "[4150]\ttraining's rmse: 0.541233\tvalid_1's rmse: 0.551506\n",
      "[4160]\ttraining's rmse: 0.541151\tvalid_1's rmse: 0.551434\n",
      "[4170]\ttraining's rmse: 0.541085\tvalid_1's rmse: 0.5514\n",
      "[4180]\ttraining's rmse: 0.540988\tvalid_1's rmse: 0.551304\n",
      "[4190]\ttraining's rmse: 0.540897\tvalid_1's rmse: 0.551241\n",
      "[4200]\ttraining's rmse: 0.540816\tvalid_1's rmse: 0.551178\n",
      "[4210]\ttraining's rmse: 0.540709\tvalid_1's rmse: 0.551092\n",
      "[4220]\ttraining's rmse: 0.540622\tvalid_1's rmse: 0.551031\n",
      "[4230]\ttraining's rmse: 0.540555\tvalid_1's rmse: 0.550981\n",
      "[4240]\ttraining's rmse: 0.540441\tvalid_1's rmse: 0.55088\n",
      "[4250]\ttraining's rmse: 0.540371\tvalid_1's rmse: 0.550837\n",
      "[4260]\ttraining's rmse: 0.540287\tvalid_1's rmse: 0.550766\n",
      "[4270]\ttraining's rmse: 0.540197\tvalid_1's rmse: 0.550693\n",
      "[4280]\ttraining's rmse: 0.540101\tvalid_1's rmse: 0.550618\n",
      "[4290]\ttraining's rmse: 0.540014\tvalid_1's rmse: 0.550553\n",
      "[4300]\ttraining's rmse: 0.539919\tvalid_1's rmse: 0.550486\n",
      "[4310]\ttraining's rmse: 0.539824\tvalid_1's rmse: 0.550411\n",
      "[4320]\ttraining's rmse: 0.539686\tvalid_1's rmse: 0.550295\n",
      "[4330]\ttraining's rmse: 0.539591\tvalid_1's rmse: 0.550226\n",
      "[4340]\ttraining's rmse: 0.539473\tvalid_1's rmse: 0.55013\n",
      "[4350]\ttraining's rmse: 0.539355\tvalid_1's rmse: 0.550027\n",
      "[4360]\ttraining's rmse: 0.53929\tvalid_1's rmse: 0.549987\n",
      "[4370]\ttraining's rmse: 0.539214\tvalid_1's rmse: 0.549926\n",
      "[4380]\ttraining's rmse: 0.539139\tvalid_1's rmse: 0.549871\n",
      "[4390]\ttraining's rmse: 0.539039\tvalid_1's rmse: 0.549785\n",
      "[4400]\ttraining's rmse: 0.538961\tvalid_1's rmse: 0.549733\n",
      "[4410]\ttraining's rmse: 0.538856\tvalid_1's rmse: 0.549643\n",
      "[4420]\ttraining's rmse: 0.538754\tvalid_1's rmse: 0.549566\n",
      "[4430]\ttraining's rmse: 0.538654\tvalid_1's rmse: 0.549492\n",
      "[4440]\ttraining's rmse: 0.538528\tvalid_1's rmse: 0.549414\n",
      "[4450]\ttraining's rmse: 0.538419\tvalid_1's rmse: 0.549332\n",
      "[4460]\ttraining's rmse: 0.538285\tvalid_1's rmse: 0.549238\n",
      "[4470]\ttraining's rmse: 0.538203\tvalid_1's rmse: 0.549172\n",
      "[4480]\ttraining's rmse: 0.538097\tvalid_1's rmse: 0.549081\n",
      "[4490]\ttraining's rmse: 0.537999\tvalid_1's rmse: 0.548998\n",
      "[4500]\ttraining's rmse: 0.537919\tvalid_1's rmse: 0.548935\n",
      "[4510]\ttraining's rmse: 0.537826\tvalid_1's rmse: 0.548845\n",
      "[4520]\ttraining's rmse: 0.537734\tvalid_1's rmse: 0.548769\n",
      "[4530]\ttraining's rmse: 0.537651\tvalid_1's rmse: 0.548701\n",
      "[4540]\ttraining's rmse: 0.537545\tvalid_1's rmse: 0.548609\n",
      "[4550]\ttraining's rmse: 0.537461\tvalid_1's rmse: 0.548543\n",
      "[4560]\ttraining's rmse: 0.537379\tvalid_1's rmse: 0.548483\n",
      "[4570]\ttraining's rmse: 0.537295\tvalid_1's rmse: 0.548419\n",
      "[4580]\ttraining's rmse: 0.537202\tvalid_1's rmse: 0.548341\n",
      "[4590]\ttraining's rmse: 0.537099\tvalid_1's rmse: 0.548254\n",
      "[4600]\ttraining's rmse: 0.537007\tvalid_1's rmse: 0.548176\n",
      "[4610]\ttraining's rmse: 0.536927\tvalid_1's rmse: 0.548114\n",
      "[4620]\ttraining's rmse: 0.536859\tvalid_1's rmse: 0.548075\n",
      "[4630]\ttraining's rmse: 0.536798\tvalid_1's rmse: 0.548026\n",
      "[4640]\ttraining's rmse: 0.536724\tvalid_1's rmse: 0.547983\n",
      "[4650]\ttraining's rmse: 0.536631\tvalid_1's rmse: 0.547908\n",
      "[4660]\ttraining's rmse: 0.536522\tvalid_1's rmse: 0.547822\n",
      "[4670]\ttraining's rmse: 0.536424\tvalid_1's rmse: 0.547748\n",
      "[4680]\ttraining's rmse: 0.536344\tvalid_1's rmse: 0.547687\n",
      "[4690]\ttraining's rmse: 0.536256\tvalid_1's rmse: 0.547627\n",
      "[4700]\ttraining's rmse: 0.536186\tvalid_1's rmse: 0.54758\n",
      "[4710]\ttraining's rmse: 0.536099\tvalid_1's rmse: 0.54751\n",
      "[4720]\ttraining's rmse: 0.536021\tvalid_1's rmse: 0.547448\n",
      "[4730]\ttraining's rmse: 0.535948\tvalid_1's rmse: 0.547384\n",
      "[4740]\ttraining's rmse: 0.535873\tvalid_1's rmse: 0.547323\n",
      "[4750]\ttraining's rmse: 0.535797\tvalid_1's rmse: 0.547267\n",
      "[4760]\ttraining's rmse: 0.535705\tvalid_1's rmse: 0.547191\n",
      "[4770]\ttraining's rmse: 0.535599\tvalid_1's rmse: 0.547114\n",
      "[4780]\ttraining's rmse: 0.535492\tvalid_1's rmse: 0.547041\n",
      "[4790]\ttraining's rmse: 0.535424\tvalid_1's rmse: 0.546997\n",
      "[4800]\ttraining's rmse: 0.535327\tvalid_1's rmse: 0.546933\n",
      "[4810]\ttraining's rmse: 0.535215\tvalid_1's rmse: 0.546838\n",
      "[4820]\ttraining's rmse: 0.535148\tvalid_1's rmse: 0.546776\n",
      "[4830]\ttraining's rmse: 0.535063\tvalid_1's rmse: 0.546699\n",
      "[4840]\ttraining's rmse: 0.534997\tvalid_1's rmse: 0.546644\n",
      "[4850]\ttraining's rmse: 0.534924\tvalid_1's rmse: 0.546593\n",
      "[4860]\ttraining's rmse: 0.534855\tvalid_1's rmse: 0.546535\n",
      "[4870]\ttraining's rmse: 0.534768\tvalid_1's rmse: 0.546465\n",
      "[4880]\ttraining's rmse: 0.534695\tvalid_1's rmse: 0.54641\n",
      "[4890]\ttraining's rmse: 0.534604\tvalid_1's rmse: 0.546329\n",
      "[4900]\ttraining's rmse: 0.534512\tvalid_1's rmse: 0.546253\n",
      "[4910]\ttraining's rmse: 0.534383\tvalid_1's rmse: 0.546144\n",
      "[4920]\ttraining's rmse: 0.534273\tvalid_1's rmse: 0.546037\n",
      "[4930]\ttraining's rmse: 0.534179\tvalid_1's rmse: 0.545959\n",
      "[4940]\ttraining's rmse: 0.534097\tvalid_1's rmse: 0.545868\n",
      "[4950]\ttraining's rmse: 0.534037\tvalid_1's rmse: 0.545825\n",
      "[4960]\ttraining's rmse: 0.53397\tvalid_1's rmse: 0.545777\n",
      "[4970]\ttraining's rmse: 0.533897\tvalid_1's rmse: 0.545724\n",
      "[4980]\ttraining's rmse: 0.533813\tvalid_1's rmse: 0.545655\n",
      "[4990]\ttraining's rmse: 0.533738\tvalid_1's rmse: 0.5456\n",
      "[5000]\ttraining's rmse: 0.533615\tvalid_1's rmse: 0.545496\n",
      "[5010]\ttraining's rmse: 0.533515\tvalid_1's rmse: 0.545395\n",
      "[5020]\ttraining's rmse: 0.533445\tvalid_1's rmse: 0.545328\n",
      "[5030]\ttraining's rmse: 0.533366\tvalid_1's rmse: 0.545265\n",
      "[5040]\ttraining's rmse: 0.533276\tvalid_1's rmse: 0.54519\n",
      "[5050]\ttraining's rmse: 0.533198\tvalid_1's rmse: 0.545118\n",
      "[5060]\ttraining's rmse: 0.533106\tvalid_1's rmse: 0.545041\n",
      "[5070]\ttraining's rmse: 0.533016\tvalid_1's rmse: 0.544964\n",
      "[5080]\ttraining's rmse: 0.532946\tvalid_1's rmse: 0.5449\n",
      "[5090]\ttraining's rmse: 0.532864\tvalid_1's rmse: 0.54483\n",
      "[5100]\ttraining's rmse: 0.532768\tvalid_1's rmse: 0.544739\n",
      "[5110]\ttraining's rmse: 0.532703\tvalid_1's rmse: 0.544684\n",
      "[5120]\ttraining's rmse: 0.532614\tvalid_1's rmse: 0.544619\n",
      "[5130]\ttraining's rmse: 0.532553\tvalid_1's rmse: 0.544588\n",
      "[5140]\ttraining's rmse: 0.532478\tvalid_1's rmse: 0.544524\n",
      "[5150]\ttraining's rmse: 0.53237\tvalid_1's rmse: 0.544429\n",
      "[5160]\ttraining's rmse: 0.53231\tvalid_1's rmse: 0.544395\n",
      "[5170]\ttraining's rmse: 0.532231\tvalid_1's rmse: 0.544324\n",
      "[5180]\ttraining's rmse: 0.532144\tvalid_1's rmse: 0.544252\n",
      "[5190]\ttraining's rmse: 0.532061\tvalid_1's rmse: 0.54417\n",
      "[5200]\ttraining's rmse: 0.531996\tvalid_1's rmse: 0.544121\n",
      "[5210]\ttraining's rmse: 0.531885\tvalid_1's rmse: 0.544022\n",
      "[5220]\ttraining's rmse: 0.531821\tvalid_1's rmse: 0.543958\n",
      "[5230]\ttraining's rmse: 0.531756\tvalid_1's rmse: 0.543902\n",
      "[5240]\ttraining's rmse: 0.53167\tvalid_1's rmse: 0.54383\n",
      "[5250]\ttraining's rmse: 0.531561\tvalid_1's rmse: 0.543736\n",
      "[5260]\ttraining's rmse: 0.531482\tvalid_1's rmse: 0.543673\n",
      "[5270]\ttraining's rmse: 0.531395\tvalid_1's rmse: 0.5436\n",
      "[5280]\ttraining's rmse: 0.531281\tvalid_1's rmse: 0.543505\n",
      "[5290]\ttraining's rmse: 0.531208\tvalid_1's rmse: 0.543445\n",
      "[5300]\ttraining's rmse: 0.531126\tvalid_1's rmse: 0.543373\n",
      "[5310]\ttraining's rmse: 0.531078\tvalid_1's rmse: 0.543337\n",
      "[5320]\ttraining's rmse: 0.530993\tvalid_1's rmse: 0.543263\n",
      "[5330]\ttraining's rmse: 0.530914\tvalid_1's rmse: 0.54321\n",
      "[5340]\ttraining's rmse: 0.530821\tvalid_1's rmse: 0.54312\n",
      "[5350]\ttraining's rmse: 0.530728\tvalid_1's rmse: 0.54305\n",
      "[5360]\ttraining's rmse: 0.530644\tvalid_1's rmse: 0.542969\n",
      "[5370]\ttraining's rmse: 0.530569\tvalid_1's rmse: 0.542906\n",
      "[5380]\ttraining's rmse: 0.530476\tvalid_1's rmse: 0.542821\n",
      "[5390]\ttraining's rmse: 0.530384\tvalid_1's rmse: 0.542741\n",
      "[5400]\ttraining's rmse: 0.530308\tvalid_1's rmse: 0.542695\n",
      "[5410]\ttraining's rmse: 0.530238\tvalid_1's rmse: 0.542654\n",
      "[5420]\ttraining's rmse: 0.530163\tvalid_1's rmse: 0.542587\n",
      "[5430]\ttraining's rmse: 0.530062\tvalid_1's rmse: 0.542512\n",
      "[5440]\ttraining's rmse: 0.529988\tvalid_1's rmse: 0.542465\n",
      "[5450]\ttraining's rmse: 0.529922\tvalid_1's rmse: 0.542413\n",
      "[5460]\ttraining's rmse: 0.529853\tvalid_1's rmse: 0.542358\n",
      "[5470]\ttraining's rmse: 0.529761\tvalid_1's rmse: 0.542291\n",
      "[5480]\ttraining's rmse: 0.529659\tvalid_1's rmse: 0.542204\n",
      "[5490]\ttraining's rmse: 0.529573\tvalid_1's rmse: 0.542126\n",
      "[5500]\ttraining's rmse: 0.529485\tvalid_1's rmse: 0.542049\n",
      "[5510]\ttraining's rmse: 0.529421\tvalid_1's rmse: 0.541987\n",
      "[5520]\ttraining's rmse: 0.529338\tvalid_1's rmse: 0.541924\n",
      "[5530]\ttraining's rmse: 0.529267\tvalid_1's rmse: 0.541874\n",
      "[5540]\ttraining's rmse: 0.529208\tvalid_1's rmse: 0.541821\n",
      "[5550]\ttraining's rmse: 0.529118\tvalid_1's rmse: 0.541742\n",
      "[5560]\ttraining's rmse: 0.529053\tvalid_1's rmse: 0.541695\n",
      "[5570]\ttraining's rmse: 0.528953\tvalid_1's rmse: 0.541605\n",
      "[5580]\ttraining's rmse: 0.528857\tvalid_1's rmse: 0.541512\n",
      "[5590]\ttraining's rmse: 0.528771\tvalid_1's rmse: 0.541431\n",
      "[5600]\ttraining's rmse: 0.528671\tvalid_1's rmse: 0.541332\n",
      "[5610]\ttraining's rmse: 0.528617\tvalid_1's rmse: 0.541287\n",
      "[5620]\ttraining's rmse: 0.528532\tvalid_1's rmse: 0.541226\n",
      "[5630]\ttraining's rmse: 0.528459\tvalid_1's rmse: 0.541171\n",
      "[5640]\ttraining's rmse: 0.528374\tvalid_1's rmse: 0.541106\n",
      "[5650]\ttraining's rmse: 0.528316\tvalid_1's rmse: 0.541064\n",
      "[5660]\ttraining's rmse: 0.528254\tvalid_1's rmse: 0.541014\n",
      "[5670]\ttraining's rmse: 0.528183\tvalid_1's rmse: 0.540949\n",
      "[5680]\ttraining's rmse: 0.528117\tvalid_1's rmse: 0.540897\n",
      "[5690]\ttraining's rmse: 0.52804\tvalid_1's rmse: 0.540824\n",
      "[5700]\ttraining's rmse: 0.527964\tvalid_1's rmse: 0.540764\n",
      "[5710]\ttraining's rmse: 0.527896\tvalid_1's rmse: 0.54071\n",
      "[5720]\ttraining's rmse: 0.527816\tvalid_1's rmse: 0.540653\n",
      "[5730]\ttraining's rmse: 0.527748\tvalid_1's rmse: 0.540591\n",
      "[5740]\ttraining's rmse: 0.527674\tvalid_1's rmse: 0.540533\n",
      "[5750]\ttraining's rmse: 0.527612\tvalid_1's rmse: 0.540475\n",
      "[5760]\ttraining's rmse: 0.527525\tvalid_1's rmse: 0.540402\n",
      "[5770]\ttraining's rmse: 0.52745\tvalid_1's rmse: 0.540346\n",
      "[5780]\ttraining's rmse: 0.527377\tvalid_1's rmse: 0.540269\n",
      "[5790]\ttraining's rmse: 0.527312\tvalid_1's rmse: 0.540228\n",
      "[5800]\ttraining's rmse: 0.527237\tvalid_1's rmse: 0.540174\n",
      "[5810]\ttraining's rmse: 0.527175\tvalid_1's rmse: 0.540135\n",
      "[5820]\ttraining's rmse: 0.527087\tvalid_1's rmse: 0.540067\n",
      "[5830]\ttraining's rmse: 0.527027\tvalid_1's rmse: 0.540022\n",
      "[5840]\ttraining's rmse: 0.526964\tvalid_1's rmse: 0.539985\n",
      "[5850]\ttraining's rmse: 0.52691\tvalid_1's rmse: 0.539953\n",
      "[5860]\ttraining's rmse: 0.526841\tvalid_1's rmse: 0.539911\n",
      "[5870]\ttraining's rmse: 0.526765\tvalid_1's rmse: 0.539872\n",
      "[5880]\ttraining's rmse: 0.526702\tvalid_1's rmse: 0.539842\n",
      "[5890]\ttraining's rmse: 0.526637\tvalid_1's rmse: 0.539793\n",
      "[5900]\ttraining's rmse: 0.526571\tvalid_1's rmse: 0.539746\n",
      "[5910]\ttraining's rmse: 0.52652\tvalid_1's rmse: 0.539716\n",
      "[5920]\ttraining's rmse: 0.526473\tvalid_1's rmse: 0.539691\n",
      "[5930]\ttraining's rmse: 0.526425\tvalid_1's rmse: 0.539667\n",
      "[5940]\ttraining's rmse: 0.526371\tvalid_1's rmse: 0.539621\n",
      "[5950]\ttraining's rmse: 0.526298\tvalid_1's rmse: 0.539557\n",
      "[5960]\ttraining's rmse: 0.526195\tvalid_1's rmse: 0.539467\n",
      "[5970]\ttraining's rmse: 0.526124\tvalid_1's rmse: 0.539412\n",
      "[5980]\ttraining's rmse: 0.526037\tvalid_1's rmse: 0.53934\n",
      "[5990]\ttraining's rmse: 0.525978\tvalid_1's rmse: 0.539301\n",
      "[6000]\ttraining's rmse: 0.525922\tvalid_1's rmse: 0.539275\n",
      "[6010]\ttraining's rmse: 0.52583\tvalid_1's rmse: 0.539196\n",
      "[6020]\ttraining's rmse: 0.525769\tvalid_1's rmse: 0.539158\n",
      "[6030]\ttraining's rmse: 0.525712\tvalid_1's rmse: 0.539105\n",
      "[6040]\ttraining's rmse: 0.525627\tvalid_1's rmse: 0.539046\n",
      "[6050]\ttraining's rmse: 0.525547\tvalid_1's rmse: 0.538984\n",
      "[6060]\ttraining's rmse: 0.525477\tvalid_1's rmse: 0.538929\n",
      "[6070]\ttraining's rmse: 0.525407\tvalid_1's rmse: 0.538878\n",
      "[6080]\ttraining's rmse: 0.525354\tvalid_1's rmse: 0.538836\n",
      "[6090]\ttraining's rmse: 0.525304\tvalid_1's rmse: 0.538804\n",
      "[6100]\ttraining's rmse: 0.52522\tvalid_1's rmse: 0.538724\n",
      "[6110]\ttraining's rmse: 0.525152\tvalid_1's rmse: 0.538667\n",
      "[6120]\ttraining's rmse: 0.525073\tvalid_1's rmse: 0.538613\n",
      "[6130]\ttraining's rmse: 0.525016\tvalid_1's rmse: 0.538576\n",
      "[6140]\ttraining's rmse: 0.524953\tvalid_1's rmse: 0.538525\n",
      "[6150]\ttraining's rmse: 0.524891\tvalid_1's rmse: 0.538486\n",
      "[6160]\ttraining's rmse: 0.524828\tvalid_1's rmse: 0.538424\n",
      "[6170]\ttraining's rmse: 0.524764\tvalid_1's rmse: 0.538376\n",
      "[6180]\ttraining's rmse: 0.524705\tvalid_1's rmse: 0.538336\n",
      "[6190]\ttraining's rmse: 0.524657\tvalid_1's rmse: 0.538301\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov 29 10:49:08 2017\n",
    "\n",
    "@author: Mengfei Li\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "#from ml_metrics import rmsle\n",
    "\n",
    "print(\"Loading Data ...\")\n",
    "# air_reserve\n",
    "df_ar = pd.read_csv('../../../mltestdata/05_recruit/air_reserve.csv')\n",
    "# air_store_info\n",
    "df_as = pd.read_csv('../../../mltestdata/05_recruit/air_store_info.csv')\n",
    "# air_visit_data\n",
    "df_av = pd.read_csv('../../../mltestdata/05_recruit/air_visit_data.csv')\n",
    "# hpg_reserve\n",
    "df_hr = pd.read_csv('../../../mltestdata/05_recruit/hpg_reserve.csv')\n",
    "# hpg_store_info\n",
    "df_hs = pd.read_csv('../../../mltestdata/05_recruit/hpg_store_info.csv')\n",
    "# date_info\n",
    "df_di = pd.read_csv('../../../mltestdata/05_recruit/date_info.csv')\n",
    "# sample_submission\n",
    "df_ss = pd.read_csv('../../../mltestdata/05_recruit/sample_submission.csv')\n",
    "# store_id_relation\n",
    "df_si = pd.read_csv('../../../mltestdata/05_recruit/store_id_relation.csv')\n",
    "\n",
    "# df_test\n",
    "df_test = pd.read_csv('../../../mltestdata/05_recruit/sample_submission.csv')\n",
    "df_test['air_store_id'] = df_test['id'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
    "df_test['visit_date'] = df_test['id'].apply(lambda x: x.split('_')[-1])\n",
    "index_test = df_test['id']\n",
    "del df_test['id'], df_test['visitors']\n",
    "\n",
    "gc.collect()\n",
    "print(\"Loading Data Compelete.\")\n",
    "\n",
    "print(\"=========================================================================================\")\n",
    "print(\"Data Exploring ...\")\n",
    "print(\"=========================================================================================\")\n",
    "print(\"Unique store id in different dataset :\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "num_store_ar = np.unique(df_ar['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_ar' is:\" + str(len(num_store_ar)))\n",
    "\n",
    "num_store_as = np.unique(df_as['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_as' is:\" + str(len(num_store_as)))\n",
    "\n",
    "num_store_av = np.unique(df_av['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_av' is:\" + str(len(num_store_av)))\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "num_store_in_hr = np.unique(df_hr['hpg_store_id'])\n",
    "print(\"Number of unique stores in 'df_hr' is:\" + str(len(num_store_in_hr)))\n",
    "\n",
    "num_store_in_hs = np.unique(df_hs['hpg_store_id'])\n",
    "print(\"Number of unique stores in 'df_hs' is:\" + str(len(num_store_in_hs)))\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "num_store_in_test = np.unique(df_test['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_test' is:\" + str(len(num_store_in_test)))\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "num_store_in_si = np.unique(df_si['air_store_id'])\n",
    "print(\"Number of unique stores in 'df_test' is:\" + str(len(num_store_in_si)))\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# remove outliers\n",
    "# =============================================================================\n",
    "def remove_outliers(data):\n",
    "    df_0 = data.loc[data.visitors == 0]   \n",
    "    q1 = np.percentile(data.visitors, 25, axis=0)\n",
    "    q3 = np.percentile(data.visitors, 75, axis=0)\n",
    "#    k = 5\n",
    "#    k = 2.5\n",
    "    k = 2.8\n",
    "#    k = 2\n",
    "#    k = 1.5\n",
    "    iqr = q3 - q1\n",
    "    df_temp = data.loc[data.visitors > q1 - k*iqr]\n",
    "    df_temp = data.loc[data.visitors < q3 + k*iqr]\n",
    "    frames = [df_0, df_temp]\n",
    "    result = pd.concat(frames)\n",
    "    return result\n",
    "\n",
    "df_av = remove_outliers(df_av)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# df to dict for mapping and dropping\n",
    "# =============================================================================\n",
    "print('mapping and dropping useless information in df_hr ...')\n",
    "s_1 = df_si['air_store_id']\n",
    "s_2 = df_si['hpg_store_id']\n",
    "a_h_map = dict(zip(s_2.values, s_1.values))\n",
    "del s_1, s_2\n",
    "\n",
    "df_hr['air_store_id'] = df_hr['hpg_store_id'].map(a_h_map)\n",
    "df_hr = df_hr.drop('hpg_store_id', axis=1).dropna()\n",
    "\n",
    "\n",
    "print('mapping and dropping useless information in df_hr Done!')\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "\n",
    "print('mapping and dropping useless information in df_hr ...')\n",
    "\n",
    "df_hs['air_store_id'] = df_hs['hpg_store_id'].map(a_h_map)\n",
    "df_hs = df_hs.drop('hpg_store_id', axis=1).dropna()\n",
    "print('mapping and dropping useless information in df_hs Done!')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# handle datetime (no clock info)\n",
    "# =============================================================================\n",
    "print('seperating date time features ...')\n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "def seperate_date(data):     \n",
    "    # split date feature in real visit datetime\n",
    "    data_time = pd.to_datetime(data.visit_date, format=time_format)\n",
    "    data['Year_visit']= data_time.dt.year\n",
    "    data['Month_visit'] = data_time.dt.month\n",
    "    data['DayOfYear_visit'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_visit'] = data_time.dt.day\n",
    "#    data['WeekOfYear_visit'] = data_time.dt.week\n",
    "    data['DayOfWeek_visit'] = data_time.dt.dayofweek\n",
    "#    del data['visit_date']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_av)\n",
    "seperate_date(df_test)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "def seperate_date(data):\n",
    "    # split date feature in reservation datetime\n",
    "    data_time = pd.to_datetime(data.reserve_datetime, format=time_format)\n",
    "    data['Year_re']= data_time.dt.year\n",
    "    data['Month_re'] = data_time.dt.month\n",
    "    data['DayOfYear_re'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_re'] = data_time.dt.day\n",
    "#    data['WeekOfYear_re'] = data_time.dt.week\n",
    "    data['DayOfWeek_re'] = data_time.dt.dayofweek\n",
    "    data['Hour_re'] = data_time.dt.hour\n",
    "#    del data['reserve_datetime']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_ar)\n",
    "\n",
    "\n",
    "def seperate_date(data):\n",
    "    # split date feature in reservation datetime\n",
    "    data_time = pd.to_datetime(data.reserve_datetime, format=time_format)\n",
    "    data['Year_re_h']= data_time.dt.year\n",
    "    data['Month_re_h'] = data_time.dt.month\n",
    "    data['DayOfYear_re_h'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_re_h'] = data_time.dt.day\n",
    "#    data['WeekOfYear_re_h'] = data_time.dt.week\n",
    "    data['DayOfWeek_re_h'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_h'] = data_time.dt.hour\n",
    "#    del data['reserve_datetime']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_hr)\n",
    "\n",
    "\n",
    "time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "def seperate_date(data):\n",
    "    # split date feature in reserved visiting datetime\n",
    "    data_time = pd.to_datetime(data.visit_datetime, format=time_format)\n",
    "    data['Year_re_visit']= data_time.dt.year\n",
    "    data['Month_re_visit'] = data_time.dt.month\n",
    "    data['DayOfYear_re_visit'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_re_visit'] = data_time.dt.day\n",
    "#    data['WeekOfYear_re_visit'] = data_time.dt.week\n",
    "    data['DayOfWeek_re_visit'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_visit'] = data_time.dt.hour\n",
    "#    del data['visit_datetime']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_ar)\n",
    "\n",
    "\n",
    "def seperate_date(data):\n",
    "    # split date feature in reserved visiting datetime\n",
    "    data_time = pd.to_datetime(data.visit_datetime, format=time_format)\n",
    "    data['Year_re_visit_h']= data_time.dt.year\n",
    "    data['Month_re_visit_h'] = data_time.dt.month\n",
    "    data['DayOfYear_re_visit_h'] = data_time.dt.dayofyear\n",
    "    # data['DayOfMonth_re_visit_h'] = data_time.dt.day\n",
    "    data['WeekOfYear_re_visit_h'] = data_time.dt.week\n",
    "    data['DayOfWeek_re_visit_h'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_visit_h'] = data_time.dt.hour\n",
    "#    del data['visit_datetime']\n",
    "    return data\n",
    "\n",
    "seperate_date(df_hr)\n",
    "\n",
    "print('seperating date time features done! ...')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# label encoding\n",
    "# =============================================================================\n",
    "print('label encoding ...')\n",
    "\n",
    "le.fit(df_as['air_genre_name'])\n",
    "df_as['air_genre_name'] = le.fit_transform(df_as['air_genre_name'])\n",
    "\n",
    "le.fit(df_as['air_area_name'])\n",
    "df_as['air_area_name'] = le.fit_transform(df_as['air_area_name'])\n",
    "\n",
    "le.fit(df_hs['hpg_genre_name'])\n",
    "df_hs['hpg_genre_name'] = le.fit_transform(df_hs['hpg_genre_name'])\n",
    "\n",
    "le.fit(df_hs['hpg_area_name'])\n",
    "df_hs['hpg_area_name'] = le.fit_transform(df_hs['hpg_area_name'])\n",
    "\n",
    "\n",
    "\n",
    "le.fit(df_as['air_store_id'])\n",
    "\n",
    "\n",
    "df_ar['air_store_id'] = le.transform(df_ar['air_store_id'])\n",
    "df_as['air_store_id'] = le.transform(df_as['air_store_id'])\n",
    "df_av['air_store_id'] = le.transform(df_av['air_store_id'])\n",
    "df_hr['air_store_id'] = le.transform(df_hr['air_store_id'])\n",
    "df_hs['air_store_id'] = le.transform(df_hs['air_store_id'])\n",
    "\n",
    "df_test['air_store_id'] = le.transform(df_test['air_store_id'])\n",
    "\n",
    "\n",
    "print('label encoding done !')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Merge dataset\n",
    "# =============================================================================\n",
    "features_to_drop = [\n",
    "        'air_store_id__'\n",
    "        ]\n",
    "\n",
    "def merge_df(data, data_to_join):\n",
    "    # merge dataframes        \n",
    "    data = data.join(data_to_join, on='air_store_id', rsuffix='__', how='left')   \n",
    "    return data\n",
    "\n",
    "def fix_data(data):\n",
    "    # drop __ data    \n",
    "    for feature in features_to_drop:\n",
    "        del data[feature]\n",
    "    return data\n",
    "\n",
    "# Merge to df_train\n",
    "print('merging dataframes ...')\n",
    "df_train = merge_df(df_av, df_ar)\n",
    "df_train = merge_df(df_train, df_as)\n",
    "\n",
    "df_hr['reserve_visitors_hr'] = df_hr['reserve_visitors'] \n",
    "del df_hr['reserve_visitors'] \n",
    "\n",
    "df_hs['latitude_hr'] = df_hs['latitude'] \n",
    "del df_hs['latitude'] \n",
    "\n",
    "df_hs['longitude_hr'] = df_hs['longitude'] \n",
    "del df_hs['longitude'] \n",
    "\n",
    "df_train = merge_df(df_train, df_hs)\n",
    "df_train = merge_df(df_train, df_hr)\n",
    "gc.collect()\n",
    "fix_data(df_train)\n",
    "\n",
    "# Merge to df_test\n",
    "\n",
    "df_test = merge_df(df_test, df_ar)\n",
    "df_test = merge_df(df_test, df_as)\n",
    "\n",
    "df_test = merge_df(df_test, df_hs)\n",
    "df_test = merge_df(df_test, df_hr)\n",
    "gc.collect()\n",
    "fix_data(df_test)\n",
    "\n",
    "\n",
    "print('merging dataframes done!')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# add holiday feature (for the visiting day)\n",
    "# =============================================================================\n",
    "df_di['visit_date'] = df_di['calendar_date']\n",
    "del df_di['calendar_date'] \n",
    "\n",
    "def add_is_holiday(data):\n",
    "    # merge dataframes        \n",
    "    data = data.merge(df_di, on='visit_date', how='left')\n",
    "    del data['day_of_week']\n",
    "    return data\n",
    "\n",
    "df_train = add_is_holiday(df_train)\n",
    "df_test = add_is_holiday(df_test)\n",
    "\n",
    "# =============================================================================\n",
    "# drop date-time-hour info\n",
    "# =============================================================================\n",
    "def drop_datetime_info(data):\n",
    "    del data['visit_date'], data['visit_datetime'], data['reserve_datetime'], data['visit_datetime__'], data['reserve_datetime__']\n",
    "#    del data['visit_date'], data['visit_datetime'], data['reserve_datetime']\n",
    "    return data\n",
    "df_train = drop_datetime_info(df_train)\n",
    "\n",
    "def drop_datetime_info(data):\n",
    "    del data['visit_date'], data['visit_datetime'], data['reserve_datetime'], data['visit_datetime__'], data['reserve_datetime__']\n",
    "#    del data['visit_date'], data['visit_datetime'], data['reserve_datetime']\n",
    "    return data\n",
    "df_test = drop_datetime_info(df_test)\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# autoclean\n",
    "# =============================================================================\n",
    "#df_train_clean = autoclean(df_train)\n",
    "#df_test_clean = autoclean(df_test)\n",
    "#\n",
    "train = df_train.fillna(-1)\n",
    "test = df_test.fillna(-1)\n",
    "#\n",
    "# =============================================================================\n",
    "# shuffle dataset\n",
    "# =============================================================================\n",
    "from sklearn.utils import shuffle\n",
    "train =  shuffle(train, random_state=21)\n",
    "\n",
    "\n",
    "X_train, X_valid = train_test_split(train, test_size=0.05, random_state=42, shuffle=False)\n",
    "\n",
    "X = X_train.drop(['visitors'], axis=1)\n",
    "y = np.log1p(X_train['visitors'].values)\n",
    "d_train = lgb.Dataset(X, y)\n",
    "\n",
    "X = X_valid.drop(['visitors'], axis=1)\n",
    "y = np.log1p(X_valid['visitors'].values)\n",
    "d_valid = lgb.Dataset(X, y)\n",
    "\n",
    "watchlist = [d_train, d_valid]\n",
    "\n",
    "print('Training LGBM model...')\n",
    "params = {}\n",
    "params['application'] = 'regression'\n",
    "params['boosting'] = 'gbdt'\n",
    "params['learning_rate'] = 0.01\n",
    "params['num_leaves'] = 32\n",
    "params['min_sum_hessian_in_leaf'] = 1e-2\n",
    "params['min_gain_to_split'] = 0\n",
    "\n",
    "params['bagging_fraction'] = 0.8\n",
    "params['feature_fraction'] = 0.8\n",
    "params['num_threads'] = 4\n",
    "params['metric'] = 'rmse'\n",
    "\n",
    "lgb_model1 = lgb.train(params, train_set=d_train, num_boost_round=50000, valid_sets=watchlist, \\\n",
    "verbose_eval=10)\n",
    "\n",
    "test_probs = lgb_model1.predict(test)\n",
    "test_probs = np.expm1(test_probs)\n",
    "\n",
    "result = pd.DataFrame({\"id\": index_test, \"visitors\": test_probs})\n",
    "    \n",
    "result.to_csv('LGB_sub.csv', index=False)\n",
    "    \n",
    "    # gbm.save_model(r\"..\\output\\models\\LGB_\"+str(file_name)+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
