{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test xgboost with Bayesian Optimsation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Contributions from:\n",
    "DSEverything - Mean Mix - Math, Geo, Harmonic (LB 0.493) \n",
    "https://www.kaggle.com/dongxu027/mean-mix-math-geo-harmonic-lb-0-493\n",
    "JdPaletto - Surprised Yet? - Part2 - (LB: 0.503)\n",
    "https://www.kaggle.com/jdpaletto/surprised-yet-part2-lb-0-503\n",
    "hklee - weighted mean comparisons, LB 0.497, 1ST\n",
    "https://www.kaggle.com/zeemeen/weighted-mean-comparisons-lb-0-497-1st\n",
    "\n",
    "Also all comments for changes, encouragement, and forked scripts rock\n",
    "\n",
    "Keep the Surprise Going\n",
    "\"\"\"\n",
    "\n",
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "\n",
    "data = {\n",
    "    'tra': pd.read_csv('../../../mltestdata/05_recruit/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('../../../mltestdata/05_recruit/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('../../../mltestdata/05_recruit/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('../../../mltestdata/05_recruit/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('../../../mltestdata/05_recruit/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('../../../mltestdata/05_recruit/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('../../../mltestdata/05_recruit/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('../../../mltestdata/05_recruit/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\n",
    "\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n",
    "\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "#sure it can be compressed...\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) \n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    stores['air_area_name'+str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n",
    "\n",
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n",
    "\n",
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n",
    "\n",
    "# NEW FEATURES FROM JMBULL\n",
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "\n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])\n",
    "\n",
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, dtype in zip(train.columns, train.dtypes):\t\n",
    "    if dtype == np.float64:\t\t\n",
    "        train[c] = train[c].astype(np.float32)\n",
    "\n",
    "for c, dtype in zip(test.columns, test.dtypes):\t\n",
    "    if dtype == np.float64:\t\t\n",
    "        test[c] = test[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols=['visitors','air_store_id','visit_date','id']\n",
    "y_train=train['visitors']\n",
    "x_train=train.drop(drop_cols, axis=1)\n",
    "\n",
    "x_test=test.copy()\n",
    "x_test=x_test.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.visitors\n",
    "train_input = train.copy()\n",
    "test_input = test.copy()\n",
    "\n",
    "drop_cols=['visitors','air_store_id','visit_date','id']\n",
    "train_input=train_input.drop(drop_cols, axis=1)\n",
    "test_input=test_input.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a evaluation function\n",
    "\n",
    "def rmsle(preds, true):\n",
    "    rmsle = np.sqrt(mean_squared_error(np.log1p(true), np.log1p(preds)))\n",
    "    return float(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a evaluation matrix \n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "RMSLE = make_scorer(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for comparing predictions and true data.\n",
    "def compare_result(preds, true):\n",
    "    compare = pd.DataFrame({\"test_id\": true.index,\n",
    "                           \"real_cost\": true,\n",
    "                           \"pred_cost\": preds})\n",
    "    compare = compare[[\"test_id\", \"real_cost\", \"pred_cost\"]].reset_index(drop=True)\n",
    "    \n",
    "    compare[\"error_percent_(%)\"] = np.abs(compare.real_cost - compare.pred_cost) / compare.real_cost * 100\n",
    "    \n",
    "    return compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_xgb(params, x_train, y_train, x_test, kf,  verbose=True, verbose_eval=50, scoreonly=False):\n",
    "    start_time=time.time()\n",
    "    nround=[]\n",
    "    # the prediction matrix need to contains 3 columns, one for the probability of each class\n",
    "    #train_pred = np.zeros((x_train.shape[0],3))\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "    \n",
    "    # self-defined eval metric\n",
    "    # f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "    # binary error\n",
    "    def feval_rmsle(preds, train_data):\n",
    "        preds = np.expm1(preds)\n",
    "        true = np.expm1(train_data.get_label())\n",
    "        #return 'rmsle', rmsle(true, preds), False\n",
    "\n",
    "        return 'rmsle', rmsle(preds, true), False\n",
    "\n",
    "    # use the k-fold object to enumerate indexes for each training and validation fold\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[val_index, :]\n",
    "\n",
    "        #y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "        y_train_kf, y_val_kf = np.log1p(y_train[train_index]), np.log1p(y_train[val_index])\n",
    "        x_test_kf=x_test.copy()\n",
    "        \n",
    "        d_train = xgboost.DMatrix(x_train_kf, y_train_kf)\n",
    "        d_val=xgboost.DMatrix(x_val_kf, y_val_kf)\n",
    "        d_test = xgboost.DMatrix(x_test_kf)\n",
    "        \n",
    "        watchlist= [(d_train, \"train\"), (d_val, 'val')]\n",
    "        bst = xgboost.train(params=params, \n",
    "                            dtrain=d_train, \n",
    "                            num_boost_round=8000, \n",
    "                            early_stopping_rounds=100,\n",
    "                            evals=watchlist, \n",
    "                            verbose_eval=verbose_eval)        \n",
    "        \n",
    "        y_val_kf_preds=bst.predict(d_val, ntree_limit=bst.best_ntree_limit)\n",
    "        nround.append(bst.best_ntree_limit)\n",
    "        \n",
    "        train_pred[val_index] += y_val_kf_preds\n",
    "#        test_pred += np.expm1((bst.predict(x_test, ntree_limit=bst.best_ntree_limit)))\n",
    "        test_pred += np.expm1(bst.predict(d_test))\n",
    "        \n",
    "        \n",
    "        #fold_cv = log_loss(y_val_kf.values, y_val_kf_preds)\n",
    "        fold_rmsle = rmsle(np.expm1(train_pred[val_index]),np.expm1(y_val_kf.values))\n",
    "        fold_cv = fold_rmsle\n",
    "        \n",
    "        if verbose:\n",
    "            print('fold cv {} rmsle score is {:.6f}'.format(i, fold_cv))\n",
    "\n",
    "    test_pred = test_pred / kf.n_splits\n",
    "    #cv_score = log_loss(y_train, train_pred)\n",
    "    cv_score = rmsle(np.expm1(train_pred), y_train)\n",
    "    \n",
    "    if verbose:\n",
    "        print('cv rmsle score is {:.6f}'.format(cv_score))    \n",
    "        end_time = time.time()\n",
    "        print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n",
    " \n",
    "    if scoreonly:\n",
    "        #return cv_score # for the purpose of bayesian optimisation, we only need to return the CV score\n",
    "        return cv_score\n",
    "    else:\n",
    "        return (cv_score,train_pred,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[0]\ttrain-rmse:2.32524\tval-rmse:2.32559\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.540204\tval-rmse:0.53997\n",
      "[100]\ttrain-rmse:0.503524\tval-rmse:0.505309\n",
      "[150]\ttrain-rmse:0.499514\tval-rmse:0.502423\n",
      "[200]\ttrain-rmse:0.496776\tval-rmse:0.500778\n",
      "[250]\ttrain-rmse:0.494905\tval-rmse:0.499717\n",
      "[300]\ttrain-rmse:0.493272\tval-rmse:0.498906\n",
      "[350]\ttrain-rmse:0.491967\tval-rmse:0.498327\n",
      "[400]\ttrain-rmse:0.490957\tval-rmse:0.497908\n",
      "[450]\ttrain-rmse:0.490155\tval-rmse:0.497603\n",
      "[500]\ttrain-rmse:0.489363\tval-rmse:0.497266\n",
      "[550]\ttrain-rmse:0.488451\tval-rmse:0.496836\n",
      "[600]\ttrain-rmse:0.487514\tval-rmse:0.496431\n",
      "[650]\ttrain-rmse:0.486539\tval-rmse:0.496022\n",
      "[700]\ttrain-rmse:0.485696\tval-rmse:0.495715\n",
      "[750]\ttrain-rmse:0.484827\tval-rmse:0.49546\n",
      "[800]\ttrain-rmse:0.483804\tval-rmse:0.495047\n",
      "[850]\ttrain-rmse:0.482952\tval-rmse:0.494719\n",
      "[900]\ttrain-rmse:0.482168\tval-rmse:0.494482\n",
      "[950]\ttrain-rmse:0.481562\tval-rmse:0.494301\n",
      "[1000]\ttrain-rmse:0.480814\tval-rmse:0.494054\n",
      "[1050]\ttrain-rmse:0.480012\tval-rmse:0.493791\n",
      "[1100]\ttrain-rmse:0.479324\tval-rmse:0.493595\n",
      "[1150]\ttrain-rmse:0.478773\tval-rmse:0.493429\n",
      "[1200]\ttrain-rmse:0.478046\tval-rmse:0.493214\n",
      "[1250]\ttrain-rmse:0.477428\tval-rmse:0.493005\n",
      "[1300]\ttrain-rmse:0.476701\tval-rmse:0.492765\n",
      "[1350]\ttrain-rmse:0.47595\tval-rmse:0.492572\n",
      "[1400]\ttrain-rmse:0.475158\tval-rmse:0.492323\n",
      "[1450]\ttrain-rmse:0.474332\tval-rmse:0.492041\n",
      "[1500]\ttrain-rmse:0.473621\tval-rmse:0.491837\n",
      "[1550]\ttrain-rmse:0.473025\tval-rmse:0.491685\n",
      "[1600]\ttrain-rmse:0.472488\tval-rmse:0.491509\n",
      "[1650]\ttrain-rmse:0.471771\tval-rmse:0.491256\n",
      "[1700]\ttrain-rmse:0.47114\tval-rmse:0.491073\n",
      "[1750]\ttrain-rmse:0.470507\tval-rmse:0.490888\n",
      "[1800]\ttrain-rmse:0.469836\tval-rmse:0.490709\n",
      "[1850]\ttrain-rmse:0.469227\tval-rmse:0.49057\n",
      "[1900]\ttrain-rmse:0.468669\tval-rmse:0.490445\n",
      "[1950]\ttrain-rmse:0.468034\tval-rmse:0.490332\n",
      "[2000]\ttrain-rmse:0.467419\tval-rmse:0.490198\n",
      "[2050]\ttrain-rmse:0.46673\tval-rmse:0.490037\n",
      "[2100]\ttrain-rmse:0.466148\tval-rmse:0.48989\n",
      "[2150]\ttrain-rmse:0.465562\tval-rmse:0.489783\n",
      "[2200]\ttrain-rmse:0.464924\tval-rmse:0.489635\n",
      "[2250]\ttrain-rmse:0.464368\tval-rmse:0.489546\n",
      "[2300]\ttrain-rmse:0.463796\tval-rmse:0.489516\n",
      "[2350]\ttrain-rmse:0.46323\tval-rmse:0.489441\n",
      "[2400]\ttrain-rmse:0.462723\tval-rmse:0.489387\n",
      "[2450]\ttrain-rmse:0.462198\tval-rmse:0.489335\n",
      "[2500]\ttrain-rmse:0.461749\tval-rmse:0.489242\n",
      "[2550]\ttrain-rmse:0.461295\tval-rmse:0.489186\n",
      "[2600]\ttrain-rmse:0.460796\tval-rmse:0.48913\n",
      "[2650]\ttrain-rmse:0.460287\tval-rmse:0.489032\n",
      "[2700]\ttrain-rmse:0.459727\tval-rmse:0.488946\n",
      "[2750]\ttrain-rmse:0.459258\tval-rmse:0.488894\n",
      "[2800]\ttrain-rmse:0.458814\tval-rmse:0.488843\n",
      "[2850]\ttrain-rmse:0.458431\tval-rmse:0.488833\n",
      "[2900]\ttrain-rmse:0.457994\tval-rmse:0.488814\n",
      "[2950]\ttrain-rmse:0.457549\tval-rmse:0.488747\n",
      "[3000]\ttrain-rmse:0.457112\tval-rmse:0.48869\n",
      "[3050]\ttrain-rmse:0.456656\tval-rmse:0.488581\n",
      "[3100]\ttrain-rmse:0.456243\tval-rmse:0.488536\n",
      "[3150]\ttrain-rmse:0.455792\tval-rmse:0.488512\n",
      "[3200]\ttrain-rmse:0.455358\tval-rmse:0.488479\n",
      "[3250]\ttrain-rmse:0.454947\tval-rmse:0.488449\n",
      "[3300]\ttrain-rmse:0.454549\tval-rmse:0.48843\n",
      "[3350]\ttrain-rmse:0.454113\tval-rmse:0.488407\n",
      "[3400]\ttrain-rmse:0.453736\tval-rmse:0.488424\n",
      "[3450]\ttrain-rmse:0.453361\tval-rmse:0.4884\n",
      "Stopping. Best iteration:\n",
      "[3354]\ttrain-rmse:0.454073\tval-rmse:0.4884\n",
      "\n",
      "[0]\ttrain-rmse:2.32335\tval-rmse:2.32577\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.537267\tval-rmse:0.543833\n",
      "[100]\ttrain-rmse:0.500992\tval-rmse:0.509049\n",
      "[150]\ttrain-rmse:0.497263\tval-rmse:0.506365\n",
      "[200]\ttrain-rmse:0.494761\tval-rmse:0.504844\n",
      "[250]\ttrain-rmse:0.493087\tval-rmse:0.504032\n",
      "[300]\ttrain-rmse:0.491341\tval-rmse:0.503011\n",
      "[350]\ttrain-rmse:0.490042\tval-rmse:0.502378\n",
      "[400]\ttrain-rmse:0.489075\tval-rmse:0.501852\n",
      "[450]\ttrain-rmse:0.488199\tval-rmse:0.501389\n",
      "[500]\ttrain-rmse:0.487399\tval-rmse:0.501021\n",
      "[550]\ttrain-rmse:0.486586\tval-rmse:0.500624\n",
      "[600]\ttrain-rmse:0.486105\tval-rmse:0.500498\n",
      "[650]\ttrain-rmse:0.485455\tval-rmse:0.500227\n",
      "[700]\ttrain-rmse:0.484803\tval-rmse:0.499918\n",
      "[750]\ttrain-rmse:0.484297\tval-rmse:0.499734\n",
      "[800]\ttrain-rmse:0.483883\tval-rmse:0.499639\n",
      "[850]\ttrain-rmse:0.483369\tval-rmse:0.49947\n",
      "[900]\ttrain-rmse:0.482876\tval-rmse:0.499291\n",
      "[950]\ttrain-rmse:0.482465\tval-rmse:0.499156\n",
      "[1000]\ttrain-rmse:0.482016\tval-rmse:0.499018\n",
      "[1050]\ttrain-rmse:0.481643\tval-rmse:0.498895\n",
      "[1100]\ttrain-rmse:0.481132\tval-rmse:0.498759\n",
      "[1150]\ttrain-rmse:0.480806\tval-rmse:0.498673\n",
      "[1200]\ttrain-rmse:0.480424\tval-rmse:0.498585\n",
      "[1250]\ttrain-rmse:0.479995\tval-rmse:0.498469\n",
      "[1300]\ttrain-rmse:0.479601\tval-rmse:0.498306\n",
      "[1350]\ttrain-rmse:0.479192\tval-rmse:0.498189\n",
      "[1400]\ttrain-rmse:0.478887\tval-rmse:0.498073\n",
      "[1450]\ttrain-rmse:0.478456\tval-rmse:0.497973\n",
      "[1500]\ttrain-rmse:0.478104\tval-rmse:0.497856\n",
      "[1550]\ttrain-rmse:0.477759\tval-rmse:0.497685\n",
      "[1600]\ttrain-rmse:0.477328\tval-rmse:0.49755\n",
      "[1650]\ttrain-rmse:0.476894\tval-rmse:0.497409\n",
      "[1700]\ttrain-rmse:0.476567\tval-rmse:0.497314\n",
      "[1750]\ttrain-rmse:0.476224\tval-rmse:0.497217\n",
      "[1800]\ttrain-rmse:0.475927\tval-rmse:0.497172\n",
      "[1850]\ttrain-rmse:0.475623\tval-rmse:0.497069\n",
      "[1900]\ttrain-rmse:0.475444\tval-rmse:0.497061\n",
      "[1950]\ttrain-rmse:0.47509\tval-rmse:0.496985\n",
      "[2000]\ttrain-rmse:0.474861\tval-rmse:0.49693\n",
      "[2050]\ttrain-rmse:0.474538\tval-rmse:0.496852\n",
      "[2100]\ttrain-rmse:0.474225\tval-rmse:0.496755\n",
      "[2150]\ttrain-rmse:0.473919\tval-rmse:0.496695\n",
      "[2200]\ttrain-rmse:0.473616\tval-rmse:0.496621\n",
      "[2250]\ttrain-rmse:0.473341\tval-rmse:0.496558\n",
      "[2300]\ttrain-rmse:0.473071\tval-rmse:0.496519\n",
      "[2350]\ttrain-rmse:0.472649\tval-rmse:0.49639\n",
      "[2400]\ttrain-rmse:0.472361\tval-rmse:0.496305\n",
      "[2450]\ttrain-rmse:0.472195\tval-rmse:0.496275\n",
      "[2500]\ttrain-rmse:0.471951\tval-rmse:0.496231\n",
      "[2550]\ttrain-rmse:0.471754\tval-rmse:0.496191\n",
      "[2600]\ttrain-rmse:0.471513\tval-rmse:0.496146\n",
      "[2650]\ttrain-rmse:0.471236\tval-rmse:0.496136\n",
      "[2700]\ttrain-rmse:0.470823\tval-rmse:0.496048\n",
      "[2750]\ttrain-rmse:0.470571\tval-rmse:0.49602\n",
      "[2800]\ttrain-rmse:0.470278\tval-rmse:0.495957\n",
      "[2850]\ttrain-rmse:0.46999\tval-rmse:0.49583\n",
      "[2900]\ttrain-rmse:0.469692\tval-rmse:0.495765\n",
      "[2950]\ttrain-rmse:0.469496\tval-rmse:0.49573\n",
      "[3000]\ttrain-rmse:0.46936\tval-rmse:0.495729\n",
      "[3050]\ttrain-rmse:0.469201\tval-rmse:0.495716\n",
      "[3100]\ttrain-rmse:0.468985\tval-rmse:0.495642\n",
      "[3150]\ttrain-rmse:0.468767\tval-rmse:0.495619\n",
      "[3200]\ttrain-rmse:0.468483\tval-rmse:0.495519\n",
      "[3250]\ttrain-rmse:0.468282\tval-rmse:0.495471\n",
      "[3300]\ttrain-rmse:0.468175\tval-rmse:0.495436\n",
      "[3350]\ttrain-rmse:0.467973\tval-rmse:0.49541\n",
      "[3400]\ttrain-rmse:0.467851\tval-rmse:0.495393\n",
      "[3450]\ttrain-rmse:0.467671\tval-rmse:0.49536\n",
      "[3500]\ttrain-rmse:0.467453\tval-rmse:0.495336\n",
      "[3550]\ttrain-rmse:0.467281\tval-rmse:0.495262\n",
      "[3600]\ttrain-rmse:0.467171\tval-rmse:0.495241\n",
      "[3650]\ttrain-rmse:0.466961\tval-rmse:0.495213\n",
      "[3700]\ttrain-rmse:0.466797\tval-rmse:0.495184\n",
      "[3750]\ttrain-rmse:0.466539\tval-rmse:0.49513\n",
      "[3800]\ttrain-rmse:0.466298\tval-rmse:0.495124\n",
      "Stopping. Best iteration:\n",
      "[3738]\ttrain-rmse:0.466575\tval-rmse:0.495112\n",
      "\n",
      "[0]\ttrain-rmse:2.32499\tval-rmse:2.32226\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.540569\tval-rmse:0.538473\n",
      "[100]\ttrain-rmse:0.504383\tval-rmse:0.502582\n",
      "[150]\ttrain-rmse:0.50112\tval-rmse:0.500128\n",
      "[200]\ttrain-rmse:0.499529\tval-rmse:0.499121\n",
      "[250]\ttrain-rmse:0.498474\tval-rmse:0.498505\n",
      "[300]\ttrain-rmse:0.497327\tval-rmse:0.497831\n",
      "[350]\ttrain-rmse:0.496365\tval-rmse:0.4974\n",
      "[400]\ttrain-rmse:0.495646\tval-rmse:0.497017\n",
      "[450]\ttrain-rmse:0.494966\tval-rmse:0.496689\n",
      "[500]\ttrain-rmse:0.494439\tval-rmse:0.496465\n",
      "[550]\ttrain-rmse:0.493769\tval-rmse:0.496188\n",
      "[600]\ttrain-rmse:0.493283\tval-rmse:0.495988\n",
      "[650]\ttrain-rmse:0.492718\tval-rmse:0.49573\n",
      "[700]\ttrain-rmse:0.492139\tval-rmse:0.495483\n",
      "[750]\ttrain-rmse:0.491638\tval-rmse:0.495294\n",
      "[800]\ttrain-rmse:0.491171\tval-rmse:0.495064\n",
      "[850]\ttrain-rmse:0.490666\tval-rmse:0.494867\n",
      "[900]\ttrain-rmse:0.490292\tval-rmse:0.494767\n",
      "[950]\ttrain-rmse:0.489678\tval-rmse:0.494532\n",
      "[1000]\ttrain-rmse:0.489239\tval-rmse:0.494377\n",
      "[1050]\ttrain-rmse:0.488481\tval-rmse:0.49408\n",
      "[1100]\ttrain-rmse:0.487809\tval-rmse:0.493808\n",
      "[1150]\ttrain-rmse:0.48694\tval-rmse:0.493433\n",
      "[1200]\ttrain-rmse:0.486295\tval-rmse:0.493183\n",
      "[1250]\ttrain-rmse:0.485663\tval-rmse:0.492973\n",
      "[1300]\ttrain-rmse:0.485136\tval-rmse:0.492765\n",
      "[1350]\ttrain-rmse:0.48444\tval-rmse:0.492546\n",
      "[1400]\ttrain-rmse:0.483782\tval-rmse:0.492293\n",
      "[1450]\ttrain-rmse:0.483202\tval-rmse:0.492062\n",
      "[1500]\ttrain-rmse:0.482719\tval-rmse:0.491875\n",
      "[1550]\ttrain-rmse:0.482201\tval-rmse:0.491645\n",
      "[1600]\ttrain-rmse:0.481707\tval-rmse:0.491511\n",
      "[1650]\ttrain-rmse:0.48122\tval-rmse:0.491382\n",
      "[1700]\ttrain-rmse:0.480682\tval-rmse:0.491234\n",
      "[1750]\ttrain-rmse:0.480156\tval-rmse:0.491037\n",
      "[1800]\ttrain-rmse:0.479502\tval-rmse:0.490785\n",
      "[1850]\ttrain-rmse:0.479055\tval-rmse:0.490665\n",
      "[1900]\ttrain-rmse:0.478628\tval-rmse:0.490483\n",
      "[1950]\ttrain-rmse:0.478181\tval-rmse:0.49038\n",
      "[2000]\ttrain-rmse:0.477775\tval-rmse:0.490252\n",
      "[2050]\ttrain-rmse:0.477319\tval-rmse:0.490155\n",
      "[2100]\ttrain-rmse:0.476933\tval-rmse:0.490022\n",
      "[2150]\ttrain-rmse:0.476559\tval-rmse:0.48987\n",
      "[2200]\ttrain-rmse:0.476246\tval-rmse:0.489813\n",
      "[2250]\ttrain-rmse:0.475817\tval-rmse:0.489668\n",
      "[2300]\ttrain-rmse:0.475351\tval-rmse:0.489505\n",
      "[2350]\ttrain-rmse:0.475048\tval-rmse:0.489431\n",
      "[2400]\ttrain-rmse:0.474626\tval-rmse:0.48933\n",
      "[2450]\ttrain-rmse:0.474267\tval-rmse:0.48925\n",
      "[2500]\ttrain-rmse:0.473884\tval-rmse:0.489184\n",
      "[2550]\ttrain-rmse:0.473427\tval-rmse:0.489026\n",
      "[2600]\ttrain-rmse:0.473045\tval-rmse:0.488964\n",
      "[2650]\ttrain-rmse:0.472665\tval-rmse:0.48889\n",
      "[2700]\ttrain-rmse:0.472272\tval-rmse:0.488863\n",
      "[2750]\ttrain-rmse:0.471931\tval-rmse:0.488803\n",
      "[2800]\ttrain-rmse:0.471562\tval-rmse:0.488727\n",
      "[2850]\ttrain-rmse:0.471285\tval-rmse:0.488669\n",
      "[2900]\ttrain-rmse:0.470874\tval-rmse:0.488567\n",
      "[2950]\ttrain-rmse:0.470499\tval-rmse:0.488453\n",
      "[3000]\ttrain-rmse:0.470059\tval-rmse:0.488329\n",
      "[3050]\ttrain-rmse:0.469775\tval-rmse:0.488282\n",
      "[3100]\ttrain-rmse:0.469477\tval-rmse:0.488237\n",
      "[3150]\ttrain-rmse:0.469204\tval-rmse:0.488161\n",
      "[3200]\ttrain-rmse:0.468796\tval-rmse:0.488049\n",
      "[3250]\ttrain-rmse:0.46842\tval-rmse:0.487985\n",
      "[3300]\ttrain-rmse:0.468007\tval-rmse:0.487872\n",
      "[3350]\ttrain-rmse:0.467592\tval-rmse:0.487754\n",
      "[3400]\ttrain-rmse:0.467336\tval-rmse:0.487726\n",
      "[3450]\ttrain-rmse:0.466933\tval-rmse:0.487668\n",
      "[3500]\ttrain-rmse:0.466527\tval-rmse:0.48758\n",
      "[3550]\ttrain-rmse:0.466129\tval-rmse:0.487484\n",
      "[3600]\ttrain-rmse:0.465839\tval-rmse:0.487437\n",
      "[3650]\ttrain-rmse:0.465501\tval-rmse:0.487373\n",
      "[3700]\ttrain-rmse:0.465052\tval-rmse:0.487271\n",
      "[3750]\ttrain-rmse:0.464636\tval-rmse:0.487165\n",
      "[3800]\ttrain-rmse:0.464245\tval-rmse:0.487104\n",
      "[3850]\ttrain-rmse:0.463789\tval-rmse:0.487\n",
      "[3900]\ttrain-rmse:0.463374\tval-rmse:0.486915\n",
      "[3950]\ttrain-rmse:0.463006\tval-rmse:0.486812\n",
      "[4000]\ttrain-rmse:0.46248\tval-rmse:0.486704\n",
      "[4050]\ttrain-rmse:0.462015\tval-rmse:0.486622\n",
      "[4100]\ttrain-rmse:0.461651\tval-rmse:0.48654\n",
      "[4150]\ttrain-rmse:0.461316\tval-rmse:0.486469\n",
      "[4200]\ttrain-rmse:0.460916\tval-rmse:0.486435\n",
      "[4250]\ttrain-rmse:0.460572\tval-rmse:0.486381\n",
      "[4300]\ttrain-rmse:0.460182\tval-rmse:0.486247\n",
      "[4350]\ttrain-rmse:0.459672\tval-rmse:0.486129\n",
      "[4400]\ttrain-rmse:0.45924\tval-rmse:0.486066\n",
      "[4450]\ttrain-rmse:0.458857\tval-rmse:0.486013\n",
      "[4500]\ttrain-rmse:0.458563\tval-rmse:0.48598\n",
      "[4550]\ttrain-rmse:0.458131\tval-rmse:0.485883\n",
      "[4600]\ttrain-rmse:0.457765\tval-rmse:0.485811\n",
      "[4650]\ttrain-rmse:0.457418\tval-rmse:0.485735\n",
      "[4700]\ttrain-rmse:0.457018\tval-rmse:0.485661\n",
      "[4750]\ttrain-rmse:0.456652\tval-rmse:0.485618\n",
      "[4800]\ttrain-rmse:0.456329\tval-rmse:0.485622\n",
      "[4850]\ttrain-rmse:0.455872\tval-rmse:0.485493\n",
      "[4900]\ttrain-rmse:0.455496\tval-rmse:0.48544\n",
      "[4950]\ttrain-rmse:0.455037\tval-rmse:0.485398\n",
      "[5000]\ttrain-rmse:0.454663\tval-rmse:0.48533\n",
      "[5050]\ttrain-rmse:0.454258\tval-rmse:0.485299\n",
      "[5100]\ttrain-rmse:0.453888\tval-rmse:0.485248\n",
      "[5150]\ttrain-rmse:0.453525\tval-rmse:0.485225\n",
      "[5200]\ttrain-rmse:0.453131\tval-rmse:0.485165\n",
      "[5250]\ttrain-rmse:0.452783\tval-rmse:0.485146\n",
      "[5300]\ttrain-rmse:0.452354\tval-rmse:0.485092\n",
      "[5350]\ttrain-rmse:0.451998\tval-rmse:0.485049\n",
      "[5400]\ttrain-rmse:0.451688\tval-rmse:0.484994\n",
      "[5450]\ttrain-rmse:0.451276\tval-rmse:0.484931\n",
      "[5500]\ttrain-rmse:0.450944\tval-rmse:0.484922\n",
      "[5550]\ttrain-rmse:0.450618\tval-rmse:0.48488\n",
      "[5600]\ttrain-rmse:0.450322\tval-rmse:0.484842\n",
      "[5650]\ttrain-rmse:0.44999\tval-rmse:0.484804\n",
      "[5700]\ttrain-rmse:0.449669\tval-rmse:0.4848\n",
      "[5750]\ttrain-rmse:0.449342\tval-rmse:0.484776\n",
      "[5800]\ttrain-rmse:0.448975\tval-rmse:0.48472\n",
      "[5850]\ttrain-rmse:0.448638\tval-rmse:0.484687\n",
      "[5900]\ttrain-rmse:0.448322\tval-rmse:0.484683\n",
      "[5950]\ttrain-rmse:0.447999\tval-rmse:0.484688\n",
      "[6000]\ttrain-rmse:0.447727\tval-rmse:0.484691\n",
      "Stopping. Best iteration:\n",
      "[5913]\ttrain-rmse:0.448227\tval-rmse:0.484668\n",
      "\n",
      "cv score is 0.489414\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \"objective\" : \"reg:linear\",\n",
    "    #\"num_class\" : 3,\n",
    "    #\"tree_method\" : \"hist\",\n",
    "    \"eval_metric\" : \"rmse\",\n",
    "    \"nthread\": 4,\n",
    "    \"seed\" : 0,\n",
    "    'silent': 1,\n",
    "\n",
    "    \"eta\":0.05,  # default 0.3\n",
    "    \"max_depth\" : 5, # default 6\n",
    "    \"subsample\" : 0.8, # default 1\n",
    "    \"colsample_bytree\" : 0.6, # default 1\n",
    "    \"gamma\": 0.5\n",
    "}\n",
    "\n",
    "# only do 3 fold CV here so that we save some running time on Kaggle Kernel\n",
    "kf=StratifiedKFold(n_splits=3, shuffle=True, random_state=2018)\n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "cv_score =cross_validate_xgb(xgb_params, train_input, y, test_input, kf, verbose=False, verbose_eval=50, scoreonly=True)\n",
    "\n",
    "print('cv score is {:.6f}'.format(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimsation - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'max_depth':(4,10),\n",
    "        'learning_rate':(0.05,0.3),\n",
    "        'subsample': (0.4, 1),\n",
    "        'colsample_bytree': (0.4, 1),\n",
    "        'gamma': (0.001, 10.0),\n",
    "        'min_child_weight': (0, 20),\n",
    "        'max_delta_step': (0, 10),\n",
    "        'n_estimators': (10, 25),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'max_features': (0.1, 0.999)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(xgb_wrapper)\n",
    "def xgbcv_func(max_depth, learning_rate, subsample, \n",
    "               colsample_bytree, gamma, min_child_weight, \n",
    "               max_delta_step, n_estimators, \n",
    "               min_samples_split, max_features,nthread=4, seed=0):\n",
    "    params = {\n",
    "        \"objective\" : \"reg:linear\",\n",
    "        #\"num_class\" : 3,\n",
    "        #\"tree_method\" : \"hist\",\n",
    "        \"eval_metric\" : \"rmse\",\n",
    "        \"nthread\": nthread,\n",
    "        \"seed\" : 0,\n",
    "        'silent': 1,\n",
    "\n",
    "        \"eta\":learning_rate,  # default 0.3\n",
    "        \"max_depth\" : int(max_depth), # default 6\n",
    "        \"subsample\" : subsample, # default 1\n",
    "        \"colsample_bytree\" : colsample_bytree, # default 1\n",
    "\n",
    "        'gamma': gamma,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'max_delta_step': max_delta_step,\n",
    "        'n_estimators': n_estimators,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'max_features': max_features    \n",
    "\n",
    "    }\n",
    "    \n",
    "    # for a more ideal out-of-fold model prediction for this dataset, we use 10-fold CV\n",
    "    kf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "    \n",
    "    # we will disable all the verbose setting in this functional call, so that we don't have too much information \n",
    "    # to read during the bayesian optimisation process.\n",
    "    return 1-cross_validate_xgb(params, train_input, y, test_input, kf, verbose=False, verbose_eval=False, scoreonly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo=BayesianOptimization(xgbcv_func, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   learning_rate |   max_delta_step |   max_depth |   max_features |   min_child_weight |   min_samples_split |   n_estimators |   subsample | \n",
      "    1 | 52m02s | \u001b[35m   0.51265\u001b[0m | \u001b[32m            0.7803\u001b[0m | \u001b[32m   3.6419\u001b[0m | \u001b[32m         0.1012\u001b[0m | \u001b[32m          7.2818\u001b[0m | \u001b[32m     6.0705\u001b[0m | \u001b[32m        0.3809\u001b[0m | \u001b[32m            5.6931\u001b[0m | \u001b[32m             9.5157\u001b[0m | \u001b[32m       20.7736\u001b[0m | \u001b[32m     0.7271\u001b[0m | \n",
      "    2 | 26m30s | \u001b[35m   0.51301\u001b[0m | \u001b[32m            0.9688\u001b[0m | \u001b[32m   3.7053\u001b[0m | \u001b[32m         0.2111\u001b[0m | \u001b[32m          4.9818\u001b[0m | \u001b[32m     8.3164\u001b[0m | \u001b[32m        0.9697\u001b[0m | \u001b[32m            8.6903\u001b[0m | \u001b[32m             4.6695\u001b[0m | \u001b[32m       15.4761\u001b[0m | \u001b[32m     0.5796\u001b[0m | \n",
      "    3 | 22m56s |    0.51055 |             0.9373 |    4.3357 |          0.2039 |           5.5973 |      7.2179 |         0.1338 |             4.7578 |             18.8519 |        18.6618 |      0.8157 | \n",
      "    4 | 28m31s |    0.50547 |             0.7208 |    4.5594 |          0.2690 |           5.7510 |      4.5022 |         0.3226 |            17.9203 |              3.3148 |        11.3466 |      0.6874 | \n",
      "    5 | 13m12s |    0.50563 |             0.4392 |    7.2499 |          0.2672 |           2.1283 |      7.4616 |         0.9798 |            13.5326 |              6.1049 |        21.8702 |      0.6940 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   learning_rate |   max_delta_step |   max_depth |   max_features |   min_child_weight |   min_samples_split |   n_estimators |   subsample | \n",
      "    6 | 06m51s |    0.49753 |             0.4033 |    9.3138 |          0.1972 |           7.6985 |      4.0451 |         0.1552 |             0.0752 |              3.3675 |        10.4031 |      0.6942 | \n",
      "    7 | 06m29s |    0.51021 |             0.9086 |    0.1565 |          0.2241 |           0.4536 |      6.1791 |         0.9232 |             0.5812 |              2.1443 |        24.7425 |      0.5621 | \n",
      "    8 | 03m55s |    0.50726 |             0.9232 |    0.0323 |          0.2588 |           9.9145 |      9.4858 |         0.3860 |            15.7341 |              4.8233 |        24.7829 |      0.4909 | \n",
      "    9 | 26m09s |    0.50952 |             0.4617 |    0.0507 |          0.0755 |           9.4991 |      5.9605 |         0.9323 |            17.7143 |             19.9889 |        12.6714 |      0.8324 | \n",
      "   10 | 19m56s |    0.50989 |             0.9014 |    0.3718 |          0.1386 |           0.1851 |      4.1281 |         0.9016 |             3.4580 |             19.3527 |        11.0237 |      0.5753 | \n",
      "   11 | 03m34s |    0.50783 |             0.4372 |    0.5183 |          0.2152 |           9.8642 |      9.5969 |         0.6727 |             1.2791 |             18.2681 |        20.2541 |      0.6783 | \n",
      "   12 | 25m14s |    0.51061 |             0.8275 |    0.2629 |          0.1827 |           0.0615 |      9.8409 |         0.3699 |            14.3687 |             10.7236 |        12.2820 |      0.9221 | \n",
      "   13 | 82m42s |    0.50977 |             0.9930 |    0.2580 |          0.0666 |           7.4486 |      4.1469 |         0.8774 |            10.9872 |             19.5196 |        24.2744 |      0.4820 | \n",
      "   14 | 28m32s |    0.50311 |             0.9329 |    9.9379 |          0.1025 |           8.5019 |      7.0449 |         0.9884 |            18.5757 |             19.1478 |        10.0001 |      0.8001 | \n",
      "   15 | 35m25s |    0.51276 |             0.9430 |    0.0403 |          0.0939 |           9.1233 |      4.4036 |         0.6921 |             7.9034 |             10.7583 |        10.0489 |      0.7832 | \n",
      "   16 | 17m55s |    0.50417 |             0.8896 |    8.3897 |          0.0942 |           9.9727 |      9.9860 |         0.8362 |             0.9162 |              6.5599 |        24.7330 |      0.9300 | \n",
      "   17 | 18m21s |    0.50749 |             0.9252 |    0.2258 |          0.2884 |           6.8550 |      5.4285 |         0.8586 |             9.4637 |              4.6990 |        18.9193 |      0.9730 | \n",
      "   18 | 25m18s |    0.51280 |             0.9761 |    0.2362 |          0.0788 |           0.0921 |      8.7211 |         0.1603 |             4.3785 |              2.3452 |        13.7451 |      0.4090 | \n"
     ]
    }
   ],
   "source": [
    "xgb_bo.maximize(init_points=5, n_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Final Results\n",
      "Maximum value: 0.486679\n",
      "Best parameters:  {'max_depth': 10.0, 'learning_rate': 0.05000000200182169, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0.001, 'min_child_weight': 20.0, 'max_delta_step': 0.0, 'n_estimators': 25.0, 'min_samples_split': 20.0, 'max_features': 0.10000000000000001}\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print('Maximum value: %f' % xgb_bo.res['max']['max_val'])\n",
    "print('Best parameters: ', xgb_bo.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Velification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold cv 0 rmsle score is 0.497094\n",
      "fold cv 1 rmsle score is 0.501248\n",
      "fold cv 2 rmsle score is 0.496586\n",
      "cv rmsle score is 0.498314\n",
      "it takes 307.088 seconds to perform cross validation\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \"objective\" : \"reg:linear\",\n",
    "    \"eval_metric\" : \"rmse\",\n",
    "    \"nthread\": 4,\n",
    "    \"seed\" : 0,\n",
    "    'silent': 1,\n",
    "    \"colsample_bytree\"  :  0.5555, \n",
    "    \"gamma\": 1.8385,\n",
    "    \"learning_rate\": 0.2968,\n",
    "    \"max_delta_step\": 8.3539,\n",
    "    \"max_depth\": 10,#9.6366,\n",
    "    \"max_features\": 0.6203,\n",
    "    \"min_child_weight\": 8.1246,\n",
    "    \"min_samples_split\": 16.2850,\n",
    "    \"n_estimators\": 14.1175,\n",
    "    \"subsample\": 0.7658,\n",
    "    \"seed\": 0,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "outcomes=cross_validate_xgb(xgb_params, train_input, y, test_input, kf, verbose_eval=False)\n",
    "\n",
    "xgb_cv=outcomes[0]\n",
    "xgb_train_pred=outcomes[1]\n",
    "xgb_test_pred=outcomes[2]\n",
    "\n",
    "xgb_train_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_train_pred)\n",
    "xgb_test_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_test_pred)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold cv 0 rmsle score is 0.491962\n",
      "fold cv 1 rmsle score is 0.496301\n",
      "fold cv 2 rmsle score is 0.490484\n",
      "cv rmsle score is 0.492923\n",
      "it takes 161.602 seconds to perform cross validation\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \"objective\" : \"reg:gamma\",\n",
    "    \"eval_metric\" : \"rmse\",\n",
    "    \"nthread\": 4,\n",
    "    \"seed\" : 0,\n",
    "    'silent': 1,\n",
    "    'max_depth': 10, \n",
    "    'learning_rate': 0.05000000200182169, \n",
    "    'subsample': 1.0, \n",
    "    'colsample_bytree': 1.0, \n",
    "    'gamma': 0.001, \n",
    "    'min_child_weight': 20.0, \n",
    "    'max_delta_step': 0.0, \n",
    "    'n_estimators': 25.0, \n",
    "    'min_samples_split': 20.0, \n",
    "    'max_features': 0.10000000000000001\n",
    "}\n",
    "\n",
    "outcomes=cross_validate_xgb(xgb_params, x_train, y_train, test_input, kf, verbose_eval=False)\n",
    "\n",
    "xgb_cv=outcomes[0]\n",
    "xgb_train_pred=outcomes[1]\n",
    "xgb_test_pred=outcomes[2]\n",
    "\n",
    "xgb_train_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_train_pred)\n",
    "xgb_test_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_test_pred)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold cv 0 rmsle score is 0.491962\n",
      "fold cv 1 rmsle score is 0.496301\n",
      "fold cv 2 rmsle score is 0.490484\n",
      "cv rmsle score is 0.492923\n",
      "it takes 177.738 seconds to perform cross validation\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \"objective\" : \"reg:gamma\",\n",
    "    \"eval_metric\" : \"rmse\",\n",
    "    \"nthread\": 4,\n",
    "    \"seed\" : 0,\n",
    "    'silent': 1,\n",
    "    'max_depth': 10, \n",
    "    'learning_rate': 0.05000000200182169, \n",
    "    'subsample': 1.0, \n",
    "    'colsample_bytree': 1.0, \n",
    "    'gamma': 0.001, \n",
    "    'min_child_weight': 20.0, \n",
    "    'max_delta_step': 0.0, \n",
    "    'n_estimators': 25.0, \n",
    "    'min_samples_split': 20.0, \n",
    "    'max_features': 0.10000000000000001\n",
    "}\n",
    "\n",
    "outcomes=cross_validate_xgb(xgb_params, x_train, y_train, test_input, kf, verbose_eval=False)\n",
    "\n",
    "xgb_cv=outcomes[0]\n",
    "xgb_train_pred=outcomes[1]\n",
    "xgb_test_pred=outcomes[2]\n",
    "\n",
    "xgb_train_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_train_pred)\n",
    "xgb_test_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_test_pred)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step |   Time |      Value |   colsample_bytree |     gamma |   learning_rate |   max_delta_step |   max_depth |   max_features |   min_child_weight |   min_samples_split |   n_estimators |   subsample | \n",
    "    1 | 52m02s |    0.51265 |             0.7803 |    3.6419 |          0.1012 |           7.2818 |      6.0705 |         0.3809 |             5.6931 |              9.5157 |        20.7736 |      0.7271 | \n",
    "    2 | 26m30s |    0.51301 |             0.9688 |    3.7053 |          0.2111 |           4.9818 |      8.3164 |         0.9697 |             8.6903 |              4.6695 |        15.4761 |      0.5796 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation...\n",
      "fold cv 0 rmsle score is 0.487422\n",
      "fold cv 1 rmsle score is 0.492397\n",
      "fold cv 2 rmsle score is 0.488326\n",
      "cv rmsle score is 0.489387\n",
      "it takes 1305.697 seconds to perform cross validation\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \"objective\" : \"reg:linear\",\n",
    "    \"eval_metric\" : \"rmse\",\n",
    "    'colsample_bytree': 0.7803, \n",
    "    \"nthread\": 4,\n",
    "    \"seed\" : 0,\n",
    "    'silent': 1,\n",
    "    'max_depth': 6, \n",
    "    'learning_rate': 0.1012, \n",
    "    'subsample': 0.7271, \n",
    "    'gamma': 3.6419, \n",
    "    'min_child_weight': 5.6931, \n",
    "    'max_delta_step': 7.2818, \n",
    "    'n_estimators': 20.7736, \n",
    "    'min_samples_split': 9.5157, \n",
    "    'max_features': 0.3809\n",
    "}\n",
    "\n",
    "print(\"Start validation...\")\n",
    "outcomes=cross_validate_xgb(xgb_params, x_train, y_train, test_input, kf, verbose_eval=False)\n",
    "\n",
    "xgb_cv=outcomes[0]\n",
    "xgb_train_pred=outcomes[1]\n",
    "xgb_test_pred=outcomes[2]\n",
    "\n",
    "xgb_train_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_train_pred)\n",
    "xgb_test_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_test_pred)\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good luck :)\n"
     ]
    }
   ],
   "source": [
    "test['visitors'] = xgb_test_pred_df.values\n",
    "sub = test[['id','visitors']].copy()\n",
    "sub.to_csv('submission_rs_recruit_v11_xgbm_v13_v03.csv', index=False)\n",
    "print('Good luck :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub8['id'] = sub1['id']\n",
    "sub8['visitors'] = 0.4*sub1['visitors']+0.1*sub2['visitors']+0.25*sub3['visitors']+0.25*sub4['visitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All these datasets are from different kaggle kernels\n",
    "stacked_1 = pd.read_csv('/Users/wolheelee/python/kaggle/PortoSeguroSafeDriverPrediction/input/kaggleportosegurosubmissions/stacked_1.csv')\n",
    "xgb_submit = pd.read_csv('/Users/wolheelee/python/kaggle/PortoSeguroSafeDriverPrediction/input/kaggleportosegurosubmissions/xgb_submit.csv')\n",
    "Froza_and_Pascal = pd.read_csv('/Users/wolheelee/python/kaggle/PortoSeguroSafeDriverPrediction/input/kaggleportosegurosubmissions/Froza_and_Pascal.csv')\n",
    "rgf_submit = pd.read_csv('/Users/wolheelee/python/kaggle/PortoSeguroSafeDriverPrediction/input/kaggleportosegurosubmissions/rgf_submit.csv')\n",
    "gpari = pd.read_csv('/Users/wolheelee/python/kaggle/PortoSeguroSafeDriverPrediction/input/kaggleportosegurosubmissions/gpari.csv')\n",
    "\n",
    "# Ensemble and create submission \n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = stacked_1['id']\n",
    "sub['target'] = np.exp(np.mean(\n",
    "\t[\t\n",
    "    sub_1['target'].apply(lambda x: np.log(x)),\\\n",
    "    Froza_and_Pascal['target'].apply(lambda x: np.log(x)),\\\n",
    "    rgf_submit['target'].apply(lambda x: np.log(x)),\\\n",
    "    gpari['target'].apply(lambda x: np.log(x)),\\\n",
    "\tstacked_1['target'].apply(lambda x: np.log(x)),\\\n",
    "\txgb_submit['target'].apply(lambda x: np.log(x))\\\n",
    "\t], axis =0))\n",
    "\n",
    "sub.to_csv('sub.csv', index = False, compression = 'gzip')\n",
    "#xgboost\n",
    "#Bopt\n",
    "#LB 0.489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
