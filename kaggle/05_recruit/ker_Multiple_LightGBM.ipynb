{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded - number visits: 252108\n",
      "Data merged - number visits in train: 252108\n",
      "Data merged - number visits in test: 32019\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import model_selection, ensemble, neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from subprocess import check_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data = {\n",
    "    'tra': pd.read_csv('../../../mltestdata/05_recruit/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('../../../mltestdata/05_recruit/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('../../../mltestdata/05_recruit/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('../../../mltestdata/05_recruit/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('../../../mltestdata/05_recruit/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('../../../mltestdata/05_recruit/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('../../../mltestdata/05_recruit/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('../../../mltestdata/05_recruit/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "data['hr'].drop('hpg_store_id',  axis=1, inplace=True)\n",
    "data['ar'] = data['ar'].append(data['hr'])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "test_id = data['tes']['id']\n",
    "data['tes'].drop('id', axis=1, inplace=True)\n",
    "print ('Data loaded - number visits: ' + str(data['tra'].shape[0]))\n",
    "\n",
    "# Create single data set with all relevant base data:\n",
    "data['tra']['visit_datetime'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow']     = data['tra']['visit_datetime'].dt.dayofweek\n",
    "data['ar']['res_visit_datetime'] = pd.to_datetime(data['ar']['visit_datetime'])\n",
    "data['ar']['reserve_datetime']   = pd.to_datetime(data['ar']['reserve_datetime'])\n",
    "data['ar']['visit_date']         = data['ar']['res_visit_datetime'].dt.date\n",
    "data['ar']['reserve_diff'] = data['ar'].apply(lambda r: (r['res_visit_datetime']\n",
    "                                                         - r['reserve_datetime']).days, \n",
    "                                        axis=1)\n",
    "data['ar'].drop('visit_datetime',  axis=1, inplace=True)\n",
    "data['ar'].drop('reserve_datetime',  axis=1, inplace=True)\n",
    "data['ar'].drop('res_visit_datetime',  axis=1, inplace=True)\n",
    "avg_reserv = data['ar'].groupby(['air_store_id','visit_date'], \n",
    "                                as_index=False).mean().reset_index()\n",
    "data['ar'] = data['ar'].groupby(['air_store_id','visit_date'], \n",
    "                                as_index=False).sum().reset_index()\n",
    "data['ar'] = data['ar'].drop(['reserve_diff'],axis=1)\n",
    "data['ar'] = data['ar'].drop(['index'],axis=1)\n",
    "data['ar']['reserve_diff'] = avg_reserv['reserve_diff']  \n",
    "data['ar']['visit_date'] = data['ar']['visit_date'].astype(str)    \n",
    "\n",
    "data['tes']['visit_datetime'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow']     = data['tes']['visit_datetime'].dt.dayofweek\n",
    "\n",
    "prep_df = pd.merge(data['tra'], data['ar'],  how='left', on=['air_store_id', 'visit_date'])\n",
    "prep_df = pd.merge(prep_df,     data['as'],  how='inner', on='air_store_id')\n",
    "prep_df = pd.merge(prep_df,     data['hol'], how='left',  on='visit_date')\n",
    "print ('Data merged - number visits in train: ' + str(prep_df.shape[0]))\n",
    "predict_data = pd.merge(data['tes'],  data['ar'],   how='left', on=['air_store_id', 'visit_date'])\n",
    "predict_data = pd.merge(predict_data, data['as'],   how='inner', on='air_store_id')\n",
    "predict_data = pd.merge(predict_data, data['hol'],  how='left', on='visit_date')\n",
    "print ('Data merged - number visits in test: ' + str(predict_data.shape[0]))\n",
    "\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].min().rename(\n",
    "    columns={'visitors': 'min_visitors'})\n",
    "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].mean().rename(\n",
    "    columns={'visitors': 'mean_visitors'})\n",
    "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].median().rename(\n",
    "    columns={'visitors': 'median_visitors'})\n",
    "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].max().rename(\n",
    "    columns={'visitors': 'max_visitors'})\n",
    "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].count().rename(\n",
    "    columns={'visitors': 'count_observations'})\n",
    "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n",
    "\n",
    "prep_df.drop('dow',  axis=1, inplace=True)\n",
    "predict_data.drop('dow',  axis=1, inplace=True)\n",
    "\n",
    "# Encode fields:\n",
    "prep_df['month'] = prep_df['visit_datetime'].dt.month\n",
    "#prep_df['day']   = prep_df['visit_datetime'].dt.day\n",
    "prep_df['woy']   = prep_df['visit_datetime'].dt.weekofyear\n",
    "prep_df.drop('visit_datetime',      axis=1, inplace=True)   \n",
    "predict_data['month'] = predict_data['visit_datetime'].dt.month\n",
    "#predict_data['day']   = predict_data['visit_datetime'].dt.day\n",
    "predict_data['woy']   = predict_data['visit_datetime'].dt.weekofyear\n",
    "predict_data.drop('visit_datetime', axis=1, inplace=True)\n",
    "prep_df.fillna(-1, inplace=True)\n",
    "predict_data.fillna(-1, inplace=True)\n",
    "\n",
    "# Encode labels of categorical columns:\n",
    "cat_features = [col for col in ['air_genre_name', 'air_area_name', 'day_of_week']]\n",
    "for column in cat_features:\n",
    "    temp_prep = pd.get_dummies(pd.Series(prep_df[column]))\n",
    "    prep_df = pd.concat([prep_df,temp_prep],axis=1)\n",
    "    prep_df = prep_df.drop([column],axis=1)\n",
    "    temp_predict = pd.get_dummies(pd.Series(predict_data[column]))\n",
    "    predict_data = pd.concat([predict_data,temp_predict],axis=1)\n",
    "    predict_data = predict_data.drop([column],axis=1)\n",
    "    for missing_col in temp_prep:     # Make sure the columns of train and test are identical\n",
    "        if missing_col not in predict_data.columns:\n",
    "            predict_data[missing_col] = 0\n",
    "    for missing_col in temp_predict:     # Make sure the columns of train and test are identical\n",
    "        if missing_col not in prep_df.columns:\n",
    "            prep_df[missing_col] = 0        \n",
    "\n",
    "# Try runs without these columns:\n",
    "#prep_df = prep_df.drop(['reserve_visitors'],axis=1)\n",
    "#prep_df = prep_df.drop(['reserve_diff'],axis=1)\n",
    "#prep_df = prep_df.drop(['latitude'],axis=1)\n",
    "#prep_df = prep_df.drop(['longitude'],axis=1)\n",
    "#predict_data = predict_data.drop(['reserve_visitors'],axis=1)\n",
    "#predict_data = predict_data.drop(['reserve_diff'],axis=1)\n",
    "#predict_data = predict_data.drop(['latitude'],axis=1)\n",
    "#predict_data = predict_data.drop(['longitude'],axis=1)  \n",
    "\n",
    "prep_df['visitors'] = np.log1p(prep_df['visitors'])\n",
    "print('Done')\n",
    "\n",
    "prep_df = prep_df[prep_df['visit_date'] >= '2016-06-29']\n",
    "#prep_df.head()\n",
    "\n",
    "prep_df.drop(['visit_date'], axis=1, inplace=True)\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "label_enc.fit(prep_df['air_store_id'])\n",
    "prep_df['air_store_id'] = label_enc.transform(prep_df['air_store_id'])\n",
    "prep_cols = prep_df.columns\n",
    "\n",
    "predict_data.drop(['visit_date'], axis=1, inplace=True)  \n",
    "predict_data['air_store_id'] = label_enc.transform(predict_data['air_store_id'])\n",
    " \n",
    "X_train = prep_df.drop(['visitors'], axis=1)\n",
    "y_train = prep_df['visitors'].values    \n",
    "X_test = predict_data.drop(['visitors'], axis=1)\n",
    "# Submissions are evaluated using RMSLE:\n",
    "def RMSLE(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5\n",
    "    \n",
    "lgb_params1 = {}\n",
    "lgb_params1['application'] = 'regression'\n",
    "lgb_params1['boosting'] = 'gbdt'\n",
    "lgb_params1['learning_rate'] = 0.015\n",
    "lgb_params1['num_leaves'] = 32\n",
    "lgb_params1['min_sum_hessian_in_leaf'] = 2e-2\n",
    "lgb_params1['min_gain_to_split'] = 0\n",
    "lgb_params1['bagging_fraction'] = 0.9\n",
    "lgb_params1['feature_fraction'] = 0.9\n",
    "lgb_params1['num_threads'] = 8\n",
    "lgb_params1['metric'] = 'rmse'\n",
    "\n",
    "lgb_params2 = {}\n",
    "lgb_params2['application'] = 'regression'\n",
    "lgb_params2['boosting'] = 'gbdt'\n",
    "lgb_params2['learning_rate'] = 0.02\n",
    "lgb_params2['lambda_l1'] = 0.5\n",
    "lgb_params2['num_leaves'] = 32\n",
    "lgb_params2['min_gain_to_split'] = 0\n",
    "lgb_params2['bagging_fraction'] = 0.8\n",
    "lgb_params2['feature_fraction'] = 0.8\n",
    "lgb_params2['num_threads'] = 4\n",
    "lgb_params2['metric'] = 'rmse'\n",
    "\n",
    "lgb_params3 = {}\n",
    "lgb_params3['application'] = 'regression'\n",
    "lgb_params3['boosting'] = 'gbdt'\n",
    "lgb_params3['learning_rate'] = 0.022\n",
    "lgb_params3['num_leaves'] = 32\n",
    "lgb_params2['lambda_l2'] = 0.3\n",
    "lgb_params3['bagging_freq'] = 8\n",
    "lgb_params3['min_gain_to_split'] = 0\n",
    "lgb_params3['bagging_fraction'] = 0.8\n",
    "lgb_params3['feature_fraction'] = 0.8\n",
    "lgb_params3['num_threads'] = 4\n",
    "lgb_params3['metric'] = 'rmse'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(X_train, X_valid, lgb_params, rounds):\n",
    "    X_t = X_train.drop(['visitors'], axis=1)\n",
    "    y_t = X_train['visitors'].values\n",
    "    d_train = lgb.Dataset(X_t, y_t)\n",
    "    X_v = X_valid.drop(['visitors'], axis=1)\n",
    "    y_v = X_valid['visitors'].values\n",
    "    d_valid = lgb.Dataset(X_v, y_v)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    lgb_model = lgb.train(lgb_params, train_set=d_train, num_boost_round=rounds, \n",
    "                          valid_sets=watchlist, verbose_eval=1000, early_stopping_rounds = 300)\n",
    "    test_pred = lgb_model.predict(X_v)\n",
    "    rmsle = RMSLE(y_v, test_pred)\n",
    "    print(X_t.columns)\n",
    "    print(lgb_model.feature_importance())\n",
    "    return rmsle, lgb_model\n",
    "\n",
    "#print('Train with neighbors...')\n",
    "#X_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=74, shuffle=True)\n",
    "#model_gb = neighbors.KNeighborsRegressor(n_jobs=-1, n_neighbors=4)                                            \n",
    "#X_t = X_train.drop(['visitors'], axis=1)\n",
    "#y_t = X_train['visitors'].values                                            \n",
    "#model_gb.fit(X_t, y_t)\n",
    "#X_v = X_valid.drop(['visitors'], axis=1)\n",
    "#y_v = X_valid['visitors'].values\n",
    "#val_pred = model_gb.predict(X_v)\n",
    "#rmsle = RMSLE(y_v, val_pred)\n",
    "#test_pred = model_gb.predict(X_test)\n",
    "#print('Test RMSLE: %.3f' % rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>reserve_diff</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>Ōsaka-fu Ōsaka-shi Shinmachi</th>\n",
       "      <th>Ōsaka-fu Ōsaka-shi Ōgimachi</th>\n",
       "      <th>Ōsaka-fu Ōsaka-shi Ōhiraki</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>603</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>23.843750</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>603</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.292308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>603</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>34.738462</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>603</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>27.651515</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>603</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.754386</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     air_store_id  visitors  reserve_visitors  reserve_diff   latitude  \\\n",
       "138           603  3.526361              -1.0          -1.0  35.658068   \n",
       "139           603  3.526361              -1.0          -1.0  35.658068   \n",
       "140           603  4.127134              -1.0          -1.0  35.658068   \n",
       "141           603  3.258097              -1.0          -1.0  35.658068   \n",
       "142           603  3.091042              -1.0          -1.0  35.658068   \n",
       "\n",
       "      longitude  holiday_flg  min_visitors  mean_visitors  median_visitors  \\\n",
       "138  139.751599            0             7      23.843750             25.0   \n",
       "139  139.751599            0             2      20.292308             21.0   \n",
       "140  139.751599            0             4      34.738462             35.0   \n",
       "141  139.751599            0             6      27.651515             27.0   \n",
       "142  139.751599            0             2      13.754386             12.0   \n",
       "\n",
       "       ...      Ōsaka-fu Ōsaka-shi Shinmachi  Ōsaka-fu Ōsaka-shi Ōgimachi  \\\n",
       "138    ...                                 0                            0   \n",
       "139    ...                                 0                            0   \n",
       "140    ...                                 0                            0   \n",
       "141    ...                                 0                            0   \n",
       "142    ...                                 0                            0   \n",
       "\n",
       "     Ōsaka-fu Ōsaka-shi Ōhiraki  Friday  Monday  Saturday  Sunday  Thursday  \\\n",
       "138                           0       0       0         0       0         0   \n",
       "139                           0       0       0         0       0         1   \n",
       "140                           0       1       0         0       0         0   \n",
       "141                           0       0       0         1       0         0   \n",
       "142                           0       0       1         0       0         0   \n",
       "\n",
       "     Tuesday  Wednesday  \n",
       "138        0          1  \n",
       "139        0          0  \n",
       "140        0          0  \n",
       "141        0          0  \n",
       "142        0          0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\ttraining's rmse: 0.48253\tvalid_1's rmse: 0.491393\n",
      "[2000]\ttraining's rmse: 0.473497\tvalid_1's rmse: 0.488381\n",
      "[3000]\ttraining's rmse: 0.46557\tvalid_1's rmse: 0.486186\n",
      "[4000]\ttraining's rmse: 0.457822\tvalid_1's rmse: 0.484689\n",
      "[5000]\ttraining's rmse: 0.451477\tvalid_1's rmse: 0.483925\n",
      "[6000]\ttraining's rmse: 0.445752\tvalid_1's rmse: 0.483213\n",
      "[7000]\ttraining's rmse: 0.440508\tvalid_1's rmse: 0.482886\n",
      "[8000]\ttraining's rmse: 0.435542\tvalid_1's rmse: 0.482591\n",
      "[9000]\ttraining's rmse: 0.430926\tvalid_1's rmse: 0.482436\n",
      "Early stopping, best iteration is:\n",
      "[8749]\ttraining's rmse: 0.431942\tvalid_1's rmse: 0.482396\n",
      "Index(['air_store_id', 'reserve_visitors', 'reserve_diff', 'latitude',\n",
      "       'longitude', 'holiday_flg', 'min_visitors', 'mean_visitors',\n",
      "       'median_visitors', 'max_visitors',\n",
      "       ...\n",
      "       'Ōsaka-fu Ōsaka-shi Shinmachi', 'Ōsaka-fu Ōsaka-shi Ōgimachi',\n",
      "       'Ōsaka-fu Ōsaka-shi Ōhiraki', 'Friday', 'Monday', 'Saturday', 'Sunday',\n",
      "       'Thursday', 'Tuesday', 'Wednesday'],\n",
      "      dtype='object', length=137)\n",
      "[24727 11862  7507 10322  8419  3887 14319 23504 16412 23715 19323 15966\n",
      " 51007    69  1368  2222   460  1585    68   803  1612   699   159   368\n",
      "   596   289   518   395   282   133    81   212   158   170    87    22\n",
      "    73   196   308   131     8   222   689    88     0   121     4    81\n",
      "   104   118   217    44   287   104   256   180   217   113   181   374\n",
      "    37   110   231   238   205   131   182    78   129    56   213   410\n",
      "   201   227    42    76   159    93   126   104   143   156   154    77\n",
      "    23   349    56   449    46   642    31   104    87    59    53   121\n",
      "    57   375    93   151   110   713   138   117   557   345   294   349\n",
      "    83   145    42   181   197   123     1   133    80    32   174    62\n",
      "   100    92   143    64   236   136   345   173   483   282  1555  1626\n",
      "  1826  1644  1603  1693  1626]\n",
      "Test RMSLE: 0.482\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\ttraining's rmse: 0.479909\tvalid_1's rmse: 0.489383\n",
      "[2000]\ttraining's rmse: 0.46779\tvalid_1's rmse: 0.48528\n",
      "[3000]\ttraining's rmse: 0.458517\tvalid_1's rmse: 0.483329\n",
      "[4000]\ttraining's rmse: 0.450688\tvalid_1's rmse: 0.482305\n",
      "[5000]\ttraining's rmse: 0.443995\tvalid_1's rmse: 0.481792\n",
      "[6000]\ttraining's rmse: 0.437403\tvalid_1's rmse: 0.481431\n",
      "[7000]\ttraining's rmse: 0.431704\tvalid_1's rmse: 0.481363\n",
      "Early stopping, best iteration is:\n",
      "[6732]\ttraining's rmse: 0.433087\tvalid_1's rmse: 0.481324\n",
      "Index(['air_store_id', 'reserve_visitors', 'reserve_diff', 'latitude',\n",
      "       'longitude', 'holiday_flg', 'min_visitors', 'mean_visitors',\n",
      "       'median_visitors', 'max_visitors',\n",
      "       ...\n",
      "       'Ōsaka-fu Ōsaka-shi Shinmachi', 'Ōsaka-fu Ōsaka-shi Ōgimachi',\n",
      "       'Ōsaka-fu Ōsaka-shi Ōhiraki', 'Friday', 'Monday', 'Saturday', 'Sunday',\n",
      "       'Thursday', 'Tuesday', 'Wednesday'],\n",
      "      dtype='object', length=137)\n",
      "[19107  9310  6499  8878  7343  2180 10861 19403 13338 19472 15924 13309\n",
      " 37702    72   686  1365   236  1001    73   526   914   561    76   229\n",
      "   350   205   268   197   251    93    14   147    48   114    63    25\n",
      "    94    97   226    91     4   216   548    96     2   127    14    70\n",
      "    65    83   133    54   222   221   261   114   174   108    72   179\n",
      "    38    50   172   156   135    97   128    42   102    59   136   220\n",
      "   184   191    25    56    71    11    90    64    90   105   156    88\n",
      "     1   215   144   253    19   398     9    48    57    77    45    92\n",
      "    43   187    98   103    91   330    91    69   283   198   184   165\n",
      "    71   124     3   104    44   133     0    39    70    58   165    55\n",
      "    96    67    95    64   216   126   206   101   311   159   818   864\n",
      "  1105   967   900   942  1012]\n",
      "Test RMSLE: 0.481\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\ttraining's rmse: 0.476325\tvalid_1's rmse: 0.488016\n",
      "[2000]\ttraining's rmse: 0.4624\tvalid_1's rmse: 0.484425\n",
      "[3000]\ttraining's rmse: 0.45155\tvalid_1's rmse: 0.482637\n",
      "[4000]\ttraining's rmse: 0.443073\tvalid_1's rmse: 0.481947\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=74, shuffle=True)\n",
    "rmsle, lgb_model1 = do_train(X_train, X_valid, lgb_params1, 12000)\n",
    "test_pred1 = np.expm1(lgb_model1.predict(X_test))\n",
    "print('Test RMSLE: %.3f' % rmsle)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=2121, shuffle=True)\n",
    "rmsle, lgb_model2 = do_train(X_train, X_valid, lgb_params2, 10000)\n",
    "test_pred2 = np.expm1(lgb_model2.predict(X_test))\n",
    "print('Test RMSLE: %.3f' % rmsle)   \n",
    "\n",
    "X_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=4, shuffle=True)\n",
    "rmsle, lgb_model3 = do_train(X_train, X_valid, lgb_params3, 8000)\n",
    "test_pred3 = np.expm1(lgb_model3.predict(X_test))\n",
    "print('Test RMSLE: %.3f' % rmsle)   \n",
    "\n",
    "X_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=19, shuffle=True)\n",
    "rmsle, lgb_model4 = do_train(X_train, X_valid, lgb_params3, 8000)\n",
    "test_pred4 = np.expm1(lgb_model4.predict(X_test))\n",
    "print('Test RMSLE: %.3f' % rmsle)  \n",
    "\n",
    "#test_pred = (test_pred3 + test_pred4) / 2\n",
    "test_pred = (test_pred1 + test_pred2 + test_pred3 + test_pred4) / 4\n",
    "result = pd.DataFrame({\"id\": test_id, \"visitors\": test_pred})   \n",
    "result.to_csv('LGB_sub.csv', index=False)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
