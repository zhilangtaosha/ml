{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# porto-segro-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, I would say the following need to be followed in a very often iterative manners:\n",
    "\n",
    "- Understand problem definition\n",
    "- Understand the evaluation metric in the context of the problem. \n",
    "- Understand how public and private leaderboard are split \n",
    "- Initial Data exploration, establish initial understand the nature of dataset\n",
    "- Build first batch of models, create first batch of submissions\n",
    "- Create first cross-validation scheme, and start evaluating relationship between cross-validation and leaderboard score\n",
    "- Start designing experiment for rigorous cross-validation, this shall include both the methodology of cross-validation, the actual implementation, a data capturing mechanism for experiment data\n",
    "- In-depth data manipulation for feature engineering, \n",
    "- For deep learning dominated approaches, design and evaluate model architecture\n",
    "- use established cross-validation method to decide the effectiveness of features and model architecture \n",
    "- Apply ensemble methods - this can range from simple weigh averaging to stacking\n",
    "- post-process of prediction from machine learning model. this is optional depends on specific problem and evaluation metric.\n",
    "\n",
    "\n",
    "[8:17] \n",
    "Additionally, the following shall be strongly encouraged throughout the competition:\n",
    "- Pay close attention to what others are sharing on forum and competition specific kernels \n",
    "- Review and check past competition top solutions - especially the ones with similar problems and similar evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "Generally speaking, I would say the following need to be followed in a very often iterative manners:\n",
    "\n",
    "- Understand problem definition\n",
    "- Understand the evaluation metric in the context of the problem. \n",
    "- Understand how public and private leaderboard are split \n",
    "- Initial Data exploration, establish initial understand the nature of dataset\n",
    "- Build first batch of models, create first batch of submissions\n",
    "- Create first cross-validation scheme, and start evaluating relationship between cross-validation and leaderboard score\n",
    "- Start designing experiment for rigorous cross-validation, this shall include both the methodology of cross-validation, the actual implementation, a data capturing mechanism for experiment data\n",
    "- In-depth data manipulation for feature engineering, \n",
    "- For deep learning dominated approaches, design and evaluate model architecture\n",
    "- use established cross-validation method to decide the effectiveness of features and model architecture \n",
    "- Apply ensemble methods - this can range from simple weigh averaging to stacking\n",
    "- post-process of prediction from machine learning model. this is optional depends on specific problem and evaluation metric.\n",
    "\n",
    "\n",
    "[8:17] \n",
    "Additionally, the following shall be strongly encouraged throughout the competition:\n",
    "- Pay close attention to what others are sharing on forum and competition specific kernels \n",
    "- Review and check past competition top solutions - especially the ones with similar problems and similar evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "for LightGBM, and also if you want to try out other algorithms without going through the pain of the installation, I fully recommend you to use the kernel facility that is available in each competition.\n",
    "\n",
    "\n",
    "[11:20] \n",
    "you just need to create your scrip on Kaggle, and most of the libraries are there, I think you can even save your prediction and submit it on there\n",
    "\n",
    "\n",
    "[11:25] \n",
    "Soon, I will also use the Kaggle Kernel to share some of my code with you, for instance there are more useful techniques than one hot encoding to treat categorical variables - I will start working on this today :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "for more reading on how to do feature engineering, you can have a look at this https://www.slideshare.net/HJvanVeen/feature-engineering-72376750\n",
    "slideshare.net\n",
    "Feature Engineering\n",
    "Tips & Tricks for Feature Engineering / Applied Machine Learning. This presentation was given as part of the Sao Paulo ML meetup.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    " Yifan Xie\n",
    "@here #porto-seguro-a  #porto-seguro-b  #porto-seguro-c I have created a kernel in the competition's Kernel facility to demonstrate the following techniques:\n",
    "1. Capturing statistic overview of the features\n",
    "2. Categorical encoding - particularly useful for this competition\n",
    "3. Model training and prediction with Sklearn for Random Forest and Logistic Regression.\n",
    "\n",
    "The link is here https://www.kaggle.com/yifanxie/porto-seguro-tutorial-simple-e2e-pipeline\n",
    "Posted in #ai-kaggle-porto-segurNov 23rd at 7:56 AM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "For this competition, the most important aspect is cross validation - in fact, the next topic I would like to share is probably exactly this,\n",
    "\n",
    "* * *\n",
    "here is my understanding: Cross validation is a method of model selection - hint: in sklearn, you do `from sklearn.model_selection import StratifiedKFold` :slightly_smiling_face:\n",
    "\n",
    "why do we call that model selection? because when you are using a tool like Xgboost or any of the sklearn apis (i.e. RandomForest), you are using IMPLEMENTATION of machine learning model algorithm to generate models. And every time you use different set of parameters (i.e. different values for `max_depth`)  you are generating different model.\n",
    "\n",
    "The point here about CV and model selection, is that by doing Cross Validation, you are validating if the model you are going to generate with some parameters is \"good\". \n",
    "\n",
    "What we mean by \"good\" is interesting: let's say we want our model to strike the right balance between bias (underfitting) and variance (overfitting) - and most importantly, you want your model CV performance to be well correlated with the modeling performance with UNSEEN data\n",
    "\n",
    "\n",
    "\n",
    "[6:31] \n",
    "So, in  a Kaggle competition, this requirement of \"well correlation\" is simulated in the following way:\n",
    "- 1) you want your CV score on the train data to be well correlated with the public LB data - as much as possible, and sometime it is difficult if you have a noisy dataset - like this one in Porto\n",
    "- 2) you NEED your CV score to be well correlated with private LB data - this is the UNSEEN data (edited)\n",
    "\n",
    "\n",
    "[6:33] \n",
    "here is the bottom line: you need a good CV strategy - and a good CV strategy is one that can simulate as closely as possible how the public LB and private LB is split - this is the BIGGEST hint I can give you :grinning:\n",
    "\n",
    "\n",
    "[6:37] \n",
    "@wol_tar how about this, how about you do a small experiment, with the basic XGB classifier you tried, can you try to run it with Kfold 5 for several time, each time with different random seed?\n",
    "\n",
    "\n",
    "[6:37] \n",
    "can you then let me know, what is the average of your Kfold 5 CV between different run, and the standard deviation?\n",
    "\n",
    "\n",
    "[6:39] \n",
    "Also, within each Kfold, you have 5 in-fold CV score - the CV score for each validation fold - can you check the standard deviation between each fold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "that is why I said, for this competition, the biggest challenge is solid CV\n",
    "\n",
    "\n",
    "[11:21] \n",
    "you need to generate models that can generalise in the private LB\n",
    "\n",
    "\n",
    "[11:22] \n",
    "but that is fine, this is one of the more tricky challenge, and it is not so bad to start with this :sm\n",
    "\n",
    "Yifan Xie [11:24 PM] \n",
    "also, whenever you implement a new feature, or trying out new set of parameter, you need to make that evaluation. (edited)\n",
    "\n",
    "\n",
    "[11:25] \n",
    "and as perhaps you can see now, at least doing repeated K-fold can can help you to gauge the \"true performance\" of your model, so that you don't fixate on any particular good CV score from one of the run ("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "The only problem I have had with the -1 being missing value: If you use LGB, and if you explicitly specify some column to be treated as categorical - LGB had this function to automatically treat categorical - if you run with the -1 value in some the the feature you specified as categorical, LGB will throw an error. In those case, simply replace -1 with positive integer value, I use 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to use a value that is not sued by any of the existing categorical column\n",
    "\n",
    "\n",
    "[12:51] \n",
    "some of the categorical column have more than 100 levels\n",
    "\n",
    "\n",
    "[12:51] \n",
    "so I think 999 is safe, and decision tree models don't care about scale of value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "wol_tar [8:34 AM] \n",
    "I guess he meant it as each feature means. It might mean how it represents in real life or just what it means. Anyway, the dataset in this competition is very hard to see what it stands for (T ^ T)\n",
    "\n",
    "\n",
    "the data description gave some small hints, and some of the forum post guess what is behind individual features, I suggest you have a look\n",
    "\n",
    "\n",
    "[8:46] \n",
    "for instance, this one: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41489\n",
    "kaggle.com\n",
    "Porto Seguro’s Safe Driver Prediction\n",
    "Predict if a driver will file an insurance claim next year.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * *\n",
    "今、これまでのKFlodからStratifiedKFoldに変更、ps_calc_をドロップし、lightgbmを組み合わせるモデルを作ってみてます。エラーばかりでなかなか進みませんが、スコアがよければ共有しますのでしばしお待ちを！（今日中にできればいいですが:joy:）\n",
    "\n",
    "\n",
    "[10:58] \n",
    "うまくいったら2本程度お借りします:bow:\n",
    "\n",
    "\n",
    "[11:03] \n",
    "学習させたら私のnotebook上ではこんな数値になりました↓\n",
    "\n",
    "\n",
    "[11:03] \n",
    "Fold: 0\n",
    "  Gini =  0.277058606087\n",
    "\n",
    "Fold: 1\n",
    "  Gini =  0.292058397448\n",
    "\n",
    "Fold: 2\n",
    "  Gini =  0.286225891573\n",
    "\n",
    "Fold: 3\n",
    "  Gini =  0.283901013879\n",
    "\n",
    "Fold: 4\n",
    "  Gini =  0.291433577769\n",
    "\n",
    "Gini for full training set:\n",
    "Out[12]:\n",
    "0.28605694735666809\n",
    "\n",
    "lgbmはxgboostより格段に早いです:scream_cat:\n",
    "スコアもいい感じ（Public LBはわかりませんが）なので、もう少し改良してみます！0.287を超え始めたらサブミットしてみます！\n",
    "\n",
    "\n",
    "[11:06] \n",
    "時間も短縮できるので多目のfoldでも待ち時間少なそうです:heart_eyes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * * *\n",
    "まずは提出後に実際のPublic LBとこの評価を比較してみてください\n",
    "\n",
    "\n",
    "[12:50] \n",
    "Yifanさんが言うUNSEEN Private LBと上記評価を近づけることがこのコンペの秘訣ということを意識して、見えない本当のスコアを導き出せる自分の評価=solid CVを持つことが大事なのだそうです:thinking_face:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量ってどうやって決めてるのか。。。\n",
    "# Solid CV??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なにかがおかしいです:scream_cat:明日検証してみましょう！私も結局.282だったのでまだsolid CVができていないようです:crying_cat_face:\n",
    "\n",
    "\n",
    "[1:28] \n",
    "お疲れ様でした！とりあえずまた明日ですね、おやすみなさい:zzz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "Yifan Xie [1:35 AM] \n",
    "don't worry about the LB score too muche :wink:\n",
    "\n",
    "\n",
    "[1:35] \n",
    "repeat K-folds CV, and average, I would trust that score more\n",
    "\n",
    "\n",
    "Yifan Xie [1:41 AM] \n",
    "Personally, I am doing a bit more than this, I do this:\n",
    "\n",
    "First of all, introduce a new feature, and then do the following evaluation:\n",
    "Do this 20 times with different random setting:\n",
    "1. Train_test_split (70%/30%) -> local train (70% of original train), local val (30% of original train)\n",
    "2. Perform 5-fold CV on local train(70% of original train) -> generate out-of-fold prediction for local train (70% of original train) and local validation (30% of original train)\n",
    "3. Calculate AUC/Gini with (Y of local val, oof prediction of local val) -> Validation score for the local val (30% of original train)\n",
    "\n",
    "As I said above,  I repeat steps 1-2-3 20 times, and then I average the validation scores of (output of step 3).\n",
    "\n",
    "Now if the validation score improve compare to the validation score for data without the new feature, I proceed to second round of validation, this time I for the train_test_split with (50%/50%) setting.\n",
    "\n",
    "Only features that improve validation score in both rounds i.e. (70%/30%) and (50%/50%) setting, I will consider them to be useful \n",
    "\n",
    "So far, none of the features share on the kernel pass this test:joy:\n",
    "Maybe I am being too strict, but I am gonna stick with it -> there is always the next competition! :smile: (edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple repeated k-fold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yifan Xie [1:47 AM] \n",
    "I am doing it this way also partly because I have a good work station, so if your laptop/PC is too slow to do this, just do simple repeated k-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "@Yifan Xie Thank you for your advice! Your steps really show how you meant to create a solid CV:thinking_face:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "@koji_takahashi もう一つ気になったのが、clfの中身で、このコンペの評価基準がgini係数なので、それに合った形で評価して上げないといけません:persevere:\n",
    "\n",
    "\n",
    "[3:18] \n",
    "clf = RandomForestClassifier(max_depth=8, criterion=‘entropy’, random_state=0)\n",
    "\n",
    "\n",
    "[3:19] \n",
    "上記clfのcriterionのentropyをcriterion=‘gini’に変更しないといけないのではないかと思います！\n",
    "\n",
    "\n",
    "[3:22] \n",
    "giniにしてpredict_dataまで実行してみたところ、予測結果が以下のようになりました↓\n",
    "\n",
    "array([ 0.02809289,  0.03081622,  0.0366754 , ...,  0.03048102,\n",
    "        0.03312124,  0.03248458])\n",
    "\n",
    "\n",
    "[3:24] \n",
    "@shinji_suzuki いや、私もYifanさんのkernelを参考にして比べてただけなんですけど、predictのパートとclfのパートがそれぞれYifanさんのものと違かったので、そうなのではないかとという仮定で話してます、、\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "predict_probaは確率を出すためのものだったんですね。私も勉強になります。https://datacreative.me/blog/mlr_analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "お疲れ様です！Yifanさんのkernelを参考に自分のスコアを出せるようなコードにしておくと提出後にPublic LBとコード内のスコアを比較できて便利ですよ:+1:\n",
    "\n",
    "\n",
    "[5:09] \n",
    "https://www.kaggle.com/yifanxie/porto-seguro-tutorial-simple-e2e-pipeline\n",
    "kaggle.com\n",
    "Porto Seguro Tutorial Simple E2E pipeline\n",
    "Using data from Porto Seguro’s Safe Driver Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * *\n",
    "私は、以下のkernelを参考に少しずつ変化させています↓\n",
    "\n",
    "\n",
    "[5:25] \n",
    "https://www.kaggle.com/aharless/xgboost-cv-lb-284\n",
    "kaggle.com\n",
    "XGBoost CV (LB .284)\n",
    "Using data from Porto Seguro’s Safe Driver Prediction\n",
    " \n",
    "\n",
    "\n",
    "[5:26] \n",
    "In[3]でgini係数の計算方法を入れて、In[11]で計測しています\n",
    "\n",
    "\n",
    "[5:27] \n",
    "最初の方で所々、特徴量を作っているようですが、そういったものはすっ飛ばして、シンプルな構造部分だけ抜き出して使っています。\n",
    "\n",
    "\n",
    "[5:29] \n",
    "Yifanさんのkernelでは、rf_val_gininormで計算しているようです。\n",
    "\n",
    "\n",
    "[5:30] \n",
    "あるいは、In[18]のlogit_val_gininormも同じかと思います。\n",
    "\n",
    "\n",
    "[5:32] \n",
    "鈴木さんはどのkernelをベースにしているかわかりませんが、私は上記モデルを参考にしてやっています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * * *\n",
    "私はkernelではなく、紹介頂いたこちらを元に作成しました！\n",
    "https://m.youtube.com/watch?amp=&v=SGTGAGfp-AM&index=6-czDnP9kvF9-Um5q6Q%EF%BC%89%E3%82%92%E5%85%83%E3%81%AB%E6%9B%B8%E3%81%84%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%81%8C%E6%9C%80%E5%BE%8C%E3%81%AE%E6%96%B9%E3%81%A7%E3%81%A4%E3%81%BE%E3%81%A5%E3%81%84%E3%81%A6%E3%81%84%E3%81%A6%E3%80%81%E3%81%BE%E3%81%A0%E3%81%A7%E3%81%99%E3%81%8C%E3%83%BB%E3%83%BB%E3%83%BB%E3%81%BF%E3%81%AA%E3%81%95%E3%82%93%E3%81%A9%E3%82%93%E3%81%AA%E6%84%9F%E3%81%98%E3%81%A7%E3%81%97%E3%82%87%E3%81%86%E3%81%8B%EF%BC%9F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * *\n",
    "koji_takahashi [3:43 PM] \n",
    "https://github.com/takahashikoji/DIVE_INTO_CODE_AI/blob/master/porto_seguro_stacked_Generalization.ipynb\n",
    "GitHub\n",
    "takahashikoji/DIVE_INTO_CODE_AI\n",
    "Contribute to DIVE_INTO_CODE_AI development by creating an account on GitHub.\n",
    " \n",
    "\n",
    "\n",
    "[3:43] \n",
    "stacking de\n",
    "\n",
    "[3:44] \n",
    "私が見た中で一番分かりやすく凡用性が高いコードなのではないかと思います。\n",
    "\n",
    "\n",
    "[3:46] \n",
    "私はRFとXGBで試してPublic Scoreが0.277でした。組み合わせ次第でスコアが上がると思うのでたくさん試したいです:smiley:\n",
    "\n",
    "\n",
    "wol_tar [3:48 PM] \n",
    "いい感じですね:grin: 私も一部パクらせて頂きます:pray:\n",
    "\n",
    "\n",
    "koji_takahashi [3:53 PM] \n",
    "どうぞどうぞ:sparkles:\n",
    "\n",
    "wol_tar [4:06 PM] \n",
    "gini係数の計算はこれを使ってます！\n",
    "\n",
    "\n",
    "[4:06] \n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * * *\n",
    "koji_takahashi [11:21 PM] \n",
    "https://github.com/takahashikoji/DIVE_INTO_CODE_AI/blob/master/porto_seguro_stacked_Generalization_2.ipynb\n",
    "GitHub\n",
    "takahashikoji/DIVE_INTO_CODE_AI\n",
    "Contribute to DIVE_INTO_CODE_AI development by creating an account on GitHub.\n",
    " \n",
    "\n",
    "\n",
    "[11:22] \n",
    "ちなみに上記のstackingを先ほど試して見たところ、0.281まで出ました。\n",
    "\n",
    "\n",
    "[11:24] \n",
    "step1でRFとLGBMとExtraTreeというものを使用してstep2でXGBを使用してます。\n",
    "\n",
    "\n",
    "[11:26] \n",
    "お二人ともstacking無しであのPSが出ていたという事はstackingを組み合わればもっと高いスコアを狙えるのではと思います:laughing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "Yifan Xie [12:00 AM] \n",
    "just a reminder, when doing stacking, make sure your fold split is consistent with all models and at all level - this is to avoid overfitting\n",
    "\n",
    "\n",
    "[12:01] \n",
    "especially important if you are working with others, i.e. you might take other's OOF output and put into your stacking routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * * *\n",
    "Yifan Xie [11:32 AM] \n",
    "At this moment, the kernel is still being computed on Kaggle server, it shall be ready in one hour's time\n",
    "\n",
    "\n",
    "Yifan Xie\n",
    "@channel please see my second shared kernel - this time it is a end-to-end ensemble guild with 3 level stacking :slightly_smiling_face: https://www.kaggle.com/yifanxie/porto-seguro-tutorial-end-to-end-ensemble/\n",
    "Posted in #ai-kaggle-porto-segurNov 27th at 11:31 AM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guys, I hope the above kernel would show you some more information on how to do ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yifan Xie [6:27 PM] \n",
    "in the kernel shared above, I would like to point your attention to `In [24]` and `In [25]`\n",
    "This touches on a point that we haven't talked about so far - that Gini and AUC are ranked based metric - which means the only thing that matter are not probability itself - it is the ranking of probabilities from each data point that determines this type of metrics\n",
    "You will see that on the level ensemble, if you don't normalised the probabilities into ranking, you will get good CV for each training fold, but very poor CV for the whole train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * *\n",
    "shinji_suzuki [10:19 PM] \n",
    "https://www.kaggle.com/vpaslay/lb-0-287-porto-seguro-mix\n",
    "kaggle.com\n",
    "LB 0.287 - Porto Seguro Mix\n",
    "Using data from multiple data sources\n",
    " \n",
    "\n",
    "\n",
    "[10:20] \n",
    "こちら李さんから送ってもらったアンサンブルのカーネルです。\n",
    "\n",
    "\n",
    "[10:22] \n",
    "今まで自分で出したcsvを全て入れて見たところ（PB LBが判明しているのは0.273,0.273,0.275の３件）、PB LBで0.277が出ましたよ。なので、おそらく数値が高くなると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あと、今日Yifanさんに送っていただいたこちらのカーネル。https://www.kaggle.com/yifanxie/porto-seguro-tutorial-end-to-end-ensemble/\n",
    "kaggle.com\n",
    "Porto Seguro Tutorial: end-to-end ensemble\n",
    "Using data from Porto Seguro’s Safe Driver Prediction\n",
    " \n",
    "\n",
    "\n",
    "[10:23] \n",
    "こちらだと、出したcsvをさらにアルゴリズムに食べさせるみたいなことをしています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "wol_tar [8:34 AM] \n",
    "Another question: as Shinji pointed, to get good score by mixing predicted csv(s) up, do you think it’s better to mix them approached by many different perspectives?\n",
    "\n",
    "\n",
    "advisor_yifan [8:35 AM] \n",
    "with stacking - yes, with simple weight averaging - no, especially you have one or two scores are much better than the rest (edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wol_tar [8:46 AM] \n",
    "Thank you, crystal clear!\n",
    "\n",
    "\n",
    "advisor_yifan [8:46 AM] \n",
    "no problem, enjoy the last two days - and we will really see how big the lottery is :slightly_smiling_face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
