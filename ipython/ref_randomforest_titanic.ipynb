{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題 タイタニック生存予測 ランダムフォレスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題定義\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回の目的は、タイタニックの生存予測を行う。この生存予測を行うことで、このような事故が起こらないようにアクションを起こしていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ取得/データ読み込み\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df = sns.load_dataset(\"titanic\")\n",
    "df = pd.read_csv('../../mltestdata/train.csv')\n",
    "\n",
    "data_train = pd.read_csv('../../mltestdata/train.csv')\n",
    "data_test = pd.read_csv('../../mltestdata/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(frac=0.01, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理について記述せよ\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __前処理とは何か__\n",
    "\n",
    "前処理とは使うモデルに投入できるようにデータを加工、変換すること。\n",
    "（有益なデータソースを探すところも含まれるのかと）\n",
    "\n",
    "- __なぜ前処理を行う必要があるのか__\n",
    "\n",
    "データの品質を管理するため（投入するデータに基づいて分析結果が左右される。biasが上がる可能性あり。）\n",
    "\n",
    "\n",
    "- __前処理は具体的に何を行うか(3つ以上記述せよ)__\n",
    "\n",
    "    - 分析できるデータフォーマット（配列、データフレーム…）に加工\n",
    "    - 分析可能なデータの型に変換。名義変数の数量化/カテゴリデータの~~連続データ~~<font color=\"RED\">数値データ化</font>（機械学習では~~連続データ~~<font color=\"RED\">数値データ化</font>を前提にしているものが多いため。ダミー変数化。）あとは日付の形式。\n",
    "    - 外れ値や欠損値の補完\n",
    "    - 連続値の離散化/数量変数の離散化（必要であれば）\n",
    "    - 正規化（必要であれば）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "# [20171028 追記]\n",
    "\n",
    "__(コメント)__\n",
    "\n",
    "カテゴリデータを連続データにするという表現ですが、この表現だと語弊があります。\n",
    "カテゴリデータを数値（整数、one-hot）に変換はしますが、連続データの性質（四則演算ができる性質など）を追加するわけではありません。\n",
    "\n",
    "__(追加確認内容)__\n",
    "\n",
    "カテゴリデータは名義尺度に分類され、数値やone hot表記の表現をとること理解しました。下記尺度の分類の確認内容です。\n",
    "\n",
    "- 数値データ（量的変数） ---定量的（連続的な数値をとる）\n",
    " - 比例尺度 \n",
    "    質量，長さなど\n",
    " - 間隔尺度\n",
    "    摂氏，華氏など（乗除不可） \n",
    "\n",
    "- カテゴリデータ（質的変数） ---定性的（離散的な数値をとる）\n",
    " - 名義尺度\n",
    "    名前，電話番号など \n",
    " - 順序尺度\n",
    "    レースの着順など \n",
    " - 間隔尺度\n",
    "    摂氏，華氏など（乗除不可） \n",
    "\n",
    "機械学習アルゴリズムは数値データを前提としているものが多い。決定木やNativeBayesは数値でないカテゴリカルデータも対応できるが、線形モデルでは対応不可。[The Basics of Encoding Categorical Data for Predictive Models](http://appliedpredictivemodeling.com/blog/2013/10/23/the-basics-of-encoding-categorical-data-for-predictive-models)\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __前述した具体的な前処理について、その前処理を行うと何を得ることができるか(記述したそれぞれの前処理例について記述せよ)__\n",
    "\n",
    "    - 分析できるデータフォーマットに加工\n",
    "        - カラムに沿ったデータの整理。分析可能な特徴量を得ることができる。\n",
    "    - 分析可能なデータの型に変換。カテゴリデータを~~連続データ~~<font color=\"RED\">数値データ化</font>にする。（機械学習では~~連続データ~~<font color=\"RED\">数値データ化</font>を前提にしているものが多いため。ダミー変数化。）\n",
    "        - ex) TitanicのSex column. Sex: Male/Female から Male: 1/0に変更。\n",
    "        - 質的変数を量的変数に変換することができる。\n",
    "        - n-1個特徴量を作成する。カテゴリが３つ以上の場合は２個。\n",
    "        \n",
    "    - 外れ値や欠損値の補完\n",
    "        - 外れ値は統計的、空間的、またはクラスタリングに基づく方法で外れ値を排除することができる。排除により、分析の計算結果の歪みを防ぐことができる。\n",
    "        - 欠損値は削除、最尤法、補完をすることで、分析可能なデータセットを得ることができる。データ量も減らすことを避けることができる。\n",
    "\n",
    "    - 連続値の離散化（必要であれば）\n",
    "        - 相関がありそうな特徴量で、欠損値を多く含む場合など、存在するデータを離散化・カテゴリに分け、それらの平均値や中央値を使うことで、誤差を含まない外れ値の補完をすることができる。\n",
    "        \n",
    "    - 正規化（必要であれば）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "# [20171028 追記]\n",
    "\n",
    "__(コメント)__\n",
    "\n",
    "正規化についての具体例の説明。標準化との違いも説明できてると better です。\n",
    "\n",
    "__(追加確認内容)__\n",
    "- 特徴量の尺度をそろえることを正規化と呼び、正規化と標準化の２つの方法がある。\n",
    "- 正規化とは、特徴量を[0,1]の範囲でスケールし直すこと。\n",
    "- 標準化とは、平均が0、標準偏差が1であるような正規分布としてスケールを合わせること。\n",
    "* * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2/前処理について記述せよ\n",
    "\n",
    "\n",
    "* * *\n",
    "__前処理について記述せよの調査により、データを確認する際にどのような点を見るとよいか、3つ以上記述せよ。__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ヒストグラム、平均、標準偏差で関連性の確認\n",
    "- パラメータの相関係数で相関の強さを確認(連続データ、離散データの両方で)\n",
    "- 欠損値の確認（あとで補完が必要かもしれないから）\n",
    "\n",
    "\n",
    "その他メモ\n",
    "    - 線形回帰分析するなら単回帰分析をとりあえず行う（重回帰分析での指標に使う）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理を行う\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-725cfd0c3659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    \n",
    "\n",
    "\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n",
    "\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "data_train = transform_features(data_train)\n",
    "data_test = transform_features(data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7a4a2e68939a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "\n",
    "data_train, data_test = encode_features(data_train, data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7d6cb65cce29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[\"Age\"].value_counts()\n",
    "# data_train[\"Age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_train.sample(frac=0.01, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理の内容について記述せよ\n",
    "- 以下の観点をすべて含めて記述しましょう。\n",
    "- 以上のメソッドがそれぞれ何を行っているか記述せよ\n",
    "- それぞれなぜそのようなことを行っているか記述せよ(それによって得られるメリットまで考察すること)\n",
    "\n",
    "simplify_ages\n",
    "- binsで設定した区間ごとに、group_namesで設定した名前で階級分けをする。df.Ageを階級に置き換える。\n",
    "- メリット\n",
    "    - 下記[引用](https://www.msi.co.jp/bayolink/pdf/discretization.pdf)。\n",
    "    > 一般的にベイジアンネットモデルは状態の数が増えると、確率推論の精度も悪くなります。ノードの状態の最適な個数はモデルの目的や学習データのサイズによって大きく異なりますが、5 個前後に設定するケースが多いようです。\n",
    "\n",
    "simplify_cabins\n",
    "- NaNを\"N\"に置き換え、各値の頭文字一文字に変更。\n",
    "- メリット\n",
    "    - カテゴリ化ができ、データが見やすくなる。\n",
    "\n",
    "simplify_fares\n",
    "- binsで設定した区間ごとに、group_namesで設定した名前で階級分けをする。df.Fareを階級に置き換える。\n",
    "- メリットはsimplify_agesと同じ。\n",
    "\n",
    "format_name\n",
    "- Name属性を' '(スペース)で分けた0番目の配列をLname、1番目の配列をNamePrefixとして新しい特徴量を追加する。\n",
    "- メリット\n",
    "    - 新しい特徴量から分析の幅を広げることができる。\n",
    "\n",
    "drop_features\n",
    "- 'Ticket', 'Name', 'Embarked'のカラムを削除する。\n",
    "- メリット\n",
    "    - 不要データ、分析済みのデータを削除し、データセットを扱いやすくする。\n",
    "\n",
    "encode_features\n",
    "- すでに上記でビンニングしていたカテゴリデータを数値に変更する。\n",
    "- メリット\n",
    "    - ２種類の離散データが格納されているカラムについてはダミー変数化ができる。\n",
    "    - データ記述の簡略 ([引用](https://www.slideshare.net/tetsuroito/tokyor-lt-r))\n",
    "    - 離散化されたデータしか扱えない手法にも対応できるようにするため。\n",
    "- デメリット\n",
    "    - 順序付けが勝手にされる。[labelencorder](https://datascience.stackexchange.com/questions/9443/when-to-use-one-hot-encoding-vs-labelencoder-vs-dictvectorizor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル選択について記述せよ\n",
    "* * * \n",
    "今回使用するモデルは決定していますが、モデル選択をする際の演習を行いましょう。\n",
    "\n",
    "- 今回は、生存予測（分類）を行いますが、この分類について使用できそうな手法を4つ以上しらべて記述せよ。\n",
    "- その手法の概要をそれぞれ記述せよ\n",
    "- その手法の長所/短所をそれぞれ3つずつ、記述したすべての手法において記述せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰\n",
    "- 概要: 識別モデル。予測結果が0から1までを取るような目的変数。従属変数に２値しか取りえない値を説明変数を用いてその発生確率を説明・予測する多変量解析。\n",
    "- 長所\n",
    "    1. ~~線形回帰。ホワイトボックス性高い、説明が明瞭。~~\n",
    "    2. バリアンスが低い\n",
    "    3. 発生確率を求めることができる\n",
    "    4. 決定境界を引く際に有効\n",
    "- 短所\n",
    "    1. ~~線形性であること~~  ___(20171028追記) 対象が線形分離問題であること___、説明変数同士が独立であることなど仮定が求められる。\n",
    "    2. バイアス（予想精度）が高い\n",
    "    3. 大量のカテゴリデータは正しく扱えない可能性あり([Doesn’t handle large number of categorical features/variables well](https://www.edvancer.in/logistic-regression-vs-decision-trees-vs-svm-part2/))\n",
    "    4. ___(20171028追記)* [[参考slide.14](https://www.slideshare.net/sakura-mike/ss-65379598)]のように目的関数を高次方程式にすることで線形非分離問題へも対応可だが、___非線形の場合は非線形変換が必要で精度が下がる可能性あり。([Doesn’t perform well when feature space is too large/Relies on transformations for non-linear features](https://www.edvancer.in/logistic-regression-vs-decision-trees-vs-svm-part2/))\n",
    "\n",
    "\n",
    "\n",
    "([参考1](https://datumstudio.jp/blog/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E9%81%B8%E6%8A%9E%E6%96%B9%E6%B3%95%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6))\n",
    "([参考2](https://github.com/ctufts/Cheat_Sheets/wiki/Classification-Model-Pros-and-Cons))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "# [20171028 追記]\n",
    "\n",
    "__(コメント)__\n",
    "\n",
    "varianceが低い/biasが高いとどういったことがそれぞれ起きますでしょうか？（確認）\n",
    "\n",
    "__(追加確認内容)__\n",
    "\n",
    "- varianceが低い/biasが高い場合は、訓練データが偏っていても、その偏りに引きずれることはないが、真のデータと結果にずれがある。\n",
    "\n",
    "- Varianceはアルゴリズムの良し悪しを決めるスペック。\n",
    "- Var高だと、過学習気味。汎化性能が低い。（モデルが複雑になると教師データに偏りがある場合に結果が偏る可能性がある。）\n",
    "- Biasは真のデータと学習モデルの結果のデータとのズレ。\n",
    "- Bias高だと、未学習気味。真のデータと結果が異なっている。（モデルが単純な場合は教師データに偏りがあっても引きずられる度合いは低いが、真のデータとモデルの結果データとはズレがある。）\n",
    "\n",
    "* * *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "# [20171028 追記]\n",
    "\n",
    "__(コメント)__\n",
    "\n",
    "線形/非線形モデル、線形回帰、線形分離可能/不可能問題　という言葉の定義\n",
    "これらが曖昧にされてるイメージがあります。線形モデルと線形分離可能の「線形」の意味は異なります。「何に対して」それぞれ線形なのか調べてください。\n",
    "\n",
    "決定木の長所で、非線形属性も取り扱えるとありますが、これは、線形分離不可能問題にも対応しているということでしょうか？もしそうなら、ロジスティック回帰などの線形モデルも、2次以上の項を特徴量としていれれば、線形分離不可能問題にも対応できます。\n",
    "\n",
    "__(追加確認内容)__\n",
    "\n",
    "- 線形\n",
    "\n",
    "    - 「線形」というのは、「目的変数」と「説明変数」の関係性が線形（変数と変数の関係が直線的）であること。モデル内の各項が加法であり、項を乗算するパラメータが1つだけ含まれている場合は線形。\n",
    "    - （式例）　応答 = 定数 + パラメータ * 予測変数 + ... + パラメータ * 予測変数\n",
    "    -  非線形形状としては、凹、凸、指数的な増加または減少、シグモイド(S)、および漸近曲線など。例えば「exp」とか「log」とかの関係性が入ると、「線形モデル」ではなくなる。\n",
    "\n",
    "- 線形モデル\n",
    "    - 応答 = 定数 + パラメータ * 予測変数 + ... + パラメータ * 予測変数のように線形結合の目的関数をモデル化したもので直線になる。\n",
    "\n",
    "- 非線形モデル\n",
    "    - 非線形モデルは曲線。（例）多項式回帰\n",
    "\n",
    "- 線形回帰\n",
    "    - 目的関数をあるモデル（コスト関数）に当てはめて、パラメータを求めるまでが線形回帰。\n",
    "    - 多項式回帰での x に対しては線形ではないが、係数 β （パラメータ）に対しては線形であるため、線形回帰の問題に分類される。[[参考](https://ja.wikipedia.org/wiki/%E7%B7%9A%E5%BD%A2%E5%9B%9E%E5%B8%B0)]\n",
    "\n",
    "\n",
    "\n",
    "- 線形分離可能/線形分離不可能\n",
    "    - 線形分離可能とは、線形モデルによってクラス1と0に分離できること。線形分離不可能は線形モデルで分離できないこと。[[参考](https://qiita.com/imaimai1125/items/2a126cf04e64432f1bfd)]\n",
    "\n",
    "* * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree/決定木(コピー済み)\n",
    "- 概要：\n",
    "    - 識別関数。\n",
    "    - CART（Classification and Regression Tree）法というアルゴリズムを使い、目的変数を最もよく「分類」する、説明変数の分岐を生成する。\n",
    "    - 目的変数を「最もよく」分類する基準として、CART法ではいくつかの方法があるが、良く使われるのは、ジニ係数、エントロピー（どれだけ情報が整理されたか。低い→better）、分類誤差。\n",
    "    - エントロピー低→情報ゲイン増。情報ゲインが最大となる質問を各ノードで探し、リーフノードを入れ替え、目的変数を最もよく分類するルートノードを生成する。\n",
    "    - 分類木は属するカテゴリを、回帰木は連続的な数値を求める。\n",
    "\n",
    "- 長所\n",
    "    1. ~~ホワイトボックス性高い、解釈が容易。~~\n",
    "    2. 非線形分類器として使える。[[Ref](https://www.gixo.jp/blog/3980/)]\n",
    "    3. 説明変数のエンコード等を検討する必要がないこと。目的変数、説明変数ともにカテゴリ変数と量的変数のどちらも使用可能。[[Ref](https://webcache.googleusercontent.com/search?q=cache:3uVzQK6NgI4J:https://assign-navi.jp/magazine/consultant/c41.html+&cd=1&hl=en&ct=clnk&gl=us)]\n",
    "    4. データのスケールに対して普遍（スケーリングが不要）\n",
    "    5. accuracyが高い[[Ref2 slide.33](https://www.slideshare.net/kangdaeki/machine-learning-decision-tree)]\n",
    "    6. ノイズに強い。\n",
    "\n",
    "- 短所\n",
    "    1. 予想精度低。訓練データにかなり依存。決定木はアルゴリズムの性質上、モデルが学習データからうける影響が大きくバリアンスが高い学習モデル([Ref5](http://d.hatena.ne.jp/shakezo/20121221/1356089207))\n",
    "    2. 不安定→モデルとしてのロバスト性（頑健性）が弱く、適切でない説明変数が入ると、その変数にモデル全体が引っ張られてしまうこと。（訓練データにない範囲に関しては「新しい」答えを生成することができません。）\n",
    "    3. XORパターンには適用が難しいケースあり\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "メモ([引用元](https://github.com/ctufts/Cheat_Sheets/blob/master/Classification_Model_Pros_And_Cons.md))\n",
    "\n",
    "\n",
    "__Regular (not bagged or boosted)__\n",
    "- Pros\n",
    "    1. easy to interpret visually when the trees only contain several levels\n",
    "    2. Can easily handle qualitative (categorical) features\n",
    "    3. Works well with decision boundaries parellel to the feature axis\n",
    "- Cons\n",
    "    1. prone to overfitting\n",
    "    2. possible issues with diagonal decision boundaries\n",
    "\n",
    "__Bagged Trees : train multiple trees using bootstrapped data to reduce variance and prevent overfitting__\n",
    "- Pros\n",
    "    1. reduces variance in comparison to regular decision trees\n",
    "    2. Can provide variable importance measures\n",
    "        - classification: Gini index\n",
    "        - regression: RSS\n",
    "    3. Can easily handle qualitative (categorical) features\n",
    "    4. Out of bag (OOB) estimates can be used for model validation\n",
    "- Cons\n",
    "    1. Not as easy to visually interpret\n",
    "    2. Does not reduce variance if the features are correlated\n",
    "\n",
    "__Boosted Trees : Similar to bagging, but learns sequentially and builds off previous trees__\n",
    "- Pros\n",
    "    1. Somewhat more interpretable than bagged trees/random forest as the user can define the size of each tree resulting in a collection of stumps (1 level) which can be viewed as an additive model\n",
    "    2. Can easily handle qualitative (categorical) features\n",
    "- Cons\n",
    "    1. Unlike bagging and random forests, can overfit if number of trees is too large\n",
    "\n",
    "* * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision foreset/ランダムフォレスト（コピー済み）\n",
    "- 概要：\n",
    "    - 識別関数。\n",
    "    - 決定木ベースの集団学習アルゴリズムのひとつ。\n",
    "    - 全教師データからランダムにとったデータで学習を行う。([Ref4](https://www.slideshare.net/teppeibaba5/ss-37143977))\n",
    "    - 説明変数もランダムにすることで、baggingで問題となる各識別器の結果が似てしまう欠点を改善する。\n",
    "    \n",
    "- 長所\n",
    "    1. 説明変数の依存が少ない。ノイズに強い。\n",
    "    2. 学習が高速→並列に処理できる（それぞれの木で訓練ができる）\n",
    "    3. 集団学習ではvarianceが低い。\n",
    "    4. RFではクロスバリデーション必要なし。out-of-bag (oob) エラー計算がその代わりとなる。\n",
    "    5. 少ないパラメータでチューニング可（木の数自体がもっとも重要）\n",
    "    6. 非線形も取り扱える\n",
    "    7. データ量が多くても高速に処理。\n",
    "       \n",
    "- 短所\n",
    "    1. 学習データの説明変数をランダムで抽出するため、データ変数がすくないとうまく学習できない。\n",
    "    2. コンピューティングの複雑性は木の数に応じてリニアに増える。変数の数が多いと計算量がリニアに増える。\n",
    "    3. 視覚的な解釈が簡単ではない。\n",
    "\n",
    "\n",
    "([Ref](https://www.slideshare.net/DanielCahall/cahall-final-intern-presentation))\n",
    "([Ref2](http://rstudio-pubs-static.s3.amazonaws.com/4239_fcb292ade17648b097a9806fbe026e74.html))\n",
    "([Ref3](https://www.edvancer.in/logistic-regression-vs-decision-trees-vs-svm-part2/))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均化パーセプトロン\n",
    "- 概要：学習事例を受け取り、重みベクトルを更新する、という処理を反復した後に重みベクトルと入力ベクトルを足してその値が0以上ならクラス1、0未満はクラス2として分類する。平均化パーセプトロンは過去の反復で学習した重みベクトルの平均を使う。\n",
    "- 長所\n",
    "    1. 実装が簡単\n",
    "    2. よい測定精度が出ることが多い\n",
    "    3. 迷惑メール判定などオンライン学習に向いている([参考](http://www.nttdata.com/jp/ja/insights/trend_keyword/2014110601.html))\n",
    "- 短所\n",
    "    1. 線形分離可能なデータにしか適用できない。\n",
    "    2. 各反復における重みベクトルを保持する必要があり、メモリ的に学習が非効率である。→問題を考慮した実装方法にすること。\n",
    "    3. 過学習しやすい。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル選択の基準\n",
    "* * * \n",
    "下記の参考資料を元に、どのような視点からモデルを選択すれば良いか、最低でも3つ以上の視点を記述すること(他の参考資料でも構わない、その場合参考資料を明記すること)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 「予測精度」([参考](https://datumstudio.jp/blog/機械学習におけるモデルの選択方法について))\n",
    "2. 「中身のわかりやすさ」(同上)\n",
    "3. 訓練・テストデータの分布([P29](https://www.slideshare.net/canard0328/ss-44288984))\n",
    "4. カテゴリの予測([参考](http://scikit-learn.org/stable/tutorial/machine_learning_map/))\n",
    "5. 教師データの有り無し(同上)\n",
    "6. 数量の予測か(同上)\n",
    "\n",
    "メモ([参考](https://datumstudio.jp/blog/機械学習におけるモデルの選択方法について))：\n",
    "- 説明変数の予測値への寄与を大雑把に知りたい：線形判別/回帰\n",
    "- 予測値の正確性が命：ディープラーニング、サポートベクタマシン/回帰\n",
    "- 予測精度が実用的で因果関係の類推も行いたい：CART(ランダムフォレスト)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル選択におけるデータ可視化\n",
    "# データ可視化の結果について考察せよ\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noSBJKhkKkqSSoSBJKv1/1/J8x1gzfDYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fd0be48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=data_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEqakICIiYUoKIiISpqQgIiJh/x9KHqJMJP8/1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b8dc438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=df,\n",
    "              palette={\"male\": \"blue\", \"female\": \"pink\"},\n",
    "              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__上記の２つの可視化から分かったことについて考察せよ。__\n",
    "\n",
    "図1\n",
    "- 年齢のグループごとにSurvivedの結果に差があることがわかる。\n",
    "- 特に男女ともにAgeグループ1の生存率が高め。Ageグループ3の女性の生存率はすべて1（信頼区間無し）。\n",
    "- 全体のグループを通して、女性の生存率のほうが高い。\n",
    "\n",
    "図2\n",
    "- 性別とPclassのクロス集計結果でSurvivedの結果に差がある。\n",
    "- 男性はどのPclassに限らず、生存率が低い\n",
    "- 女性はどのPclassでも、男性より生存率が高い。\n",
    "- 特にPclass 1の生存率が高い。\n",
    "\n",
    "__上記の考察結果から、モデル選択を考える場合、どのようなことが考えられるか__\n",
    "- 複数の特徴量のクロス集計で生存率が変わることがわかる。各特徴量で分解を行える、決定木が有力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの分割\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = data_train['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ランダムフォレストについて記述せよ\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 決定木とはどのような手法か(前出の回答のコピー)\n",
    "    - 識別関数。\n",
    "    - CART（Classification and Regression Tree）法というアルゴリズムを使い、目的変数を最もよく「分類」する、説明変数の分岐を生成する。\n",
    "    - 目的変数を「最もよく」分類する基準として、CART法ではいくつかの方法があるが、良く使われるのは、ジニ係数、エントロピー（どれだけ情報が整理されたか。低い→better）、分類誤差。\n",
    "    - エントロピー低→情報ゲイン増。情報ゲインが最大となる質問を各ノードで探し、リーフノードを入れ替え、目的変数を最もよく分類するルートノードを生成する。\n",
    "\n",
    "- ランダムフォレストとはどのような手法か(前出の回答のコピー)\n",
    "    - 識別関数。\n",
    "    - 決定木ベースの集団学習アルゴリズムのひとつ。\n",
    "    - 全教師データからランダムにとったデータで学習を行う。([Ref4](https://www.slideshare.net/teppeibaba5/ss-37143977))\n",
    "    - 説明変数もランダムにすることで、baggingで問題となる各識別器の結果が似てしまう欠点を改善する。\n",
    "    \n",
    "\n",
    "- ランダムフォレストの長所と短所をそれぞれ3つ以上挙げてください。(前出の回答のコピー)\n",
    "    - 長所\n",
    "        1. 説明変数の依存が少ない。ノイズに強い。\n",
    "        2. 学習が高速→並列に処理できる（それぞれの木で訓練ができる）\n",
    "        3. 集団学習ではvarianceが低い。\n",
    "        4. RFではクロスバリデーション必要なし。out-of-bag (oob) エラー計算がその代わりとなる。\n",
    "        5. 少ないパラメータでチューニング可（木の数自体がもっとも重要）\n",
    "        6. 非線形も取り扱える\n",
    "        7. データ量が多くても高速に処理。\n",
    "\n",
    "    - 短所\n",
    "        1. 学習データの説明変数をランダムで抽出するため、データ変数がすくないとうまく学習できない。\n",
    "        2. コンピューティングの複雑性は木の数に応じてリニアに増える。変数の数が多いと計算量がリニアに増える。\n",
    "        3. 視覚的な解釈が簡単ではない。\n",
    "\n",
    "- 今回の目的からランダムフォレストの手法が適する理由を考察し、記述せよ\n",
    "    - 複数の特徴量のクロス集計で生存率が変わることがわかる。各特徴量で分解を行える、決定木が有力(前出の回答のコピー)。決定木よりも、バリアンスが低いため良い結果が得られる可能性が高い。よってランダムフォレストを採用す使う。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification これなに？\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracyを求めよ\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798882681564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精度を高める\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すでに75%以上の精度のため特になし（あとで上げる）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハイパーパラメータについて\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ハイパーパラメーターとは何か\n",
    "    - モデリングの前に人間が決めるパラメータで、ランダムフォレストではnum_trees、random_state、max_depthなど。（広義には単回帰(y=ax+b)でいうxもハイパーパラメータ）\n",
    "    - パラメータはハイパーパラメータのもと機械学習で決まるパラメータで単回帰(y=ax+b)でいうaとb。\n",
    "\n",
    "- ランダムフォレストにおいてどのようなハイパーパラメーターがあるか4つ以上記述せよ\n",
    "    - n_estimators\n",
    "    - max_features\n",
    "    - max_depth\n",
    "    - min_samples_leaf\n",
    "        \n",
    "- 記述したハイパーパラメーターにおいて、それぞれどのような値が存在するか記述せよ（そのハイパーパラメーターを変化させるとどのようなことが起きるかも記述すること）\n",
    "    - n_estimators\n",
    "        - いくつ決定木を作成するか。パターンを列挙。\n",
    "        - 入力値：integer, optional (default=10)\n",
    "        - 多ければ多いほど精度が良くなる(=計算時間とのトレードオフ)。\n",
    "    - max_features\n",
    "        - 各決定木で分類に使用する説明変数の数。目的変数のサンプリング時に、いくつの目的変数をサンプリングするかのパターンを列挙。\n",
    "        - 入力値：int, float, string or None, optional (default=”auto”)\n",
    "            - stringの入力候補は、auto”(\"sqrt”)はn_featuresの平方根、\"log2”はlog2(n_features)、\"None\"だとn_featuresをそのまま使う、など。\n",
    "        - 1つの説明変数で精度が低い場合は、数を増やすと精度が上がる可能性がある。\n",
    "    - max_depth\n",
    "        - どの深さの決定木を作成するか\n",
    "        - 入力値：integer or None, optional (default=None)\n",
    "        - 深ければ深いほど（数が大きいほど）複雑な分岐になる(=過学習を起こしやすい)\n",
    "    - min_samples_leaf: 決定木の葉に分類されるサンプル数を決めるパラメータ\n",
    "        - 決定木の葉に分類されるサンプル数\n",
    "        - 入力値：int, float, optional (default=2)\n",
    "        - 数が大きいほど木の深さが浅くなる。→過学習を防ぐ\n",
    "\n",
    "\n",
    "[[Ref](https://qiita.com/kenchin110100/items/24cbb1bcab80c7a6115c)]\n",
    "[[Ref2](http://ohke.hateblo.jp/entry/2017/08/04/230000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# チューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=4, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators = 4,\n",
    "    max_features = 'auto',\n",
    "    criterion = 'gini',\n",
    "    max_depth = 2,\n",
    "    min_samples_split = 2,\n",
    "    min_samples_leaf = 1)\n",
    "\n",
    "clf.fit(X_train, y_train) #0.793296089385 と下がった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=9, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_estimatorsのみを変更\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators = 9, # 6より9の方が結果がよかった。\n",
    "    max_features = 'auto',\n",
    "    criterion = 'gini',\n",
    "    max_depth = 2,\n",
    "    min_samples_split = 2,\n",
    "    min_samples_leaf = 1)\n",
    "\n",
    "clf.fit(X_train, y_train) #0.804469273743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826815642458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 検証とは何か\n",
    "学習モデルを評価すること。\n",
    "\n",
    "- なぜ検証を行う必要があるのか(Accuracyだけではダメな理由も含めること)\n",
    "学習モデルが過学習・未学習しているかなどの精度の確認する必要がある。\n",
    "\n",
    "Accuracyは過学習や未学習の精度を含んでいるため、評価の信頼性が比較的低い、かつ汎化性能が検証できない\n",
    "\n",
    "> パラメータ値を得るために学習に使用した訓練データを性能評価に使用すると過適応（Overfitting）、あるいは未適応（Underfitting）の状態を含んだ見積り値になるため、汎化性能を検証できない。\n",
    ">[機械学習における学習方法と性能評価の基礎知識](http://www.buildinsider.net/small/bookthinkingmachines/0103)\n",
    "\n",
    "過学習の確認・改善は下記を使う。\n",
    "    - 正則化\n",
    "    - 交差検証によるパラメータチューニング\n",
    "    - 学習曲線を確認\n",
    "\n",
    "- 主な検証方法について2つ以上記述せよ\n",
    "    - K-Fold Cross-Validation\n",
    "    - ROC曲線(Receiver Operating Characteristic)\n",
    "    - AUC (Area Under the Curve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFoldについて記述せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-分割交差検証について説明せよ\n",
    "\n",
    "    - データをk個に分割してサブサンプルグループを作る。k−1(サブサンプルグループ) で訓練をする。これをk回繰り返す（Test foldされるサブサンプルグループデータは各繰り返しの中でそれぞれ異なる）。それぞれの訓練データで残った1サブサンプルグループの集合がテストデータになる。\n",
    "    - 上記のように評価用データを変更しながら k 回繰り返した結果の平均を精度に用いることが多い\n",
    "    - k回繰り返すため、kが大きくなるほど、計算時間がかかる。\n",
    "\n",
    "[[交差確認（交差検証、Cross-Validation）の簡単な説明](https://mathwords.net/kousakakunin)]\n",
    "\n",
    "- K-分割交差検証はデータセットを何個に分割するか(まとめて回答)\n",
    "- データセットを分割する際、その個数はどのように考えると良いか(まとめて回答)\n",
    "- K-分割交差検証は何回の検証を行うか(まとめて回答)\n",
    "\n",
    "    - 10個と仮定。\n",
    "    - データ数が800の場合、\n",
    "    - サブサンプルグループは80個。\n",
    "    - 訓練データ数は720個。\n",
    "    - 交差検証回数は10回。\n",
    "    - テストデータは80個 x 10セット。\n",
    "\n",
    "\n",
    "- K-分割交差検証の結果は、最終的にどのように求められるか\n",
    "    - 。テストデータとモデルの残差の平均二乗誤差（mean square error; MSE）が予測精度の指標としてよく使われる。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFoldを実施する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "#ntrain = train.shape[0]\n",
    "#ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NSPLITS = 10 # set folds for out-of-fold prediction\n",
    "\n",
    "#kfold = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "kfold = KFold(n_splits= NSPLITS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for train_indices, test_indices in kfold.split(X):\n",
    "#     print('Train: %s | test: %s' % (train_indices, test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = cross_val_score(clf, X, y, cv=kfold, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81111111,  0.82022472,  0.76404494,  0.82022472,  0.7752809 ,\n",
       "        0.79775281,  0.71910112,  0.73033708,  0.82022472,  0.79775281])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.561% (3.548%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# どの特徴量が重要であったかを調査する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 8 (0.240539) cumsum: 0.240539\n",
      "2. feature 0 (0.237868) cumsum: 0.478407\n",
      "3. feature 1 (0.226834) cumsum: 0.705241\n",
      "4. feature 6 (0.156987) cumsum: 0.862227\n",
      "5. feature 5 (0.062155) cumsum: 0.924383\n",
      "6. feature 7 (0.042627) cumsum: 0.967010\n",
      "7. feature 3 (0.025429) cumsum: 0.992439\n",
      "8. feature 2 (0.003989) cumsum: 0.996428\n",
      "9. feature 4 (0.003572) cumsum: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "cumsum = 0.0\n",
    "for f in range(X_train.shape[1]):\n",
    "    cumsum+=importances[indices[f]]\n",
    "    print(\"%d. feature %d (%f) cumsum: %f\" % (f + 1, indices[f], importances[indices[f]], cumsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFn1JREFUeJzt3X+0XWV95/H3xwT8AYyo3CKQhGRsdCajVu0VndHqXYot\n8UdgWu1AR6tdauqsMurYqaLtMA7TrqXVcaZdpR3xR2W0GBBbTWtadNRMq600F8QfAbExoklAufJD\n8ScEv/PH2aGH2xsS7tm554Tn/VrrLM7e+zn7+d7Dzec893nO2SdVhSSpLfcbdwGSpKVn+EtSgwx/\nSWqQ4S9JDTL8JalBhr8kNcjwl4Ak/zvJfxl3HdJSie/z1yiSXAccD9w5tPuRVXX9COecAd5XVStG\nq+7wlOQ9wO6q+q1x16L7Lkf+6sPzqurooduig78PSZaPs/9RJFk27hrUBsNfh0ySJyf52yS3Jvlc\nN6Lfd+xXklyT5LYkO5P8arf/KOAvgROTfLe7nZjkPUl+e+jxM0l2D21fl+R1ST4PfC/J8u5xH0wy\nl+SrSV55D7Xedf59507y2iQ3JrkhyRlJnp3ky0luTvKGoce+McmlSS7ufp4rk/zU0PF/mWRr9zxs\nT7JhXr9/lGRLku8BLwX+PfDa7mf/867dOUm+0p3/6iT/dugcL0nyqSRvTXJL97OuHzr+0CR/nOT6\n7viHho49N8lVXW1/m+SxQ8del2RP1+e1SZ55EP/bdbioKm/eFn0DrgNOXWD/ScBNwLMZDDKe1W1P\ndcefAzwCCPB04PvAE7pjMwymPYbP9x7gt4e279amq+MqYCXwwK7PK4BzgSOBfw7sBH5uPz/HXefv\nzr23e+wRwMuBOeAi4BjgXwE/ANZ07d8I3AE8v2v/n4GvdvePAHYAb+jqeAZwG/CooX6/DTylq/kB\n83/Wrt0LgBO7Nv8O+B5wQnfsJV3/LweWAf8BuJ5/nNb9CHAx8JCunqd3+x8P3Ag8qXvci7vn8f7A\no4BdwIld29XAI8b9++atv5sjf/XhQ93I8dahUeULgS1VtaWqflxVHwNmGbwYUFUfqaqv1MD/Az4K\n/MyIdfx+Ve2qqh8AT2TwQnNeVd1eVTuBdwBnHuS57gB+p6ruADYBxwG/V1W3VdV24Grgp4baX1FV\nl3bt38YgxJ/c3Y4G3tTV8QngL4Czhh774ar6dPc8/XChYqrqA1V1fdfmYuAfgFOGmnytqt5RVXcC\nFwInAMcnOQFYD7yiqm6pqju65xtgI/D2qrq8qu6sqguBH3U138ngRWBdkiOq6rqq+spBPnc6DBj+\n6sMZVXVsdzuj23cy8IKhF4VbgacyCCWSrE/ymW4K5VYGLwrHjVjHrqH7JzOYOhru/w0MFqcPxk1d\nkMJglA/wzaHjP2AQ6v+k76r6MbCbwUj9RGBXt2+frzH4y2ihuheU5JeHpmduBR7N3Z+vbwz1//3u\n7tEM/hK6uapuWeC0JwO/Pu85WslgtL8DeDWDv2puTLIpyYkHqlOHD8Nfh8ou4L1DLwrHVtVRVfWm\nJPcHPgi8FTi+qo4FtjCYAgJY6C1o3wMeNLT98AXaDD9uF/DVef0fU1XPHvknW9jKfXeS3A9YwWDq\n5XpgZbdvn1XAnv3U/U+2k5zM4K+Ws4GHdc/XF/nH5+ue7AIemuTY/Rz7nXnP0YOq6v0AVXVRVT2V\nwYtEAW8+iP50mDD8dai8D3hekp9LsizJA7qF1BUM5r7vz2AefW+3OPmzQ4/9JvCwJA8e2ncV8Oxu\n8fLhDEal9+Tvgdu6RcsHdjU8OskTe/sJ7+6nk/x8Bu80ejWD6ZPPAJczWM94bZIjukXv5zGYStqf\nbzJYo9jnKAbhOweDxXIGI/8DqqobGCyg/2GSh3Q1PK07/A7gFUmelIGjkjwnyTFJHpXkGd0L9Q8Z\n/KXz4/10o8OQ4a9Doqp2AaczmGqZYzDK/A3gflV1G/BK4BLgFuCXgM1Dj/0S8H5gZzcdcSLwXuBz\nDBYkP8pgAfOe+r8TeC7wOAaLr98C3gk8+J4eN4IPM1iIvQV4EfDz3fz67QzCfn1Xwx8Cv9z9jPvz\nLgZz7bcm+VBVXQ38D+DvGLwwPAb49L2o7UUM1jC+xGCB99UAVTXLYJH4D7q6dzBYPIbBi/Obupq/\nAfwE8Pp70acmnB/ykkaU5I3AT1bVC8ddi3SwHPlLUoMMf0lqkNM+ktQgR/6S1KCJvQDWcccdV6tX\nrx53GZJ0WLniiiu+VVVTB2o3seG/evVqZmdnx12GJB1WknztYNo57SNJDTL8JalBvYR/ktO6633v\nSHLOftr8Yncd8u1JLuqjX0nS4ow855/BNw+dz+B67buBbUk2dx9J39dmLYOPhj+lqm5J8hOj9itJ\nWrw+Rv6nADuqamd3HZNNDK7pMuzlwPn7LitbVTf20K8kaZH6CP+TuPv1yHdz92uVAzwSeGSST3fX\ncD+th34lSYu0VG/1XA6sZfD1eCuAv07ymKq6dbhRko0Mvl2IVatWLVFpktSePkb+exj6IgsG4b5n\nXpvdwObuErdfBb7M4MXgbqrqgqqarqrpqakDfkZBkrRIfYT/NmBtkjVJjmTwHamb57X5EINRP0mO\nYzANtLOHvg+pmZkZZmZmxl2GJPVu5PCvqr0Mvl7uMuAa4JKq2p7kvCQbumaXATcluRr4JPAbVXXT\nqH1Lkhanlzn/qtrC4DtYh/edO3S/gNd0N0nSmPkJX0lqkOEvSQ0y/CWpQYa/JDXI8NdB8W2v0n2L\n4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+\nktQgw1+SGtRL+Cc5Lcm1SXYkOWeB4y9JMpfkqu72sj76lSQtzshf4J5kGXA+8CxgN7Atyeaqunpe\n04ur6uxR+5Mkja6Pkf8pwI6q2llVtwObgNN7OK8k6RDpI/xPAnYNbe/u9s33C0k+n+TSJCt76FeS\ntEhLteD758Dqqnos8DHgwoUaJdmYZDbJ7Nzc3BKVJknt6SP89wDDI/kV3b67VNVNVfWjbvOdwE8v\ndKKquqCqpqtqempqqofSJEkL6SP8twFrk6xJciRwJrB5uEGSE4Y2NwDX9NCvJGmRRn63T1XtTXI2\ncBmwDHh3VW1Pch4wW1WbgVcm2QDsBW4GXjJqv5KkxRs5/AGqaguwZd6+c4fuvx54fR99tWZmZgaA\nrVu3jrUOSfctfsJXkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMM\nf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kN6iX8k5yW5NokO5Kc\ncw/tfiFJJZnuo19J0uKMHP5JlgHnA+uBdcBZSdYt0O4Y4FXA5aP2KUkaTR8j/1OAHVW1s6puBzYB\npy/Q7r8DbwZ+2EOfatDMzAwzMzPjLkO6T+gj/E8Cdg1t7+723SXJE4CVVfWRezpRko1JZpPMzs3N\n9VCaJGkhh3zBN8n9gLcBv36gtlV1QVVNV9X01NTUoS5NkprVR/jvAVYOba/o9u1zDPBoYGuS64An\nA5td9JWk8ekj/LcBa5OsSXIkcCawed/Bqvp2VR1XVaurajXwGWBDVc320LckaRFGDv+q2gucDVwG\nXANcUlXbk5yXZMOo55ck9W95Hyepqi3Alnn7zt1P25k++pQkLZ6f8JWkBhn+ktQgw1+SGmT4S1KD\nDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjw\nl6QGGf6S1CDDX5Ia1Ev4JzktybVJdiQ5Z4Hjr0jyhSRXJflUknV99CtJWpyRwz/JMuB8YD2wDjhr\ngXC/qKoeU1WPA34XeNuo/UqSFq+Pkf8pwI6q2llVtwObgNOHG1TVd4Y2jwKqh34lSYu0vIdznATs\nGtreDTxpfqMkvwa8BjgSeMZCJ0qyEdgIsGrVqh5KkyQtZMkWfKvq/Kp6BPA64Lf20+aCqpquqump\nqamlKk2SmtNH+O8BVg5tr+j27c8m4Iwe+pUkLVIf4b8NWJtkTZIjgTOBzcMNkqwd2nwO8A899CtJ\nWqSR5/yram+Ss4HLgGXAu6tqe5LzgNmq2gycneRU4A7gFuDFo/YrSVq8PhZ8qaotwJZ5+84duv+q\nPvqRJPXDT/hKUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JalAvl3c4\nXCRL87jyq2okTbimwn8SLNULEPgidKjMzMwAsHXr1rHWIY3CaR9JapDhL0kNctqnQYudelrMY516\nkiaTI39JapDhL0kNMvwlqUGGvyQ1qJfwT3JakmuT7EhyzgLHX5Pk6iSfT/LxJCf30a8kaXFGDv8k\ny4DzgfXAOuCsJOvmNfssMF1VjwUuBX531H4lSYvXx8j/FGBHVe2sqtuBTcDpww2q6pNV9f1u8zPA\nih76lSQtUh/hfxKwa2h7d7dvf14K/OVCB5JsTDKbZHZubq6H0iRJC1nSBd8kLwSmgbcsdLyqLqiq\n6aqanpqaWsrSJKkpfXzCdw+wcmh7RbfvbpKcCvwm8PSq+lEP/UqSFqmPkf82YG2SNUmOBM4ENg83\nSPJ44O3Ahqq6sYc+JUkjGDn8q2ovcDZwGXANcElVbU9yXpINXbO3AEcDH0hyVZLN+zmdJGkJ9HJh\nt6raAmyZt+/cofun9tGPJKkffsJXkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjv8NXYLPa7hBfz\nOL9LWLo7R/6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+0mFoZmaGmZmZcZeh\nw5jhL0kNMvwlqUGGvyQ1qJfwT3JakmuT7EhyzgLHn5bkyiR7kzy/jz4lSYs3cvgnWQacD6wH1gFn\nJVk3r9nXgZcAF43anyRpdH1c0vkUYEdV7QRIsgk4Hbh6X4Oquq479uMe+pMkjaiPaZ+TgF1D27u7\nffdako1JZpPMzs3N9VCaJGkhE7XgW1UXVNV0VU1PTU2NuxxJus/qI/z3ACuHtld0+yRJE6qP8N8G\nrE2yJsmRwJnA5h7OK0k6REYO/6raC5wNXAZcA1xSVduTnJdkA0CSJybZDbwAeHuS7aP2K0lavF6+\nwL2qtgBb5u07d+j+NgbTQZKkCTBRC76SpKVh+EtaNK8uevgy/CWpQYa/JDXI8JekBvXybh/pcJUs\n3WOrFt+X1DdH/pLUIMNfkhpk+EtSgwx/SWqQC77SBFjswvNiHufCs8CRvyQ1yfCXpAYZ/pLUIMNf\nkhrkgq8kwE87t8aRvyQ1yPCXpAYZ/pIOa5PyhTKTUsfB6iX8k5yW5NokO5Kcs8Dx+ye5uDt+eZLV\nffQrSVqckcM/yTLgfGA9sA44K8m6ec1eCtxSVT8J/E/gzaP2K0lavD7e7XMKsKOqdgIk2QScDlw9\n1OZ04I3d/UuBP0iSKtf8Jd3dJFzqooV3PvUR/icBu4a2dwNP2l+bqtqb5NvAw4BvDTdKshHYCLBq\n1aoeSru7e/sk75u+27q17RompY5JqGFS6piEGialjkmo4VDVcShN1IJvVV1QVdNVNT01NTXuciTp\nPquPkf8eYOXQ9opu30JtdidZDjwYuKmHviU1buuEDLUnpY6D1Uf4bwPWJlnDIOTPBH5pXpvNwIuB\nvwOeD3zC+f6Dc7j9Qkk6PIwc/t0c/tnAZcAy4N1VtT3JecBsVW0G3gW8N8kO4GYGLxCSpDHp5do+\nVbUF2DJv37lD938IvKCPviRJo/PCbpIWzWnJw9dEvdtHkrQ0DH9JapDhL0kNMvwlqUEu+EqHIRda\nNSpH/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lq\nkOEvSQ0a6aqeSR4KXAysBq4DfrGqblmg3V8BTwY+VVXPHaVPtcsrWUr9GXXkfw7w8apaC3y8217I\nW4AXjdiXJKkno4b/6cCF3f0LgTMWalRVHwduG7EvSVJPRg3/46vqhu7+N4DjRzlZko1JZpPMzs3N\njViaJGl/Djjnn+T/Ag9f4NBvDm9UVSWpUYqpqguACwCmp6dHOpckaf8OGP5Vder+jiX5ZpITquqG\nJCcAN/ZanSTpkBj1O3w3Ay8G3tT998MjVzRBfHeJpPuqVC1+diXJw4BLgFXA1xi81fPmJNPAK6rq\nZV27vwH+BXA0cBPw0qq67J7OPT09XbOzs4uuTZJalOSKqpo+ULuRRv5VdRPwzAX2zwIvG9r+mVH6\nkST1y0/4SlKDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkho00id8D6Ukcww+NTxuxwHf\nsgZgMuqYhBpgMuqYhBpgMuqYhBpgMuo4uaqmDtRoYsN/UiSZPZiPSt/Xa5iUOiahhkmpYxJqmJQ6\nJqGGSarjYDjtI0kNMvwlqUGG/4FdMO4CmIwaYDLqmIQaYDLqmIQaYDLqmIQaYHLqOCDn/CWpQY78\nJalBhr8kNcjw348k/ynJ9iRfTPL+JA8YUx2nJbk2yY4k54yphncnuTHJF8fR/1Adxya5NMmXklyT\n5F+PoYbrknwhyVVJxvJVc0ke1fW/7/adJK9e4hoekOTvk3yu+3fy35ay/6E6Vib5ZJKruzpeNY46\nulqWJflskr8YVw33hnP+C0hyEvApYF1V/SDJJcCWqnrPEtexDPgy8CxgN7ANOKuqrl7iOp4GfBf4\nP1X16KXse14dFwJ/U1XvTHIk8KCqunWJa7gOmK6qcX+QB7jrd2QP8KSqWrIPRSYJcFRVfTfJEQz+\nvbyqqj6zVDV0dZwAnFBVVyY5BrgCOGOp/410tbwGmAb+WVU9d6n7v7cc+e/fcuCBSZYDDwKuH0MN\npwA7qmpnVd0ObAJOX+oiquqvgZuXut9hSR4MPA14V1fT7Usd/BPqmcBXljL4AWrgu93mEd1tyUeS\nVXVDVV3Z3b8NuAY4aanrSLICeA7wzqXue7EM/wVU1R7grcDXgRuAb1fVR8dQyknArqHt3YzhF3tC\nrAHmgD/u/rR+Z5KjxlBHAR9NckWSjWPof74zgfePo+NumuMq4EbgY1V1+TjqGKpnNfB4YBx1/C/g\ntcCPx9D3ohj+C0jyEAYj7DXAicBRSV443qqatxx4AvBHVfV44HvAONZAnlpVTwDWA7/WTYmNRTf1\ntQH4wDj6r6o7q+pxwArglCTjnBI8Gvgg8Oqq+s4S9/1c4MaqumIp+x2V4b+wU4GvVtVcVd0B/Cnw\nb8ZQxx5g5dD2im5fi3YDu4dGl5cyeDFYUt1fhVTVjcCfMZiaG5f1wJVV9c0x1kA3/fZJ4LRx9N+t\nOXwQ+JOq+tMxlPAUYEO3HrQJeEaS942hjnvF8F/Y14EnJ3lQt7D1TAZziUttG7A2yZpulHcmsHkM\ndYxdVX0D2JXkUd2uZwJLvfB9VLeoSDfl9LPAON8BdRbjm/KZSnJsd/+BDN6U8KUx1BEG60DXVNXb\nlrp/gKp6fVWtqKrVDP6NfqKqJn6mYPm4C5hEVXV5kkuBK4G9wGcZw8e2q2pvkrOBy4BlwLuravtS\n15Hk/cAMcFyS3cB/rap3LXUdwH8E/qR7IdwJ/MoS93888GeDvGE5cFFV/dUS1wDc9eLzLOBXx9E/\ncAJwYfduo/sBl1TVON7i+BTgRcAXuvUHgDdU1ZYx1HJY8a2ektQgp30kqUGGvyQ1yPCXpAYZ/pLU\nIMNfkhpk+EtSgwx/SWrQ/wcbDzaT9YxmDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a269b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"b\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Pclass\n",
      "1 Sex\n",
      "2 Age\n",
      "3 SibSp\n",
      "4 Parch\n",
      "5 Fare\n",
      "6 Cabin\n",
      "7 Lname\n",
      "8 NamePrefix\n"
     ]
    }
   ],
   "source": [
    "col_list = list(X_train.columns)\n",
    "for i in range(len(col_list)):\n",
    "    print(str(i) + \" \" + col_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果より、8 NamePrefix, 0 Pclass, 1 Sex, 6 Cabin, 5 Fareで9割結果に影響する有効な特徴量であることがわかる。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
