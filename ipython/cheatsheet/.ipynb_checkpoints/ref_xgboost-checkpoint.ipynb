{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../../mltestdata/03_predict_hourly_wage/Income_training.csv\")\n",
    "test = pd.read_csv(\"../../../mltestdata/03_predict_hourly_wage/Income_testing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessiong\n",
    "* * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値も特にないため、省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold CV\n",
    "* * * * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train.compositeHourlyWages.values\n",
    "\n",
    "test_ID = test['ID']\n",
    "test.drop(\"ID\", axis = 1, inplace = True)\n",
    "\n",
    "train.drop(['compositeHourlyWages'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train,train_target,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Validation with local train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboostモデルの作成\n",
    "reg = xgb.XGBRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# パラメータを設定した場合は下記で設定可能\n",
    "#ind_params = {'objective': 'reg:linear'}\n",
    "#reg = xgb.XGBRegressor(**ind_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = reg.predict(X_train)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from local train:  6.02475299555\n",
      "MSE from local train:  36.2976486573\n",
      "R2 from local train:  0.395235324935\n"
     ]
    }
   ],
   "source": [
    "# The error metric: RMSE\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "print(\"RMSE from local train: \", rmse(y_test, y_pred))\n",
    "print(\"MSE from local train: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 from local train: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Validation with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor()\n",
    "\n",
    "# XGBoost params\n",
    "xgb_params = {\n",
    "    'objective' : ['reg:gamma','reg:linear'],\n",
    "    'learning_rate' : [0.05,0.1],\n",
    "    'n_estimators' : [50,100,200],\n",
    "    'max_depth' : [2,4,6],\n",
    "    'subsample' : [0.8,0.85,0.9,0.95],\n",
    "    'colsample_bytree' : [0.5,1.0],\n",
    "    'min_child_weight' : [5,10,15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'objective': ['reg:gamma', 'reg:linear'], 'learning_rate': [0.05, 0.1], 'n_estimators': [50, 100, 200], 'max_depth': [2, 4, 6], 'subsample': [0.8, 0.85, 0.9, 0.95], 'colsample_bytree': [0.5, 1.0], 'min_child_weight': [5, 10, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scoring_func = make_scorer(mean_squared_error)\n",
    "\n",
    "#grid = GridSearchCV(reg,xgb_params,scoring=scoring_func,cv=5,n_jobs=-1)\n",
    "grid = GridSearchCV(reg,xgb_params,scoring='neg_mean_squared_error',cv=5,n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 2, 'min_child_weight': 15, 'n_estimators': 100, 'objective': 'reg:gamma', 'subsample': 0.8}\n",
      "Best Estimator:  XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=2, min_child_weight=15, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='reg:gamma', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=0.8)\n",
      "MSE:  -38.8108460369\n"
     ]
    }
   ],
   "source": [
    "# Best Params and Score\n",
    "print(\"Best params: \", grid.best_params_)\n",
    "print(\"Best Estimator: \", grid.best_estimator_)\n",
    "\n",
    "print(\"MSE: \", grid.best_score_)\n",
    "\n",
    "# best_score_ : Mean cross-validated score of the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result of combination\n",
    "#index = 1\n",
    "#for params, mean_score, scores in grid.grid_scores_:\n",
    "#    print(\"%d) %0.3f (+/-%0.03f) \" % (index, mean_score, scores.std() / 2))\n",
    "#    print(\"Params: %r\" % params)\n",
    "#    print(\"_\"*30)\n",
    "#    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=15, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:gamma', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改めて最適パラメータで学習\n",
    "gdm = xgb.XGBRegressor(**grid.best_params_) # 6.01679534923\n",
    "#gdm = xgb.XGBRegressor(**xgb_params) # 6.0907929398\n",
    "gdm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid = gdm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from local train:  5.99341470614\n",
      "MSE from local train:  35.9210198398\n",
      "R2 from local train:  0.401510436764\n"
     ]
    }
   ],
   "source": [
    "# The error metric: RMSE\n",
    "print(\"RMSE from local train: \", rmse(y_test, y_pred_grid))\n",
    "print(\"MSE from local train: \", mean_squared_error(y_test, y_pred_grid))\n",
    "print(\"R2 from local train: \", r2_score(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Findings__\n",
    "- RMSEがやや下がっている。\n",
    "- R2がやや増えている。過学習までには至っていないと判断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validation with sklearn cv (normal k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -38.33 (+/- 8.79)\n",
      "Fold    0: MSE= -41.7835029743\n",
      "Fold    1: MSE= -37.8696223126\n",
      "Fold    2: MSE= -32.5023692077\n",
      "Fold    3: MSE= -44.5730119578\n",
      "Fold    4: MSE= -34.9362552968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "scores = cross_val_score(gdm, train, train_target, scoring = \"neg_mean_squared_error\",cv=5)\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    print('Fold %4d: MSE= %s'% (i, score))\n",
    "    \n",
    "# Scoring types: http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Validation with sklearn cv (Stratified k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukiry/lab/March/lib/python3.6/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -33.20 (+/- 17.66)\n",
      "Stratified-Fold    0: MSE= -50.7753717825\n",
      "Stratified-Fold    1: MSE= -27.6839607022\n",
      "Stratified-Fold    2: MSE= -28.770991798\n",
      "Stratified-Fold    3: MSE= -28.4326640183\n",
      "Stratified-Fold    4: MSE= -30.3428421976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "\n",
    "scores = cross_val_score(gdm, train, train_target, scoring = \"neg_mean_squared_error\",cv=skf)\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    print('Stratified-Fold %4d: MSE= %s'% (i, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Validation without cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "import time\n",
    "#kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ce29eb4798e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0my_val_kf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_kf_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mfold_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_kf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_kf_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fold cv {} RMSE score is {:.6f}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_rmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_rmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_rmse' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=NFOLDS, random_state=SEED)\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "# initialise the size of out-of-fold train an test prediction\n",
    "scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train, train_target)):\n",
    "\n",
    "    x_train_kf, x_val_kf = train.loc[train_index, :], train.loc[test_index, :]\n",
    "    y_train_kf, y_val_kf = train_target[train_index], train_target[test_index]\n",
    " \n",
    "    # Make data as numpy\n",
    "    x_train_kf_values = x_train_kf.values\n",
    "    x_val_kf_values = x_val_kf.values\n",
    "\n",
    "    x_test_values = test.values\n",
    "\n",
    "    # fit the input classifier and perform prediction.\n",
    "    gdm.fit(x_train_kf_values, y_train_kf)\n",
    "\n",
    "    y_val_kf_pred = gdm.predict(x_val_kf_values)\n",
    "    \n",
    "    fold_rmse = eval_rmse(y_val_kf, y_val_kf_pred)\n",
    "    print('fold cv {} RMSE score is {:.6f}\\n'.format(i, fold_rmse))\n",
    "    scores.append(fold_rmse)\n",
    "\n",
    "print('cv RMSE score is {:.3f} +/- {:.3f}\\n'.format(np.mean(scores),np.std(scores)))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Stratified K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "# initialise the size of out-of-fold train an test prediction\n",
    "scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, train_target)):\n",
    "\n",
    "    x_train_kf, x_val_kf = train.loc[train_index, :], train.loc[test_index, :]\n",
    "    y_train_kf, y_val_kf = train_target[train_index], train_target[test_index]\n",
    " \n",
    "    # Make data as numpy\n",
    "    x_train_kf_values = x_train_kf.values\n",
    "    x_val_kf_values = x_val_kf.values\n",
    "\n",
    "    x_test_values = test.values\n",
    "\n",
    "    # fit the input classifier and perform prediction.\n",
    "    gdm.fit(x_train_kf_values, y_train_kf)\n",
    "\n",
    "    y_val_kf_pred = gdm.predict(x_val_kf_values)\n",
    "    \n",
    "    fold_rmse = eval_rmse(y_val_kf, y_val_kf_pred)\n",
    "    print('fold cv {} RMSE score is {:.6f}\\n'.format(i, fold_rmse))\n",
    "    scores.append(fold_rmse)\n",
    "\n",
    "print('cv RMSE score is {:.3f} +/- {:.3f}\\n'.format(np.mean(scores),np.std(scores)))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. K-fold CV with Out-of-Fold Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn K-fold & OOF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_sklearn(clf, x_train, y_train , x_test, kf,scale=False, verbose=True):\n",
    "    start_time=time.time()\n",
    "    \n",
    "    # initialise the size of out-of-fold train an test prediction\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "\n",
    "    # use the kfold object to generate the required folds\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        # generate training folds and validation fold\n",
    "        x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[test_index, :]\n",
    "        y_train_kf, y_val_kf = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # perform scaling if required i.e. for linear algorithms\n",
    "        if scale:\n",
    "            scaler = StandardScaler().fit(x_train_kf.values)\n",
    "            x_train_kf_values = scaler.transform(x_train_kf.values)\n",
    "            x_val_kf_values = scaler.transform(x_val_kf.values)\n",
    "            x_test_values = scaler.transform(x_test.values)\n",
    "        else:\n",
    "            x_train_kf_values = x_train_kf.values\n",
    "            x_val_kf_values = x_val_kf.values\n",
    "            x_test_values = x_test.values\n",
    "        \n",
    "        # fit the input classifier and perform prediction.\n",
    "        clf.fit(x_train_kf_values, y_train_kf.values)\n",
    "        val_pred=clf.predict_proba(x_val_kf_values)[:,1]\n",
    "        train_pred[test_index] += val_pred\n",
    "\n",
    "        y_test_preds = clf.predict_proba(x_test_values)[:,1]\n",
    "        test_pred += y_test_preds\n",
    "\n",
    "        fold_auc = roc_auc_score(y_val_kf.values, val_pred)\n",
    "        fold_gini_norm = auc_to_gini_norm(fold_auc)\n",
    "\n",
    "        if verbose:\n",
    "            print('fold cv {} AUC score is {:.6f}, Gini_Norm score is {:.6f}'.format(i, fold_auc, fold_gini_norm))\n",
    "\n",
    "    test_pred /= kf.n_splits\n",
    "\n",
    "    cv_auc = roc_auc_score(y_train, train_pred)\n",
    "    cv_gini_norm = auc_to_gini_norm(cv_auc)\n",
    "    cv_score = [cv_auc, cv_gini_norm]\n",
    "    if verbose:\n",
    "        print('cv AUC score is {:.6f}, Gini_Norm score is {:.6f}'.format(cv_auc, cv_gini_norm))\n",
    "        end_time = time.time()\n",
    "        print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n",
    "    return cv_score, train_pred,test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost K-fold & OOF function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LigthGBM K-fold & OOF function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gdm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['ID'] = test_ID\n",
    "sub['compositeHourlyWages'] = predictions\n",
    "sub.to_csv('rs_hourly_submission_24-Dec-2017_v02.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEICAYAAAA3PAFIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nifv9GNDXYZIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114ca02b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature importance のプロット\n",
    "importances = pd.Series(gdm.feature_importances_, index = train.columns)\n",
    "importances = importances.sort_values()\n",
    "importances.plot(kind = \"barh\")\n",
    "plt.title(\"imporance in the xgboost Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ジニ係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gini(y_true, y_prob):\n",
    "   y_true = np.asarray(y_true)\n",
    "   y_true = y_true[np.argsort(y_prob)]\n",
    "   ntrue = 0\n",
    "   gini = 0\n",
    "   delta = 0\n",
    "   n = len(y_true)\n",
    "   for i in range(n-1, -1, -1):\n",
    "       y_i = y_true[i]\n",
    "       ntrue += y_i\n",
    "       gini += y_i * delta\n",
    "       delta += 1 - y_i\n",
    "   gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "   return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFoldの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [model_selection](http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html)\n",
    "- [cross_validation](http://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "- [model_evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=4, random_state=None, shuffle=False)\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "TRAIN: 6 TEST: 2\n",
      "TRAIN: [0 1 4 5 6 7] TEST: [2 3]\n",
      "TRAIN: 6 TEST: 2\n",
      "TRAIN: [0 1 2 3 6 7] TEST: [4 5]\n",
      "TRAIN: 6 TEST: 2\n",
      "TRAIN: [0 1 2 3 4 5] TEST: [6 7]\n",
      "TRAIN: 6 TEST: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4],[3, 4], [7, 8], [6, 7], [7, 4]])\n",
    "y = np.array([0, 0, 1, 1, 0, 0, 1, 0])\n",
    "kf = KFold(n_splits=4)\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StratifiedKFoldの使い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
      "TRAIN: [3 4 5 6 7] TEST: [0 1 2]\n",
      "TRAIN: 5 TEST: 3\n",
      "TRAIN: [0 1 2 5 6 7] TEST: [3 4]\n",
      "TRAIN: 6 TEST: 2\n",
      "TRAIN: [0 1 2 3 4 7] TEST: [5 6]\n",
      "TRAIN: 6 TEST: 2\n",
      "TRAIN: [0 1 2 3 4 5 6] TEST: [7]\n",
      "TRAIN: 7 TEST: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukiry/lab/March/lib/python3.6/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4],[3, 4], [7, 8], [6, 7], [7, 4]])\n",
    "y = np.array([0, 0, 1, 1, 0, 0, 1, 0])\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "print(skf)  \n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
