{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=2017).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, train_target, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gradient Boosting Regression\n",
    "\n",
    "Reference\n",
    "- [Gradient Boosted Regression Trees](https://www.datarobot.com/blog/gradient-boosted-regression-trees/)\n",
    "- [Caifornia house price predictions with Gradient Boosted Regression Trees](https://shankarmsy.github.io/stories/gbrt-sklearn.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# model_selection.GridSearchCV\n",
    "# =================================================\n",
    "# 1) Create model\n",
    "# Set params\n",
    "# Scores XXX\n",
    "est = GradientBoostingRegressor(n_estimators=3000)\n",
    "\n",
    "# 2) Set the grid\n",
    "param_grid = {'n_estimators':[100,1000,3000], \n",
    "              'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'min_samples_leaf': [3, 5, 9, 17],\n",
    "#              'min_saples_split': [5, 10, 15],\n",
    "              'max_features': [1.0, 0.3, 0.1] ## not possible in our example (only 1 fx)\n",
    "              }\n",
    "# 3) Run GridSearch\n",
    "grid = GridSearchCV(est, param_grid, n_jobs=5).fit(X_train, y_train)\n",
    "\n",
    "# 4) Show best Params and Score\n",
    "print(\"_\"*30)\n",
    "print(\"Result of Gridsearch\")\n",
    "print(\"Best params: \", grid.best_params_)\n",
    "print(\"Best Estimator: \", grid.best_estimator_)\n",
    "print(\"MSE: \", grid.best_score_)\n",
    "\n",
    "# 5) Learning with best params\n",
    "gbm_g = GradientBoostingRegressor(**grid.best_params_)\n",
    "gbm_g.fit(X_train, y_train)\n",
    "y_pred_gs = gbm_g.predict(X_test)\n",
    "\n",
    "# 6) The error metric: RMSE\n",
    "print(\"_\"*30)\n",
    "print(\"vs Prediction\")\n",
    "print(\"RMSE from local train: \", rmse(y_test, y_pred_gs))\n",
    "print(\"MSE from local train: \", mean_squared_error(y_test, y_pred_gs))\n",
    "print(\"R2 from local train: \", r2_score(y_test, y_pred_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# model_selection.GridSearchCV\n",
    "# =================================================\n",
    "# 1) Create model\n",
    "mdl = lgb.LGBMRegressor(boosting_type= 'gbdt', \n",
    "                        n_jobs = 5,\n",
    "                        metric='RMSE'\n",
    "                       )\n",
    "\n",
    "\n",
    "#Best params:  {'colsample_bytree': 0.8, 'learning_rate': 0.05, \n",
    "#'max_depth': 3, 'n_estimators': 100, 'num_leaves': 5, \n",
    "#'objective': 'regression', 'reg_alpha': 1.2, 'reg_lambda': 1.4, 'subsample': 0.75}\n",
    "\n",
    "# 2) Set params for gridsearch\n",
    "gridParams = {\n",
    "    'objective': ['binary','regression'],\n",
    "    'num_leaves': [4,5,6], #2,10,20,100   \n",
    "    'learning_rate': [0.05, 0.06], # 0.005,\n",
    "    'n_estimators': [100], #8,24,\n",
    "    'colsample_bytree' :[0.8, 0.85, 0.9], #0.64,\n",
    "    'reg_lambda' : [1.3,1.4,1.5], #1,1.2,\n",
    "    'max_depth' :[2,3,4], #1,2,5,10\n",
    "    'subsample' :[0.7,0.75], \n",
    "    'reg_alpha' : [1.2], #0.1,0.51,\n",
    "#    'min_split_gain' :[],\n",
    "#    'subsample_for_bin' :[],\n",
    "#    'max_drop' :[], \n",
    "#    'gaussian_eta' :[], \n",
    "#    'drop_rate' :[],\n",
    "#    'silent' :[], \n",
    "#    'boosting_type' :['gbdt'], \n",
    "#    'min_child_weight' :[], \n",
    "#    'skip_drop' :[], \n",
    "#    'fair_c' :[], \n",
    "#    'seed' :[], \n",
    "#    'poisson_max_delta_step' :[], \n",
    "#    'subsample_freq' :[], \n",
    "#    'max_bin' :[],  #55\n",
    "#    'nthread' :[], \n",
    "#    'min_child_samples' :[], \n",
    "#    'huber_delta' :[], \n",
    "#    'use_missing' :[], \n",
    "#    'uniform_drop' :[], \n",
    "#    'bagging_fraction': [] #0.8,\n",
    "#    'bagging_freq': [] # 5\n",
    "#    'feature_fraction': [] # 0.2319,\n",
    "#    'feature_fraction_seed': [] #9\n",
    "#    'bagging_seed': [] #9,\n",
    "#    'min_data_in_leaf': [] #6\n",
    "#    'min_sum_hessian_in_leaf': [] # 11                              \n",
    "#    'xgboost_dart_mode' :[]\n",
    "}\n",
    "\n",
    "# 3) Run GridSearch\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 4) Show best Params and Score\n",
    "print(\"_\"*30)\n",
    "print(\"Result of Gridsearch\")\n",
    "print(\"Best params: \", grid.best_params_)\n",
    "print(\"Best Estimator: \", grid.best_estimator_)\n",
    "print(\"MSE: \", grid.best_score_)\n",
    "\n",
    "# 5) Learning with best params\n",
    "lgm_g = lgb.LGBMRegressor(**grid.best_params_)\n",
    "lgm_g.fit(X_train, y_train)\n",
    "y_pred_gs = lgm_g.predict(X_test)\n",
    "\n",
    "# 6) The error metric: RMSE\n",
    "print(\"_\"*30)\n",
    "print(\"vs Prediction\")\n",
    "print(\"RMSE from local train: \", rmse(y_test, y_pred_gs))\n",
    "print(\"MSE from local train: \", mean_squared_error(y_test, y_pred_gs))\n",
    "print(\"R2 from local train: \", r2_score(y_test, y_pred_gs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__ Score: __\n",
    "```\n",
    "______________________________\n",
    "Result of Gridsearch\n",
    "Best params:  {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 5, 'objective': 'regression', 'reg_alpha': 1.2, 'reg_lambda': 1.4, 'subsample': 0.75}\n",
    "Best Estimator:  LGBMRegressor(boosting_type='gbdt', colsample_bytree=0.8, learning_rate=0.05,\n",
    "       max_bin=255, max_depth=3, metric='RMSE', min_child_samples=20,\n",
    "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
    "       n_jobs=5, num_leaves=5, objective='regression', random_state=None,\n",
    "       reg_alpha=1.2, reg_lambda=1.4, silent=True, subsample=0.75,\n",
    "       subsample_for_bin=200000, subsample_freq=1)\n",
    "MSE:  0.349386487223\n",
    "______________________________\n",
    "vs Prediction\n",
    "RMSE from local train:  6.02327567741\n",
    "MSE from local train:  36.2798498861\n",
    "R2 from local train:  0.395531874947\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# model_selection.GridSearchCV\n",
    "# =================================================\n",
    "# 1) Create model\n",
    "model = KernelRidge()\n",
    "\n",
    "# 2) Set params for gridsearch\n",
    "param_grid = {\n",
    "    \"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
    "    \"gamma\": np.logspace(-2, 2, 5),\n",
    "    \"kernel\" : ['polynomial','rbf'],\n",
    "    \"degree\" : [2,5,10,20], \n",
    "    \"coef0\" : [2.5,5,10,20],\n",
    "}\n",
    "\n",
    "# 3) Run GridSearch\n",
    "model_ = GridSearchCV(estimator= model, param_grid= param_grid, scoring='neg_mean_squared_error',cv=5, n_jobs=-1)\n",
    "model_.fit(X_train, y_train)\n",
    "\n",
    "# 4) Show best Params and Score\n",
    "print(\"_\"*30)\n",
    "print(\"Result of Gridsearch\")\n",
    "print(\"Best params: \", model_.best_params_)\n",
    "print(\"Best Estimator: \", model_.best_estimator_)\n",
    "print(\"MSE: \", model_.best_score_)\n",
    "\n",
    "# 5) Learning with best params\n",
    "krr_g = KernelRidge(**model_.best_params_)\n",
    "krr_g.fit(X_train, y_train)\n",
    "y_pred_gs = krr_g.predict(X_test)\n",
    "\n",
    "# 6) The error metric: RMSE\n",
    "print(\"_\"*30)\n",
    "print(\"vs Prediction\")\n",
    "print(\"RMSE from local train: \", rmse(y_test, y_pred_gs))\n",
    "print(\"MSE from local train: \", mean_squared_error(y_test, y_pred_gs))\n",
    "print(\"R2 from local train: \", r2_score(y_test, y_pred_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Referring to followings\n",
    "- [Exploring features and regression models](https://www.kaggle.com/youssefer/xgb-and-lasso-regression)\n",
    "- [House Prices # Regression and Bagging techniques](https://www.kaggle.com/aarti1/house-prices-regression-and-bagging-techniques)\n",
    "- [XGB and Lasso Regression](https://www.kaggle.com/youssefer/xgb-and-lasso-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "print (\"10\tLasso regression\")\n",
    "# importance of train set size: first, we set a relevant alpha\n",
    "\n",
    "rm_tr=[]\n",
    "rm_te=[]\n",
    "\n",
    "opti=[]\n",
    "alphas=[1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1]\n",
    "# alphas=np.linspace(1e-4,1e-2,20)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     feat, price, test_size=0.8, random_state=42)\n",
    "\n",
    "for al in alphas:\n",
    "\tls=Lasso(alpha=al, copy_X=True, fit_intercept=True, max_iter=5000,\n",
    "\t   normalize=False, positive=False, precompute=False, random_state=111,\n",
    "\t   selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\tls.fit(X_train,y_train)\n",
    "\trm_tr.append(np.sqrt(mean_squared_error(y_train,ls.predict(X_train))))\n",
    "\trm_te.append(np.sqrt(mean_squared_error(y_test,ls.predict(X_test))))\n",
    "\n",
    "plt.figure()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.plot(np.log(alphas),rm_tr,np.log(alphas),rm_te,\"r\")\t\n",
    "plt.title(\"Train and test error vs log(alphas)\")\n",
    "#plt.savefig('fig4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# model_selection.GridSearchCV\n",
    "# =================================================\n",
    "# 1) Create model\n",
    "model = Lasso()\n",
    "\n",
    "# 2) Set params for gridsearch\n",
    "param_grid = { 'alpha': [i/100000 for i in range(1,50000)]}\n",
    "\n",
    "# 3) Run GridSearch\n",
    "model_ = GridSearchCV(estimator= model, param_grid= param_grid, scoring='neg_mean_squared_error',cv=5, n_jobs=-1)\n",
    "model_.fit(X_train, y_train)\n",
    "\n",
    "# 4) Show best Params and Score\n",
    "print(\"_\"*30)\n",
    "print(\"Result of Gridsearch\")\n",
    "print(\"Best params: \", model_.best_params_)\n",
    "print(\"Best Estimator: \", model_.best_estimator_)\n",
    "print(\"MSE: \", model_.best_score_)\n",
    "\n",
    "# 5) Learning with best params\n",
    "las_g = xgb.XGBRegressor(**model_.best_params_)\n",
    "las_g.fit(X_train, y_train)\n",
    "y_pred_gs = las_g.predict(X_test)\n",
    "\n",
    "# 6) The error metric: RMSE\n",
    "print(\"_\"*30)\n",
    "print(\"vs Prediction\")\n",
    "print(\"RMSE from local train: \", rmse(y_test, y_pred_gs))\n",
    "print(\"MSE from local train: \", mean_squared_error(y_test, y_pred_gs))\n",
    "print(\"R2 from local train: \", r2_score(y_test, y_pred_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# Manual GridSearch\n",
    "# =================================================\n",
    "# Search `alpha` regression parameters\n",
    "#x_train = x[x.train_test == 1]\n",
    "lasso = Lasso(max_iter=1e2, normalize=True)\n",
    "alphas = np.logspace(-5, -3, 10)\n",
    "scores = []\n",
    "scores_std = []\n",
    "for alpha in alphas:\n",
    "    lasso.alpha = alpha\n",
    "    this_scores = np.sqrt(-cross_val_score(lasso, train, train_target, cv=5, scoring='mean_squared_error'))\n",
    "    print('Compute alpha = {} - {}'.format(alpha, np.mean(this_scores)))\n",
    "    scores.append(np.mean(this_scores))\n",
    "    scores_std.append(np.std(this_scores))\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.semilogx(alphas, scores)\n",
    "plt.semilogx(alphas, np.array(scores) + np.array(scores_std) / np.sqrt(len(train)), 'b--')\n",
    "plt.semilogx(alphas, np.array(scores) - np.array(scores_std) / np.sqrt(len(train)), 'b--')\n",
    "plt.ylabel('CV score')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
    "#plt.savefig('lasso_lars.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_cv = ElasticNetCV(cv=5, random_state=2017)\n",
    "enr_cv.fit(X_train, y_train)\n",
    "print(enr_cv.alpha_)\n",
    "print(enr_cv.l1_ratio_)\n",
    "#print(enr_cv.intercept_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# model_selection.GridSearchCV\n",
    "# =================================================\n",
    "# 1) Create model\n",
    "regr = ElasticNet()\n",
    "\n",
    "# 2) Set params for gridsearch\n",
    "enr_params = {\n",
    "    'alpha' : [0.0640, 0.0645, 0.0649678226388, 0.65],\n",
    "    'l1_ratio' : [0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "}\n",
    "\n",
    "# 3) Run gridsearch\n",
    "grid_enr = GridSearchCV(regr,enr_params,scoring='neg_mean_squared_error',cv=5,n_jobs=-1)\n",
    "grid_enr.fit(X_train, y_train)\n",
    "\n",
    "# 4) Show best params and score\n",
    "print(\"_\"*30)\n",
    "print(\"Result of Gridsearch\")\n",
    "print(\"Best params: \", grid_enr.best_params_)\n",
    "print(\"Best Estimator: \", grid_enr.best_estimator_)\n",
    "print(\"MSE: \", grid_enr.best_score_)\n",
    "\n",
    "# 5) Learning with best params\n",
    "eln_g = ElasticNet(**grid_enr.best_params_)\n",
    "eln_g.fit(X_train, y_train)\n",
    "y_pred_gs = eln_g.predict(X_test)\n",
    "\n",
    "# 6) The error metric: RMSE\n",
    "print(\"_\"*30)\n",
    "print(\"vs Prediction\")\n",
    "print(\"RMSE from local train: \", rmse(y_test, y_pred_gs))\n",
    "print(\"MSE from local train: \", mean_squared_error(y_test, y_pred_gs))\n",
    "print(\"R2 from local train: \", r2_score(y_test, y_pred_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# model_selection.GridSearchCV\n",
    "# =================================================\n",
    "# 1) xgboostモデルの作成\n",
    "reg = xgb.XGBRegressor()\n",
    "\n",
    "# 2) XGBoost params\n",
    "xgb_params = {\n",
    "    'objective' : ['reg:gamma','reg:linear'],\n",
    "    'learning_rate' : [0.05,0.75,0.1,0.125],\n",
    "    'n_estimators' : [50,100,200],\n",
    "    'max_depth' : [2,4,6],\n",
    "    'subsample' : [0.79,0.8,0.81,0.85],\n",
    "    'colsample_bytree' : [0.9,1.0],\n",
    "    'min_child_weight' : [13,14, 15, 16]\n",
    "}\n",
    "\n",
    "# 3) Run GridSearch\n",
    "grid_xgb = GridSearchCV(reg,xgb_params,scoring='neg_mean_squared_error',cv=5,n_jobs=-1)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "# 4) Show best Params and Score\n",
    "print(\"_\"*30)\n",
    "print(\"Result of Gridsearch\")\n",
    "print(\"Best params: \", grid_xgb.best_params_)\n",
    "print(\"Best Estimator: \", grid_xgb.best_estimator_)\n",
    "print(\"MSE: \", grid_xgb.best_score_)\n",
    "\n",
    "# 5) Learning with best params\n",
    "xgr_g = xgb.XGBRegressor(**grid_xgb.best_params_)\n",
    "xgr_g.fit(X_train, y_train)\n",
    "y_pred_gs = xgr_g.predict(X_test)\n",
    "\n",
    "# 6) The error metric: RMSE\n",
    "print(\"_\"*30)\n",
    "print(\"vs Prediction\")\n",
    "print(\"RMSE from local train: \", rmse(y_test, y_pred_gs))\n",
    "print(\"MSE from local train: \", mean_squared_error(y_test, y_pred_gs))\n",
    "print(\"R2 from local train: \", r2_score(y_test, y_pred_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 総当たり戦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一次式における'LSTAT'の住宅価格への決定係数は0.430957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukiry/lab/March/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "\n",
    "boston = load_boston()\n",
    "X=pd.DataFrame(boston.data[:,:], columns=boston.feature_names)\n",
    "y=pd.DataFrame(boston.target[:])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "lin_1d = LinearRegression()\n",
    "x_train = X_train.loc[:, ['LSTAT']].as_matrix()\n",
    "lin_1d.fit(x_train, y_train)\n",
    "\n",
    "n = np.linspace(np.min(x_train),np.max(x_train), 1000)\n",
    "y_1d_fit=lin_1d.predict(n[:,np.newaxis])\n",
    "\n",
    "# LSTAT\n",
    "x_test = X_test['LSTAT'].values[:,np.newaxis]\n",
    "score_1d = lin_1d.score(x_test, y_test)\n",
    "print(\"一次式における'LSTAT'の住宅価格への決定係数は%f\" % (score_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:3 s:0.7535202032485527 p:('LSTAT', 'RM', 'NOX', 'RAD', 'CHAS')\n",
      "d:3 s:0.7685431811199619 p:('LSTAT', 'RM', 'RAD', 'DIS', 'TAX', 'B')\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "dim=[3,4]\n",
    "i = set(list(X.columns))\n",
    "\n",
    "for di in dim:\n",
    "\n",
    "    degree_=PolynomialFeatures(degree=di)\n",
    "\n",
    "    for p in chain.from_iterable(combinations(i, r) for r in range(len(i)+1)):\n",
    "        if len(p) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            x_train = X_train.loc[:, p].as_matrix()\n",
    "            x_train_d = degree_.fit_transform(x_train)\n",
    "\n",
    "            lin_ = LinearRegression(normalize=True)\n",
    "            #normalize=Trueは入力データを正規化してトレーニングすることを意味します。    \n",
    "            lin_.fit(x_train_d,y_train)\n",
    "\n",
    "            x_test = X_test.loc[:, p].as_matrix()\n",
    "            x_test_d = degree_.fit_transform(x_test)\n",
    "\n",
    "            score_d = lin_.score(x_test_d, y_test)\n",
    "\n",
    "            if score_d >= 0.75:\n",
    "                print('d:{0} s:{1} p:{2}'.format(di,score_d, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "\n",
    "boston = load_boston()\n",
    "X=pd.DataFrame(boston.data[:,:], columns=boston.feature_names)\n",
    "y=pd.DataFrame(boston.target[:],columns=['MEDV'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "params = {\"max_depth\":  list(range(1,11))}\n",
    "\n",
    "scoring_fnc=make_scorer(r2_score)\n",
    "\n",
    "grid = GridSearchCV(estimator=regressor, param_grid=params, scoring=scoring_fnc,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for params, mean_score, scores in grid.grid_scores_:\n",
    "#    print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() / 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.368496 (0.064662) with: {'max_depth': 1}\n",
      "0.626112 (0.111121) with: {'max_depth': 2}\n",
      "0.698623 (0.128678) with: {'max_depth': 3}\n",
      "0.742889 (0.129903) with: {'max_depth': 4}\n",
      "0.782156 (0.090582) with: {'max_depth': 5}\n",
      "0.752935 (0.100415) with: {'max_depth': 6}\n",
      "0.736055 (0.086652) with: {'max_depth': 7}\n",
      "0.746791 (0.092950) with: {'max_depth': 8}\n",
      "0.740257 (0.111650) with: {'max_depth': 9}\n",
      "0.766889 (0.103395) with: {'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00198293,  0.00157156,  0.00190525,  0.00142169,  0.00166516,\n",
       "         0.00173316,  0.00181875,  0.0019855 ,  0.00214195,  0.00211492]),\n",
       " 'mean_score_time': array([ 0.00058565,  0.00050249,  0.00049834,  0.00027561,  0.00025125,\n",
       "         0.000246  ,  0.00024881,  0.00026979,  0.0002737 ,  0.00025415]),\n",
       " 'mean_test_score': array([ 0.36849619,  0.62611191,  0.69862293,  0.74288852,  0.78215579,\n",
       "         0.75293457,  0.73605545,  0.74679111,  0.74025721,  0.76688932]),\n",
       " 'mean_train_score': array([ 0.48476147,  0.73065992,  0.83904408,  0.90665078,  0.93863857,\n",
       "         0.96125492,  0.97595741,  0.98612753,  0.99196729,  0.99524738]),\n",
       " 'param_max_depth': masked_array(data = [1 2 3 4 5 6 7 8 9 10],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'max_depth': 1},\n",
       "  {'max_depth': 2},\n",
       "  {'max_depth': 3},\n",
       "  {'max_depth': 4},\n",
       "  {'max_depth': 5},\n",
       "  {'max_depth': 6},\n",
       "  {'max_depth': 7},\n",
       "  {'max_depth': 8},\n",
       "  {'max_depth': 9},\n",
       "  {'max_depth': 10}],\n",
       " 'rank_test_score': array([10,  9,  8,  5,  1,  3,  7,  4,  6,  2], dtype=int32),\n",
       " 'split0_test_score': array([ 0.30767489,  0.64936367,  0.79223289,  0.80636715,  0.84248186,\n",
       "         0.85412024,  0.80171747,  0.86557038,  0.86678215,  0.86014274]),\n",
       " 'split0_train_score': array([ 0.46842968,  0.7150373 ,  0.83314472,  0.90379749,  0.9312242 ,\n",
       "         0.95692612,  0.97325975,  0.98393931,  0.99207987,  0.99559522]),\n",
       " 'split1_test_score': array([ 0.33057555,  0.42492162,  0.45714577,  0.60504402,  0.7441994 ,\n",
       "         0.75119463,  0.73260674,  0.70283515,  0.72505964,  0.70305574]),\n",
       " 'split1_train_score': array([ 0.49120139,  0.74658155,  0.84030185,  0.91552075,  0.9414533 ,\n",
       "         0.96138622,  0.97425678,  0.98695879,  0.99210965,  0.99449023]),\n",
       " 'split2_test_score': array([ 0.42251459,  0.7049177 ,  0.81692481,  0.8636611 ,  0.8550877 ,\n",
       "         0.82801918,  0.83106092,  0.83008217,  0.8360664 ,  0.84995681]),\n",
       " 'split2_train_score': array([ 0.48661107,  0.72167783,  0.83733403,  0.90716216,  0.94088476,\n",
       "         0.96441957,  0.98088613,  0.98864047,  0.9934679 ,  0.9968177 ]),\n",
       " 'split3_test_score': array([ 0.31444727,  0.60759023,  0.73662088,  0.56923584,  0.6206424 ,\n",
       "         0.56773918,  0.58082396,  0.6060482 ,  0.54922408,  0.59386081]),\n",
       " 'split3_train_score': array([ 0.50331698,  0.74907598,  0.85241386,  0.90987399,  0.94359633,\n",
       "         0.9632874 ,  0.97736389,  0.98593683,  0.99047052,  0.9945643 ]),\n",
       " 'split4_test_score': array([ 0.46850329,  0.74523698,  0.6900849 ,  0.87172505,  0.84919524,\n",
       "         0.76373291,  0.73404331,  0.72920248,  0.72395248,  0.82818725]),\n",
       " 'split4_train_score': array([ 0.47424822,  0.72092696,  0.83202593,  0.89689952,  0.93603424,\n",
       "         0.9602553 ,  0.97402053,  0.98516227,  0.99170853,  0.99476947]),\n",
       " 'std_fit_time': array([  5.65067102e-04,   3.70282171e-04,   2.04900894e-04,\n",
       "          4.06124198e-05,   2.47147850e-04,   7.13240008e-05,\n",
       "          1.13348917e-05,   1.17870191e-04,   1.24021394e-04,\n",
       "          2.39434937e-05]),\n",
       " 'std_score_time': array([  2.20482335e-04,   2.23771788e-04,   1.58857954e-04,\n",
       "          5.58506399e-05,   1.29119895e-05,   5.59222454e-06,\n",
       "          5.35375808e-06,   3.25011312e-05,   4.48870704e-05,\n",
       "          1.38553814e-05]),\n",
       " 'std_test_score': array([ 0.06466227,  0.11112121,  0.12867761,  0.12990317,  0.09058218,\n",
       "         0.10041538,  0.08665212,  0.09295032,  0.11165039,  0.10339538]),\n",
       " 'std_train_score': array([ 0.01238108,  0.01422761,  0.00731183,  0.00620573,  0.00445652,\n",
       "         0.00260388,  0.00283519,  0.00159764,  0.00095834,  0.00087809])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch関数作成\n",
    "# [20171106追記]\n",
    "[こちら](http://chrisstrelioff.ws/sandbox/2015/06/25/decision_trees_in_python_again_cross_validation.html)を参考にDecisionTreeRegressor()に書き換えて、再度グリッドサーチを実施し、パラメータを探索しました。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(grid_scores, n_top=3):\n",
    "    \"\"\"Report top n_top parameters settings, default n_top=3.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    grid_scores -- output from grid or random search\n",
    "    n_top -- how many to report, of top models\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] top parameter settings found in\n",
    "                  search\n",
    "    \"\"\"\n",
    "    top_scores = sorted(grid_scores,\n",
    "                        key=itemgetter(1),\n",
    "                        reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print((\"Mean validation score: \"\n",
    "               \"{0:.3f} (std: {1:.3f})\").format(\n",
    "               score.mean_validation_score,\n",
    "               np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "    return top_scores[0].parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from operator import itemgetter\n",
    "\n",
    "def run_gridsearch(X, y, clf, param_grid, cv=5):\n",
    "    \"\"\"Run a grid search for best Decision Tree parameters.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    X -- features\n",
    "    y -- targets (classes)\n",
    "    cf -- scikit-learn Decision Tree\n",
    "    param_grid -- [dict] parameter settings to test\n",
    "    cv -- fold of cross-validation, default 5\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] from report()\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(clf,\n",
    "                               param_grid=param_grid,\n",
    "                               cv=cv)\n",
    "    start = time()\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    print((\"\\nGridSearchCV took {:.2f} \"\n",
    "           \"seconds for {:d} candidate \"\n",
    "           \"parameter settings.\").format(time() - start,\n",
    "                len(grid_search.grid_scores_)))\n",
    "\n",
    "    top_params = report(grid_search.grid_scores_, 3)\n",
    "    return  top_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Grid Parameter Search via 10-fold CV\n",
      "\n",
      "GridSearchCV took 13.98 seconds for 180 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.366 (std: 0.417)\n",
      "Parameters: {'criterion': 'mae', 'max_depth': 5, 'max_leaf_nodes': None, 'min_samples_leaf': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.357 (std: 0.410)\n",
      "Parameters: {'criterion': 'mae', 'max_depth': 10, 'max_leaf_nodes': None, 'min_samples_leaf': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.354 (std: 0.416)\n",
      "Parameters: {'criterion': 'mae', 'max_depth': None, 'max_leaf_nodes': None, 'min_samples_leaf': 10}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukiry/lab/March/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/suzukiry/lab/March/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Grid Parameter Search via 10-fold CV\")\n",
    "\n",
    "# set of parameters to test\n",
    "param_grid = {\"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "              \"max_depth\": [None, 2, 5, 10],\n",
    "              \"min_samples_leaf\": [2, 5, 10],\n",
    "              \"max_leaf_nodes\": [None, 2, 5, 10, 20]\n",
    "              }\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "ts_gs = run_gridsearch(X, y, dt, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Best Parameters:\n",
      "parameter: criterion            setting: mae\n",
      "parameter: max_depth            setting: 5\n",
      "parameter: max_leaf_nodes       setting: None\n",
      "parameter: min_samples_leaf     setting: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-- Best Parameters:\")\n",
    "for k, v in ts_gs.items():\n",
    "    print(\"parameter: {:<20s} setting: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
