{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 総当たり戦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一次式における'LSTAT'の住宅価格への決定係数は0.430957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukiry/lab/March/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "\n",
    "boston = load_boston()\n",
    "X=pd.DataFrame(boston.data[:,:], columns=boston.feature_names)\n",
    "y=pd.DataFrame(boston.target[:])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "lin_1d = LinearRegression()\n",
    "x_train = X_train.loc[:, ['LSTAT']].as_matrix()\n",
    "lin_1d.fit(x_train, y_train)\n",
    "\n",
    "n = np.linspace(np.min(x_train),np.max(x_train), 1000)\n",
    "y_1d_fit=lin_1d.predict(n[:,np.newaxis])\n",
    "\n",
    "# LSTAT\n",
    "x_test = X_test['LSTAT'].values[:,np.newaxis]\n",
    "score_1d = lin_1d.score(x_test, y_test)\n",
    "print(\"一次式における'LSTAT'の住宅価格への決定係数は%f\" % (score_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:3 s:0.7535202032485527 p:('LSTAT', 'RM', 'NOX', 'RAD', 'CHAS')\n",
      "d:3 s:0.7685431811199619 p:('LSTAT', 'RM', 'RAD', 'DIS', 'TAX', 'B')\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "dim=[3,4]\n",
    "i = set(list(X.columns))\n",
    "\n",
    "for di in dim:\n",
    "\n",
    "    degree_=PolynomialFeatures(degree=di)\n",
    "\n",
    "    for p in chain.from_iterable(combinations(i, r) for r in range(len(i)+1)):\n",
    "        if len(p) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            x_train = X_train.loc[:, p].as_matrix()\n",
    "            x_train_d = degree_.fit_transform(x_train)\n",
    "\n",
    "            lin_ = LinearRegression(normalize=True)\n",
    "            #normalize=Trueは入力データを正規化してトレーニングすることを意味します。    \n",
    "            lin_.fit(x_train_d,y_train)\n",
    "\n",
    "            x_test = X_test.loc[:, p].as_matrix()\n",
    "            x_test_d = degree_.fit_transform(x_test)\n",
    "\n",
    "            score_d = lin_.score(x_test_d, y_test)\n",
    "\n",
    "            if score_d >= 0.75:\n",
    "                print('d:{0} s:{1} p:{2}'.format(di,score_d, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "\n",
    "boston = load_boston()\n",
    "X=pd.DataFrame(boston.data[:,:], columns=boston.feature_names)\n",
    "y=pd.DataFrame(boston.target[:],columns=['MEDV'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "params = {\"max_depth\":  list(range(1,11))}\n",
    "\n",
    "scoring_fnc=make_scorer(r2_score)\n",
    "\n",
    "grid = GridSearchCV(estimator=regressor, param_grid=params, scoring=scoring_fnc,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for params, mean_score, scores in grid.grid_scores_:\n",
    "#    print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() / 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.368496 (0.064662) with: {'max_depth': 1}\n",
      "0.626112 (0.111121) with: {'max_depth': 2}\n",
      "0.698623 (0.128678) with: {'max_depth': 3}\n",
      "0.742889 (0.129903) with: {'max_depth': 4}\n",
      "0.782156 (0.090582) with: {'max_depth': 5}\n",
      "0.752935 (0.100415) with: {'max_depth': 6}\n",
      "0.736055 (0.086652) with: {'max_depth': 7}\n",
      "0.746791 (0.092950) with: {'max_depth': 8}\n",
      "0.740257 (0.111650) with: {'max_depth': 9}\n",
      "0.766889 (0.103395) with: {'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00198293,  0.00157156,  0.00190525,  0.00142169,  0.00166516,\n",
       "         0.00173316,  0.00181875,  0.0019855 ,  0.00214195,  0.00211492]),\n",
       " 'mean_score_time': array([ 0.00058565,  0.00050249,  0.00049834,  0.00027561,  0.00025125,\n",
       "         0.000246  ,  0.00024881,  0.00026979,  0.0002737 ,  0.00025415]),\n",
       " 'mean_test_score': array([ 0.36849619,  0.62611191,  0.69862293,  0.74288852,  0.78215579,\n",
       "         0.75293457,  0.73605545,  0.74679111,  0.74025721,  0.76688932]),\n",
       " 'mean_train_score': array([ 0.48476147,  0.73065992,  0.83904408,  0.90665078,  0.93863857,\n",
       "         0.96125492,  0.97595741,  0.98612753,  0.99196729,  0.99524738]),\n",
       " 'param_max_depth': masked_array(data = [1 2 3 4 5 6 7 8 9 10],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'max_depth': 1},\n",
       "  {'max_depth': 2},\n",
       "  {'max_depth': 3},\n",
       "  {'max_depth': 4},\n",
       "  {'max_depth': 5},\n",
       "  {'max_depth': 6},\n",
       "  {'max_depth': 7},\n",
       "  {'max_depth': 8},\n",
       "  {'max_depth': 9},\n",
       "  {'max_depth': 10}],\n",
       " 'rank_test_score': array([10,  9,  8,  5,  1,  3,  7,  4,  6,  2], dtype=int32),\n",
       " 'split0_test_score': array([ 0.30767489,  0.64936367,  0.79223289,  0.80636715,  0.84248186,\n",
       "         0.85412024,  0.80171747,  0.86557038,  0.86678215,  0.86014274]),\n",
       " 'split0_train_score': array([ 0.46842968,  0.7150373 ,  0.83314472,  0.90379749,  0.9312242 ,\n",
       "         0.95692612,  0.97325975,  0.98393931,  0.99207987,  0.99559522]),\n",
       " 'split1_test_score': array([ 0.33057555,  0.42492162,  0.45714577,  0.60504402,  0.7441994 ,\n",
       "         0.75119463,  0.73260674,  0.70283515,  0.72505964,  0.70305574]),\n",
       " 'split1_train_score': array([ 0.49120139,  0.74658155,  0.84030185,  0.91552075,  0.9414533 ,\n",
       "         0.96138622,  0.97425678,  0.98695879,  0.99210965,  0.99449023]),\n",
       " 'split2_test_score': array([ 0.42251459,  0.7049177 ,  0.81692481,  0.8636611 ,  0.8550877 ,\n",
       "         0.82801918,  0.83106092,  0.83008217,  0.8360664 ,  0.84995681]),\n",
       " 'split2_train_score': array([ 0.48661107,  0.72167783,  0.83733403,  0.90716216,  0.94088476,\n",
       "         0.96441957,  0.98088613,  0.98864047,  0.9934679 ,  0.9968177 ]),\n",
       " 'split3_test_score': array([ 0.31444727,  0.60759023,  0.73662088,  0.56923584,  0.6206424 ,\n",
       "         0.56773918,  0.58082396,  0.6060482 ,  0.54922408,  0.59386081]),\n",
       " 'split3_train_score': array([ 0.50331698,  0.74907598,  0.85241386,  0.90987399,  0.94359633,\n",
       "         0.9632874 ,  0.97736389,  0.98593683,  0.99047052,  0.9945643 ]),\n",
       " 'split4_test_score': array([ 0.46850329,  0.74523698,  0.6900849 ,  0.87172505,  0.84919524,\n",
       "         0.76373291,  0.73404331,  0.72920248,  0.72395248,  0.82818725]),\n",
       " 'split4_train_score': array([ 0.47424822,  0.72092696,  0.83202593,  0.89689952,  0.93603424,\n",
       "         0.9602553 ,  0.97402053,  0.98516227,  0.99170853,  0.99476947]),\n",
       " 'std_fit_time': array([  5.65067102e-04,   3.70282171e-04,   2.04900894e-04,\n",
       "          4.06124198e-05,   2.47147850e-04,   7.13240008e-05,\n",
       "          1.13348917e-05,   1.17870191e-04,   1.24021394e-04,\n",
       "          2.39434937e-05]),\n",
       " 'std_score_time': array([  2.20482335e-04,   2.23771788e-04,   1.58857954e-04,\n",
       "          5.58506399e-05,   1.29119895e-05,   5.59222454e-06,\n",
       "          5.35375808e-06,   3.25011312e-05,   4.48870704e-05,\n",
       "          1.38553814e-05]),\n",
       " 'std_test_score': array([ 0.06466227,  0.11112121,  0.12867761,  0.12990317,  0.09058218,\n",
       "         0.10041538,  0.08665212,  0.09295032,  0.11165039,  0.10339538]),\n",
       " 'std_train_score': array([ 0.01238108,  0.01422761,  0.00731183,  0.00620573,  0.00445652,\n",
       "         0.00260388,  0.00283519,  0.00159764,  0.00095834,  0.00087809])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch関数作成\n",
    "# [20171106追記]\n",
    "[こちら](http://chrisstrelioff.ws/sandbox/2015/06/25/decision_trees_in_python_again_cross_validation.html)を参考にDecisionTreeRegressor()に書き換えて、再度グリッドサーチを実施し、パラメータを探索しました。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(grid_scores, n_top=3):\n",
    "    \"\"\"Report top n_top parameters settings, default n_top=3.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    grid_scores -- output from grid or random search\n",
    "    n_top -- how many to report, of top models\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] top parameter settings found in\n",
    "                  search\n",
    "    \"\"\"\n",
    "    top_scores = sorted(grid_scores,\n",
    "                        key=itemgetter(1),\n",
    "                        reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print((\"Mean validation score: \"\n",
    "               \"{0:.3f} (std: {1:.3f})\").format(\n",
    "               score.mean_validation_score,\n",
    "               np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "    return top_scores[0].parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from operator import itemgetter\n",
    "\n",
    "def run_gridsearch(X, y, clf, param_grid, cv=5):\n",
    "    \"\"\"Run a grid search for best Decision Tree parameters.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    X -- features\n",
    "    y -- targets (classes)\n",
    "    cf -- scikit-learn Decision Tree\n",
    "    param_grid -- [dict] parameter settings to test\n",
    "    cv -- fold of cross-validation, default 5\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    top_params -- [dict] from report()\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(clf,\n",
    "                               param_grid=param_grid,\n",
    "                               cv=cv)\n",
    "    start = time()\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    print((\"\\nGridSearchCV took {:.2f} \"\n",
    "           \"seconds for {:d} candidate \"\n",
    "           \"parameter settings.\").format(time() - start,\n",
    "                len(grid_search.grid_scores_)))\n",
    "\n",
    "    top_params = report(grid_search.grid_scores_, 3)\n",
    "    return  top_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Grid Parameter Search via 10-fold CV\n",
      "\n",
      "GridSearchCV took 13.98 seconds for 180 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.366 (std: 0.417)\n",
      "Parameters: {'criterion': 'mae', 'max_depth': 5, 'max_leaf_nodes': None, 'min_samples_leaf': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.357 (std: 0.410)\n",
      "Parameters: {'criterion': 'mae', 'max_depth': 10, 'max_leaf_nodes': None, 'min_samples_leaf': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.354 (std: 0.416)\n",
      "Parameters: {'criterion': 'mae', 'max_depth': None, 'max_leaf_nodes': None, 'min_samples_leaf': 10}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suzukiry/lab/March/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/suzukiry/lab/March/lib/python3.6/site-packages/sklearn/model_selection/_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Grid Parameter Search via 10-fold CV\")\n",
    "\n",
    "# set of parameters to test\n",
    "param_grid = {\"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "              \"max_depth\": [None, 2, 5, 10],\n",
    "              \"min_samples_leaf\": [2, 5, 10],\n",
    "              \"max_leaf_nodes\": [None, 2, 5, 10, 20]\n",
    "              }\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "ts_gs = run_gridsearch(X, y, dt, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Best Parameters:\n",
      "parameter: criterion            setting: mae\n",
      "parameter: max_depth            setting: 5\n",
      "parameter: max_leaf_nodes       setting: None\n",
      "parameter: min_samples_leaf     setting: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-- Best Parameters:\")\n",
    "for k, v in ts_gs.items():\n",
    "    print(\"parameter: {:<20s} setting: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
