{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "df = pd.read_csv('../../../mltestdata/SMSSpamCollection', sep='\\t', names = [\"label\", \"message\"])\n",
    "df['label'] = df['label'].map({'ham':0,'spam':1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'],df['label'],test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer()\n",
    "tf_vectorizer.fit(X_train)\n",
    "tf_vectorizer.vocabulary_\n",
    "\n",
    "X_train= tf_vectorizer.transform(X_train)\n",
    "X_test = tf_vectorizer.transform(X_test)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "悲しいかな、性能評価で何が何を意味しているかわからないので、まとめる。。。\n",
    "\n",
    "まず一言で言うと、__性能指標とは、y_testとy_predictを比較すること！__ のようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類の評価方法編\n",
    "* * * \n",
    "## Accuracy / Precision / Recall / f1\n",
    "例は上記の迷惑メールフィルタを使います。これを理解するにはsklearn.metricsが大いに役立ちそう。\n",
    "下の混同行列を例に考えるとよし。なので、先にこちらかを実行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (sklearn.metrics) confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[965   3]\n",
      " [  8 139]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "confmat = confusion_matrix(y_test, y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAC1CAYAAAAZU76pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXmqXOF5qlzheapc4XmqXOP8P3u6DEIOMtsIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11453e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.5,2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j,y=i,s=confmat[i,j],va='center',ha='center')\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (sklearn.metrics) accuracy_score / precision_score / recall_score / f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9901345291479821\n",
      "Precision score:  0.9788732394366197\n",
      "Recall score:  0.9455782312925171\n",
      "F1 score:  0.9619377162629758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision score: ', format(precision_score(y_test, y_pred)))\n",
    "print('Recall score: ', format(recall_score(y_test, y_pred)))\n",
    "print('F1 score: ', format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み方注意。\n",
    "- 縦に読むと、一行目が分類0、二行目が分類1を指している。\n",
    "- 横に読むと、どこに誤って分類されてしまったかを見る。一行目は０に正しく965個分類できて、１に3個誤って分類された事がわかる。\n",
    "\n",
    "この図を元にやりましょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy\n",
    "これは単純に正答率。　\n",
    "1-誤分類率なので、誤分類率を求め手から、引き算。\n",
    "\n",
    "```\n",
    "     (3+8)/(965+3+8+139)=0.00986547\n",
    "```\n",
    "\n",
    "そして引き算。\n",
    "```\n",
    "     1 - 0.00986547 = 0.99013...\n",
    "```\n",
    "__(sklearn.metrics) accuracy_score__ で求める事ができる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision\n",
    "適合率と言う指標。陽性のクラスと予測したサンプルのうち、実際に陽性と判断されたものの割合。 \n",
    "混同行列を使うと、Predictを中心に考える事。　Predictに対して、実際（True）はどうかな、と見ていく。\n",
    "\n",
    "* ここ要注意だったのですが、関数に __The best value is 1 and the worst value is 0.__ と文言があるので、ライブラリを使って求めるので、混同行列のフォーカスは１の方にして、計算をします。\n",
    "\n",
    "```\n",
    "     (139)/(139+3) = 0.97887324\n",
    "```\n",
    "\n",
    "##### Recall\n",
    "再現率という指標。\n",
    "混同行列を使うと、Trueを中心に考える事。　Trueに対して、予測（Predict）はどうかな、と見ていく。\n",
    "\n",
    "```\n",
    "     (139)/(139+8) = 0.94557823\n",
    "```\n",
    "\n",
    "##### F1\n",
    "適合率と再現率の調和平均している指標。確かPrecisionだけとか、Recallだけ、とかだと偏りが出ちゃうんだったような。\n",
    "\n",
    "```\n",
    "     F1 = 2 * (PRE * REC) / (PRE + REC)\n",
    "\n",
    "     2 * (0.97887324 * 0.94557823) / (0.97887324 + 0.94557823) = 0.9619377158661894\n",
    "```\n",
    "\n",
    "おー、一緒だ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あと注意点を以下に。\n",
    "\n",
    "RecallやPrecisionを見る事になるが、実際にはどの評価関数を重要視するかが大事。\n",
    "\n",
    "Recallの場合、True label大事になので、分類したい事（迷惑メールなど）をより検出することに、重きを置いているといえる。\n",
    "Precisionの場合、Predicted label大事になので、逆に本来の分類（迷惑メールなど）がきちんと本来の分類に分ける事ができているかということに重きを置いている事になる、と。 \n",
    "\n",
    "迷惑メールの場合、スパムで無いメールをスパムと認識しては困るので、Precisionを重要視するなど、評価する評価関数の使い分けが必要になってくる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (sklearn.metrics) classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これも便利。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       968\n",
      "          1       0.98      0.95      0.96       147\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * * \n",
    "## 決定係数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相関係数がrで、その二乗が決定係数。1に近いほど、回帰直線の式が成立して、yはxから完全に __決定__ されるから決定係数なんですね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "## p値\n",
    "一筋縄でわからないので、必要が出たら勉強します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ジニ係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gini(y_true, y_prob):\n",
    "   y_true = np.asarray(y_true)\n",
    "   y_true = y_true[np.argsort(y_prob)]\n",
    "   ntrue = 0\n",
    "   gini = 0\n",
    "   delta = 0\n",
    "   n = len(y_true)\n",
    "   for i in range(n-1, -1, -1):\n",
    "       y_i = y_true[i]\n",
    "       ntrue += y_i\n",
    "       gini += y_i * delta\n",
    "       delta += 1 - y_i\n",
    "   gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "   return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_pred, y_true):\n",
    "    return np.sqrt(np.square(np.log(y_true + 1) - np.log(y_pred + 1)).mean())\n",
    "\n",
    "def RMSLE(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5\n",
    "\n",
    "\n",
    "# A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "# https://www.kaggle.com/marknagelberg/caterpillar-tube-pricing/rmsle-function\n",
    "def rmsle(y, y_pred):\n",
    "\tassert len(y) == len(y_pred)\n",
    "\tterms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "\treturn (sum(terms_to_sum) * (1.0/len(y))) ** 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YieFan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personally, I am doing a bit more than this, I do this:\n",
    "\n",
    "First of all, introduce a new feature, and then do the following evaluation:\n",
    "Do this 20 times with different random setting:\n",
    "1. Train_test_split (70%/30%) -> local train (70% of original train), local val (30% of original train)\n",
    "2. Perform 5-fold CV on local train(70% of original train) -> generate out-of-fold prediction for local train (70% of original train) and local validation (30% of original train)\n",
    "3. Calculate AUC/Gini with (Y of local val, oof prediction of local val) -> Validation score for the local val (30% of original train)\n",
    "\n",
    "As I said above,  I repeat steps 1-2-3 20 times, and then I average the validation scores of (output of step 3).\n",
    "\n",
    "Now if the validation score improve compare to the validation score for data without the new feature, I proceed to second round of validation, this time I for the train_test_split with (50%/50%) setting.\n",
    "\n",
    "Only features that improve validation score in both rounds i.e. (70%/30%) and (50%/50%) setting, I will consider them to be useful \n",
    "\n",
    "So far, none of the features share on the kernel pass this test:joy:\n",
    "Maybe I am being too strict, but I am gonna stick with it -> there is always the next competition!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am doing it this way also partly because I have a good work station, so if your laptop/PC is too slow to do this, just do simple repeated k-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
